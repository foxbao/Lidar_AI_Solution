&&&& RUNNING TensorRT.trtexec [TensorRT v8601] # trtexec --onnx=model/rpn_centerhead_sim.onnx --saveEngine=model/rpn_centerhead_sim.plan.8503 --workspace=4096 --fp16 --outputIOFormats=fp16:chw --inputIOFormats=fp16:chw --verbose --dumpLayerInfo --dumpProfile --separateProfileRun --profilingVerbosity=detailed
[04/25/2025-09:08:31] [W] --workspace flag has been deprecated by --memPoolSize flag.
[04/25/2025-09:08:31] [I] === Model Options ===
[04/25/2025-09:08:31] [I] Format: ONNX
[04/25/2025-09:08:31] [I] Model: model/rpn_centerhead_sim.onnx
[04/25/2025-09:08:31] [I] Output:
[04/25/2025-09:08:31] [I] === Build Options ===
[04/25/2025-09:08:31] [I] Max batch: explicit batch
[04/25/2025-09:08:31] [I] Memory Pools: workspace: 4096 MiB, dlaSRAM: default, dlaLocalDRAM: default, dlaGlobalDRAM: default
[04/25/2025-09:08:31] [I] minTiming: 1
[04/25/2025-09:08:31] [I] avgTiming: 8
[04/25/2025-09:08:31] [I] Precision: FP32+FP16
[04/25/2025-09:08:31] [I] LayerPrecisions: 
[04/25/2025-09:08:31] [I] Layer Device Types: 
[04/25/2025-09:08:31] [I] Calibration: 
[04/25/2025-09:08:31] [I] Refit: Disabled
[04/25/2025-09:08:31] [I] Version Compatible: Disabled
[04/25/2025-09:08:31] [I] TensorRT runtime: full
[04/25/2025-09:08:31] [I] Lean DLL Path: 
[04/25/2025-09:08:31] [I] Tempfile Controls: { in_memory: allow, temporary: allow }
[04/25/2025-09:08:31] [I] Exclude Lean Runtime: Disabled
[04/25/2025-09:08:31] [I] Sparsity: Disabled
[04/25/2025-09:08:31] [I] Safe mode: Disabled
[04/25/2025-09:08:31] [I] Build DLA standalone loadable: Disabled
[04/25/2025-09:08:31] [I] Allow GPU fallback for DLA: Disabled
[04/25/2025-09:08:31] [I] DirectIO mode: Disabled
[04/25/2025-09:08:31] [I] Restricted mode: Disabled
[04/25/2025-09:08:31] [I] Skip inference: Disabled
[04/25/2025-09:08:31] [I] Save engine: model/rpn_centerhead_sim.plan.8503
[04/25/2025-09:08:31] [I] Load engine: 
[04/25/2025-09:08:31] [I] Profiling verbosity: 2
[04/25/2025-09:08:31] [I] Tactic sources: Using default tactic sources
[04/25/2025-09:08:31] [I] timingCacheMode: local
[04/25/2025-09:08:31] [I] timingCacheFile: 
[04/25/2025-09:08:31] [I] Heuristic: Disabled
[04/25/2025-09:08:31] [I] Preview Features: Use default preview flags.
[04/25/2025-09:08:31] [I] MaxAuxStreams: -1
[04/25/2025-09:08:31] [I] BuilderOptimizationLevel: -1
[04/25/2025-09:08:31] [I] Input(s): fp16:chw
[04/25/2025-09:08:31] [I] Output(s): fp16:chw
[04/25/2025-09:08:31] [I] Input build shapes: model
[04/25/2025-09:08:31] [I] Input calibration shapes: model
[04/25/2025-09:08:31] [I] === System Options ===
[04/25/2025-09:08:31] [I] Device: 0
[04/25/2025-09:08:31] [I] DLACore: 
[04/25/2025-09:08:31] [I] Plugins:
[04/25/2025-09:08:31] [I] setPluginsToSerialize:
[04/25/2025-09:08:31] [I] dynamicPlugins:
[04/25/2025-09:08:31] [I] ignoreParsedPluginLibs: 0
[04/25/2025-09:08:31] [I] 
[04/25/2025-09:08:31] [I] === Inference Options ===
[04/25/2025-09:08:31] [I] Batch: Explicit
[04/25/2025-09:08:31] [I] Input inference shapes: model
[04/25/2025-09:08:31] [I] Iterations: 10
[04/25/2025-09:08:31] [I] Duration: 3s (+ 200ms warm up)
[04/25/2025-09:08:31] [I] Sleep time: 0ms
[04/25/2025-09:08:31] [I] Idle time: 0ms
[04/25/2025-09:08:31] [I] Inference Streams: 1
[04/25/2025-09:08:31] [I] ExposeDMA: Disabled
[04/25/2025-09:08:31] [I] Data transfers: Enabled
[04/25/2025-09:08:31] [I] Spin-wait: Disabled
[04/25/2025-09:08:31] [I] Multithreading: Disabled
[04/25/2025-09:08:31] [I] CUDA Graph: Disabled
[04/25/2025-09:08:31] [I] Separate profiling: Enabled
[04/25/2025-09:08:31] [I] Time Deserialize: Disabled
[04/25/2025-09:08:31] [I] Time Refit: Disabled
[04/25/2025-09:08:31] [I] NVTX verbosity: 2
[04/25/2025-09:08:31] [I] Persistent Cache Ratio: 0
[04/25/2025-09:08:31] [I] Inputs:
[04/25/2025-09:08:31] [I] === Reporting Options ===
[04/25/2025-09:08:31] [I] Verbose: Enabled
[04/25/2025-09:08:31] [I] Averages: 10 inferences
[04/25/2025-09:08:31] [I] Percentiles: 90,95,99
[04/25/2025-09:08:31] [I] Dump refittable layers:Disabled
[04/25/2025-09:08:31] [I] Dump output: Disabled
[04/25/2025-09:08:31] [I] Profile: Enabled
[04/25/2025-09:08:31] [I] Export timing to JSON file: 
[04/25/2025-09:08:31] [I] Export output to JSON file: 
[04/25/2025-09:08:31] [I] Export profile to JSON file: 
[04/25/2025-09:08:31] [I] 
[04/25/2025-09:08:31] [I] === Device Information ===
[04/25/2025-09:08:31] [I] Selected Device: NVIDIA GeForce RTX 4090
[04/25/2025-09:08:31] [I] Compute Capability: 8.9
[04/25/2025-09:08:31] [I] SMs: 128
[04/25/2025-09:08:31] [I] Device Global Memory: 24210 MiB
[04/25/2025-09:08:31] [I] Shared Memory per SM: 100 KiB
[04/25/2025-09:08:31] [I] Memory Bus Width: 384 bits (ECC disabled)
[04/25/2025-09:08:31] [I] Application Compute Clock Rate: 2.52 GHz
[04/25/2025-09:08:31] [I] Application Memory Clock Rate: 10.501 GHz
[04/25/2025-09:08:31] [I] 
[04/25/2025-09:08:31] [I] Note: The application clock rates do not reflect the actual clock rates that the GPU is currently running at.
[04/25/2025-09:08:31] [I] 
[04/25/2025-09:08:31] [I] TensorRT version: 8.6.1
[04/25/2025-09:08:31] [I] Loading standard plugins
[04/25/2025-09:08:32] [V] [TRT] Registered plugin creator - ::BatchedNMSDynamic_TRT version 1
[04/25/2025-09:08:32] [V] [TRT] Registered plugin creator - ::BatchedNMS_TRT version 1
[04/25/2025-09:08:32] [V] [TRT] Registered plugin creator - ::BatchTilePlugin_TRT version 1
[04/25/2025-09:08:32] [V] [TRT] Registered plugin creator - ::Clip_TRT version 1
[04/25/2025-09:08:32] [V] [TRT] Registered plugin creator - ::CoordConvAC version 1
[04/25/2025-09:08:32] [V] [TRT] Registered plugin creator - ::CropAndResizeDynamic version 1
[04/25/2025-09:08:32] [V] [TRT] Registered plugin creator - ::CropAndResize version 1
[04/25/2025-09:08:32] [V] [TRT] Registered plugin creator - ::DecodeBbox3DPlugin version 1
[04/25/2025-09:08:32] [V] [TRT] Registered plugin creator - ::DetectionLayer_TRT version 1
[04/25/2025-09:08:32] [V] [TRT] Registered plugin creator - ::EfficientNMS_Explicit_TF_TRT version 1
[04/25/2025-09:08:32] [V] [TRT] Registered plugin creator - ::EfficientNMS_Implicit_TF_TRT version 1
[04/25/2025-09:08:32] [V] [TRT] Registered plugin creator - ::EfficientNMS_ONNX_TRT version 1
[04/25/2025-09:08:32] [V] [TRT] Registered plugin creator - ::EfficientNMS_TRT version 1
[04/25/2025-09:08:32] [V] [TRT] Registered plugin creator - ::FlattenConcat_TRT version 1
[04/25/2025-09:08:32] [V] [TRT] Registered plugin creator - ::GenerateDetection_TRT version 1
[04/25/2025-09:08:32] [V] [TRT] Registered plugin creator - ::GridAnchor_TRT version 1
[04/25/2025-09:08:32] [V] [TRT] Registered plugin creator - ::GridAnchorRect_TRT version 1
[04/25/2025-09:08:32] [V] [TRT] Registered plugin creator - ::InstanceNormalization_TRT version 1
[04/25/2025-09:08:32] [V] [TRT] Registered plugin creator - ::InstanceNormalization_TRT version 2
[04/25/2025-09:08:32] [V] [TRT] Registered plugin creator - ::LReLU_TRT version 1
[04/25/2025-09:08:32] [V] [TRT] Registered plugin creator - ::ModulatedDeformConv2d version 1
[04/25/2025-09:08:32] [V] [TRT] Registered plugin creator - ::MultilevelCropAndResize_TRT version 1
[04/25/2025-09:08:32] [V] [TRT] Registered plugin creator - ::MultilevelProposeROI_TRT version 1
[04/25/2025-09:08:32] [V] [TRT] Registered plugin creator - ::MultiscaleDeformableAttnPlugin_TRT version 1
[04/25/2025-09:08:32] [V] [TRT] Registered plugin creator - ::NMSDynamic_TRT version 1
[04/25/2025-09:08:32] [V] [TRT] Registered plugin creator - ::NMS_TRT version 1
[04/25/2025-09:08:32] [V] [TRT] Registered plugin creator - ::Normalize_TRT version 1
[04/25/2025-09:08:32] [V] [TRT] Registered plugin creator - ::PillarScatterPlugin version 1
[04/25/2025-09:08:32] [V] [TRT] Registered plugin creator - ::PriorBox_TRT version 1
[04/25/2025-09:08:32] [V] [TRT] Registered plugin creator - ::ProposalDynamic version 1
[04/25/2025-09:08:32] [V] [TRT] Registered plugin creator - ::ProposalLayer_TRT version 1
[04/25/2025-09:08:32] [V] [TRT] Registered plugin creator - ::Proposal version 1
[04/25/2025-09:08:32] [V] [TRT] Registered plugin creator - ::PyramidROIAlign_TRT version 1
[04/25/2025-09:08:32] [V] [TRT] Registered plugin creator - ::Region_TRT version 1
[04/25/2025-09:08:32] [V] [TRT] Registered plugin creator - ::Reorg_TRT version 1
[04/25/2025-09:08:32] [V] [TRT] Registered plugin creator - ::ResizeNearest_TRT version 1
[04/25/2025-09:08:32] [V] [TRT] Registered plugin creator - ::ROIAlign_TRT version 1
[04/25/2025-09:08:32] [V] [TRT] Registered plugin creator - ::RPROI_TRT version 1
[04/25/2025-09:08:32] [V] [TRT] Registered plugin creator - ::ScatterND version 1
[04/25/2025-09:08:32] [V] [TRT] Registered plugin creator - ::SpecialSlice_TRT version 1
[04/25/2025-09:08:32] [V] [TRT] Registered plugin creator - ::Split version 1
[04/25/2025-09:08:32] [V] [TRT] Registered plugin creator - ::VoxelGeneratorPlugin version 1
[04/25/2025-09:08:32] [I] [TRT] [MemUsageChange] Init CUDA: CPU +14, GPU +0, now: CPU 22, GPU 834 (MiB)
[04/25/2025-09:08:32] [V] [TRT] Trying to load shared library libnvinfer_builder_resource.so.8.6.1
[04/25/2025-09:08:32] [V] [TRT] Loaded shared library libnvinfer_builder_resource.so.8.6.1
[04/25/2025-09:08:40] [I] [TRT] [MemUsageChange] Init builder kernel library: CPU +1459, GPU +266, now: CPU 1558, GPU 1100 (MiB)
[04/25/2025-09:08:40] [V] [TRT] CUDA lazy loading is enabled.
[04/25/2025-09:08:40] [I] Start parsing network model.
[04/25/2025-09:08:40] [I] [TRT] ----------------------------------------------------------------
[04/25/2025-09:08:40] [I] [TRT] Input filename:   model/rpn_centerhead_sim.onnx
[04/25/2025-09:08:40] [I] [TRT] ONNX IR version:  0.0.6
[04/25/2025-09:08:40] [I] [TRT] Opset version:    11
[04/25/2025-09:08:40] [I] [TRT] Producer name:    pytorch
[04/25/2025-09:08:40] [I] [TRT] Producer version: 1.11.0
[04/25/2025-09:08:40] [I] [TRT] Domain:           
[04/25/2025-09:08:40] [I] [TRT] Model version:    0
[04/25/2025-09:08:40] [I] [TRT] Doc string:       
[04/25/2025-09:08:40] [I] [TRT] ----------------------------------------------------------------
[04/25/2025-09:08:40] [V] [TRT] Plugin creator already registered - ::BatchedNMSDynamic_TRT version 1
[04/25/2025-09:08:40] [V] [TRT] Plugin creator already registered - ::BatchedNMS_TRT version 1
[04/25/2025-09:08:40] [V] [TRT] Plugin creator already registered - ::BatchTilePlugin_TRT version 1
[04/25/2025-09:08:40] [V] [TRT] Plugin creator already registered - ::Clip_TRT version 1
[04/25/2025-09:08:40] [V] [TRT] Plugin creator already registered - ::CoordConvAC version 1
[04/25/2025-09:08:40] [V] [TRT] Plugin creator already registered - ::CropAndResizeDynamic version 1
[04/25/2025-09:08:40] [V] [TRT] Plugin creator already registered - ::CropAndResize version 1
[04/25/2025-09:08:40] [V] [TRT] Plugin creator already registered - ::DecodeBbox3DPlugin version 1
[04/25/2025-09:08:40] [V] [TRT] Plugin creator already registered - ::DetectionLayer_TRT version 1
[04/25/2025-09:08:40] [V] [TRT] Plugin creator already registered - ::EfficientNMS_Explicit_TF_TRT version 1
[04/25/2025-09:08:40] [V] [TRT] Plugin creator already registered - ::EfficientNMS_Implicit_TF_TRT version 1
[04/25/2025-09:08:40] [V] [TRT] Plugin creator already registered - ::EfficientNMS_ONNX_TRT version 1
[04/25/2025-09:08:40] [V] [TRT] Plugin creator already registered - ::EfficientNMS_TRT version 1
[04/25/2025-09:08:40] [V] [TRT] Plugin creator already registered - ::FlattenConcat_TRT version 1
[04/25/2025-09:08:40] [V] [TRT] Plugin creator already registered - ::GenerateDetection_TRT version 1
[04/25/2025-09:08:40] [V] [TRT] Plugin creator already registered - ::GridAnchor_TRT version 1
[04/25/2025-09:08:40] [V] [TRT] Plugin creator already registered - ::GridAnchorRect_TRT version 1
[04/25/2025-09:08:40] [V] [TRT] Plugin creator already registered - ::InstanceNormalization_TRT version 1
[04/25/2025-09:08:40] [V] [TRT] Plugin creator already registered - ::InstanceNormalization_TRT version 2
[04/25/2025-09:08:40] [V] [TRT] Plugin creator already registered - ::LReLU_TRT version 1
[04/25/2025-09:08:40] [V] [TRT] Plugin creator already registered - ::ModulatedDeformConv2d version 1
[04/25/2025-09:08:40] [V] [TRT] Plugin creator already registered - ::MultilevelCropAndResize_TRT version 1
[04/25/2025-09:08:40] [V] [TRT] Plugin creator already registered - ::MultilevelProposeROI_TRT version 1
[04/25/2025-09:08:40] [V] [TRT] Plugin creator already registered - ::MultiscaleDeformableAttnPlugin_TRT version 1
[04/25/2025-09:08:40] [V] [TRT] Plugin creator already registered - ::NMSDynamic_TRT version 1
[04/25/2025-09:08:40] [V] [TRT] Plugin creator already registered - ::NMS_TRT version 1
[04/25/2025-09:08:40] [V] [TRT] Plugin creator already registered - ::Normalize_TRT version 1
[04/25/2025-09:08:40] [V] [TRT] Plugin creator already registered - ::PillarScatterPlugin version 1
[04/25/2025-09:08:40] [V] [TRT] Plugin creator already registered - ::PriorBox_TRT version 1
[04/25/2025-09:08:40] [V] [TRT] Plugin creator already registered - ::ProposalDynamic version 1
[04/25/2025-09:08:40] [V] [TRT] Plugin creator already registered - ::ProposalLayer_TRT version 1
[04/25/2025-09:08:40] [V] [TRT] Plugin creator already registered - ::Proposal version 1
[04/25/2025-09:08:40] [V] [TRT] Plugin creator already registered - ::PyramidROIAlign_TRT version 1
[04/25/2025-09:08:40] [V] [TRT] Plugin creator already registered - ::Region_TRT version 1
[04/25/2025-09:08:40] [V] [TRT] Plugin creator already registered - ::Reorg_TRT version 1
[04/25/2025-09:08:40] [V] [TRT] Plugin creator already registered - ::ResizeNearest_TRT version 1
[04/25/2025-09:08:40] [V] [TRT] Plugin creator already registered - ::ROIAlign_TRT version 1
[04/25/2025-09:08:40] [V] [TRT] Plugin creator already registered - ::RPROI_TRT version 1
[04/25/2025-09:08:40] [V] [TRT] Plugin creator already registered - ::ScatterND version 1
[04/25/2025-09:08:40] [V] [TRT] Plugin creator already registered - ::SpecialSlice_TRT version 1
[04/25/2025-09:08:40] [V] [TRT] Plugin creator already registered - ::Split version 1
[04/25/2025-09:08:40] [V] [TRT] Plugin creator already registered - ::VoxelGeneratorPlugin version 1
[04/25/2025-09:08:40] [V] [TRT] Adding network input: input with dtype: float32, dimensions: (1, 256, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input for ONNX tensor: input
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.neck.deblocks.1.0.weight
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.neck.deblocks.1.1.weight
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.neck.deblocks.1.1.bias
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.neck.deblocks.1.1.running_mean
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.neck.deblocks.1.1.running_var
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.0.reg.3.weight
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.0.reg.3.bias
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.0.height.3.weight
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.0.height.3.bias
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.0.dim.3.weight
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.0.dim.3.bias
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.0.rot.3.weight
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.0.rot.3.bias
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.0.vel.3.weight
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.0.vel.3.bias
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.0.hm.3.weight
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.0.hm.3.bias
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.1.reg.3.weight
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.1.reg.3.bias
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.1.height.3.weight
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.1.height.3.bias
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.1.dim.3.weight
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.1.dim.3.bias
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.1.rot.3.weight
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.1.rot.3.bias
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.1.vel.3.weight
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.1.vel.3.bias
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.1.hm.3.weight
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.1.hm.3.bias
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.2.reg.3.weight
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.2.reg.3.bias
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.2.height.3.weight
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.2.height.3.bias
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.2.dim.3.weight
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.2.dim.3.bias
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.2.rot.3.weight
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.2.rot.3.bias
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.2.vel.3.weight
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.2.vel.3.bias
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.2.hm.3.weight
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.2.hm.3.bias
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.3.reg.3.weight
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.3.reg.3.bias
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.3.height.3.weight
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.3.height.3.bias
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.3.dim.3.weight
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.3.dim.3.bias
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.3.rot.3.weight
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.3.rot.3.bias
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.3.vel.3.weight
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.3.vel.3.bias
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.3.hm.3.weight
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.3.hm.3.bias
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.4.reg.3.weight
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.4.reg.3.bias
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.4.height.3.weight
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.4.height.3.bias
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.4.dim.3.weight
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.4.dim.3.bias
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.4.rot.3.weight
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.4.rot.3.bias
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.4.vel.3.weight
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.4.vel.3.bias
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.4.hm.3.weight
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.4.hm.3.bias
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.5.reg.3.weight
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.5.reg.3.bias
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.5.height.3.weight
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.5.height.3.bias
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.5.dim.3.weight
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.5.dim.3.bias
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.5.rot.3.weight
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.5.rot.3.bias
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.5.vel.3.weight
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.5.vel.3.bias
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.5.hm.3.weight
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: model.bbox_head.tasks.5.hm.3.bias
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_797
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_798
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_800
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_801
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_803
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_804
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_806
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_807
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_809
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_810
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_812
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_813
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_815
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_816
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_818
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_819
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_821
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_822
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_824
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_825
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_827
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_828
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_830
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_831
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_833
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_834
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_836
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_837
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_839
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_840
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_842
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_843
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_845
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_846
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_848
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_849
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_851
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_852
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_854
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_855
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_857
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_858
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_860
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_861
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_863
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_864
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_866
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_867
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_869
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_870
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_872
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_873
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_875
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_876
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_878
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_879
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_881
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_882
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_884
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_885
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_887
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_888
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_890
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_891
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_893
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_894
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_896
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_897
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_899
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_900
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_902
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_903
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_905
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_906
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_908
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_909
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_911
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_912
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_914
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_915
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_917
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_918
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_920
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_921
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_923
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_924
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_926
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_927
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_929
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_930
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_932
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_933
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_935
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_936
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_938
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_939
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_941
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_942
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_944
[04/25/2025-09:08:40] [V] [TRT] Importing initializer: onnx::Conv_945
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_15 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_797
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_798
[04/25/2025-09:08:40] [V] [TRT] Conv_15 [Conv] inputs: [input -> (1, 256, 180, 180)[FLOAT]], [onnx::Conv_797 -> (128, 256, 3, 3)[FLOAT]], [onnx::Conv_798 -> (128)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 256, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_15 for ONNX node: Conv_15
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 128
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 128, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.8 for ONNX tensor: input.8
[04/25/2025-09:08:40] [V] [TRT] Conv_15 [Conv] outputs: [input.8 -> (1, 128, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Relu_16 [Relu]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.8
[04/25/2025-09:08:40] [V] [TRT] Relu_16 [Relu] inputs: [input.8 -> (1, 128, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Relu_16 for ONNX node: Relu_16
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.12 for ONNX tensor: input.12
[04/25/2025-09:08:40] [V] [TRT] Relu_16 [Relu] outputs: [input.12 -> (1, 128, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_17 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.12
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_800
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_801
[04/25/2025-09:08:40] [V] [TRT] Conv_17 [Conv] inputs: [input.12 -> (1, 128, 180, 180)[FLOAT]], [onnx::Conv_800 -> (128, 128, 3, 3)[FLOAT]], [onnx::Conv_801 -> (128)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 128, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_17 for ONNX node: Conv_17
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 128
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 128, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.20 for ONNX tensor: input.20
[04/25/2025-09:08:40] [V] [TRT] Conv_17 [Conv] outputs: [input.20 -> (1, 128, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Relu_18 [Relu]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.20
[04/25/2025-09:08:40] [V] [TRT] Relu_18 [Relu] inputs: [input.20 -> (1, 128, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Relu_18 for ONNX node: Relu_18
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.24 for ONNX tensor: input.24
[04/25/2025-09:08:40] [V] [TRT] Relu_18 [Relu] outputs: [input.24 -> (1, 128, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_19 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.24
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_803
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_804
[04/25/2025-09:08:40] [V] [TRT] Conv_19 [Conv] inputs: [input.24 -> (1, 128, 180, 180)[FLOAT]], [onnx::Conv_803 -> (128, 128, 3, 3)[FLOAT]], [onnx::Conv_804 -> (128)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 128, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_19 for ONNX node: Conv_19
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 128
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 128, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.32 for ONNX tensor: input.32
[04/25/2025-09:08:40] [V] [TRT] Conv_19 [Conv] outputs: [input.32 -> (1, 128, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Relu_20 [Relu]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.32
[04/25/2025-09:08:40] [V] [TRT] Relu_20 [Relu] inputs: [input.32 -> (1, 128, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Relu_20 for ONNX node: Relu_20
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.36 for ONNX tensor: input.36
[04/25/2025-09:08:40] [V] [TRT] Relu_20 [Relu] outputs: [input.36 -> (1, 128, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_21 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.36
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_806
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_807
[04/25/2025-09:08:40] [V] [TRT] Conv_21 [Conv] inputs: [input.36 -> (1, 128, 180, 180)[FLOAT]], [onnx::Conv_806 -> (128, 128, 3, 3)[FLOAT]], [onnx::Conv_807 -> (128)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 128, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_21 for ONNX node: Conv_21
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 128
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 128, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.44 for ONNX tensor: input.44
[04/25/2025-09:08:40] [V] [TRT] Conv_21 [Conv] outputs: [input.44 -> (1, 128, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Relu_22 [Relu]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.44
[04/25/2025-09:08:40] [V] [TRT] Relu_22 [Relu] inputs: [input.44 -> (1, 128, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Relu_22 for ONNX node: Relu_22
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.48 for ONNX tensor: input.48
[04/25/2025-09:08:40] [V] [TRT] Relu_22 [Relu] outputs: [input.48 -> (1, 128, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_23 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.48
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_809
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_810
[04/25/2025-09:08:40] [V] [TRT] Conv_23 [Conv] inputs: [input.48 -> (1, 128, 180, 180)[FLOAT]], [onnx::Conv_809 -> (128, 128, 3, 3)[FLOAT]], [onnx::Conv_810 -> (128)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 128, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_23 for ONNX node: Conv_23
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 128
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 128, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.56 for ONNX tensor: input.56
[04/25/2025-09:08:40] [V] [TRT] Conv_23 [Conv] outputs: [input.56 -> (1, 128, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Relu_24 [Relu]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.56
[04/25/2025-09:08:40] [V] [TRT] Relu_24 [Relu] inputs: [input.56 -> (1, 128, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Relu_24 for ONNX node: Relu_24
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.60 for ONNX tensor: input.60
[04/25/2025-09:08:40] [V] [TRT] Relu_24 [Relu] outputs: [input.60 -> (1, 128, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_25 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.60
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_812
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_813
[04/25/2025-09:08:40] [V] [TRT] Conv_25 [Conv] inputs: [input.60 -> (1, 128, 180, 180)[FLOAT]], [onnx::Conv_812 -> (128, 128, 3, 3)[FLOAT]], [onnx::Conv_813 -> (128)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 128, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_25 for ONNX node: Conv_25
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 128
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 128, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.68 for ONNX tensor: input.68
[04/25/2025-09:08:40] [V] [TRT] Conv_25 [Conv] outputs: [input.68 -> (1, 128, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Relu_26 [Relu]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.68
[04/25/2025-09:08:40] [V] [TRT] Relu_26 [Relu] inputs: [input.68 -> (1, 128, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Relu_26 for ONNX node: Relu_26
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.72 for ONNX tensor: input.72
[04/25/2025-09:08:40] [V] [TRT] Relu_26 [Relu] outputs: [input.72 -> (1, 128, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_27 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.72
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_815
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_816
[04/25/2025-09:08:40] [V] [TRT] Conv_27 [Conv] inputs: [input.72 -> (1, 128, 180, 180)[FLOAT]], [onnx::Conv_815 -> (256, 128, 1, 1)[FLOAT]], [onnx::Conv_816 -> (256)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 128, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_27 for ONNX node: Conv_27
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 256, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.80 for ONNX tensor: input.80
[04/25/2025-09:08:40] [V] [TRT] Conv_27 [Conv] outputs: [input.80 -> (1, 256, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Relu_28 [Relu]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.80
[04/25/2025-09:08:40] [V] [TRT] Relu_28 [Relu] inputs: [input.80 -> (1, 256, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Relu_28 for ONNX node: Relu_28
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: onnx::Concat_602 for ONNX tensor: onnx::Concat_602
[04/25/2025-09:08:40] [V] [TRT] Relu_28 [Relu] outputs: [onnx::Concat_602 -> (1, 256, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_44 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.72
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_818
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_819
[04/25/2025-09:08:40] [V] [TRT] Conv_44 [Conv] inputs: [input.72 -> (1, 128, 180, 180)[FLOAT]], [onnx::Conv_818 -> (256, 128, 3, 3)[FLOAT]], [onnx::Conv_819 -> (256)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 128, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_44 for ONNX node: Conv_44
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (2, 2), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 256
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 256, 90, 90)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.92 for ONNX tensor: input.92
[04/25/2025-09:08:40] [V] [TRT] Conv_44 [Conv] outputs: [input.92 -> (1, 256, 90, 90)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Relu_45 [Relu]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.92
[04/25/2025-09:08:40] [V] [TRT] Relu_45 [Relu] inputs: [input.92 -> (1, 256, 90, 90)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Relu_45 for ONNX node: Relu_45
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.96 for ONNX tensor: input.96
[04/25/2025-09:08:40] [V] [TRT] Relu_45 [Relu] outputs: [input.96 -> (1, 256, 90, 90)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_46 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.96
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_821
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_822
[04/25/2025-09:08:40] [V] [TRT] Conv_46 [Conv] inputs: [input.96 -> (1, 256, 90, 90)[FLOAT]], [onnx::Conv_821 -> (256, 256, 3, 3)[FLOAT]], [onnx::Conv_822 -> (256)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 256, 90, 90)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_46 for ONNX node: Conv_46
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 256
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 256, 90, 90)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.104 for ONNX tensor: input.104
[04/25/2025-09:08:40] [V] [TRT] Conv_46 [Conv] outputs: [input.104 -> (1, 256, 90, 90)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Relu_47 [Relu]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.104
[04/25/2025-09:08:40] [V] [TRT] Relu_47 [Relu] inputs: [input.104 -> (1, 256, 90, 90)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Relu_47 for ONNX node: Relu_47
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.108 for ONNX tensor: input.108
[04/25/2025-09:08:40] [V] [TRT] Relu_47 [Relu] outputs: [input.108 -> (1, 256, 90, 90)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_48 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.108
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_824
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_825
[04/25/2025-09:08:40] [V] [TRT] Conv_48 [Conv] inputs: [input.108 -> (1, 256, 90, 90)[FLOAT]], [onnx::Conv_824 -> (256, 256, 3, 3)[FLOAT]], [onnx::Conv_825 -> (256)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 256, 90, 90)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_48 for ONNX node: Conv_48
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 256
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 256, 90, 90)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.116 for ONNX tensor: input.116
[04/25/2025-09:08:40] [V] [TRT] Conv_48 [Conv] outputs: [input.116 -> (1, 256, 90, 90)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Relu_49 [Relu]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.116
[04/25/2025-09:08:40] [V] [TRT] Relu_49 [Relu] inputs: [input.116 -> (1, 256, 90, 90)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Relu_49 for ONNX node: Relu_49
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.120 for ONNX tensor: input.120
[04/25/2025-09:08:40] [V] [TRT] Relu_49 [Relu] outputs: [input.120 -> (1, 256, 90, 90)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_50 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.120
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_827
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_828
[04/25/2025-09:08:40] [V] [TRT] Conv_50 [Conv] inputs: [input.120 -> (1, 256, 90, 90)[FLOAT]], [onnx::Conv_827 -> (256, 256, 3, 3)[FLOAT]], [onnx::Conv_828 -> (256)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 256, 90, 90)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_50 for ONNX node: Conv_50
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 256
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 256, 90, 90)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.128 for ONNX tensor: input.128
[04/25/2025-09:08:40] [V] [TRT] Conv_50 [Conv] outputs: [input.128 -> (1, 256, 90, 90)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Relu_51 [Relu]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.128
[04/25/2025-09:08:40] [V] [TRT] Relu_51 [Relu] inputs: [input.128 -> (1, 256, 90, 90)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Relu_51 for ONNX node: Relu_51
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.132 for ONNX tensor: input.132
[04/25/2025-09:08:40] [V] [TRT] Relu_51 [Relu] outputs: [input.132 -> (1, 256, 90, 90)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_52 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.132
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_830
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_831
[04/25/2025-09:08:40] [V] [TRT] Conv_52 [Conv] inputs: [input.132 -> (1, 256, 90, 90)[FLOAT]], [onnx::Conv_830 -> (256, 256, 3, 3)[FLOAT]], [onnx::Conv_831 -> (256)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 256, 90, 90)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_52 for ONNX node: Conv_52
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 256
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 256, 90, 90)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.140 for ONNX tensor: input.140
[04/25/2025-09:08:40] [V] [TRT] Conv_52 [Conv] outputs: [input.140 -> (1, 256, 90, 90)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Relu_53 [Relu]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.140
[04/25/2025-09:08:40] [V] [TRT] Relu_53 [Relu] inputs: [input.140 -> (1, 256, 90, 90)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Relu_53 for ONNX node: Relu_53
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.144 for ONNX tensor: input.144
[04/25/2025-09:08:40] [V] [TRT] Relu_53 [Relu] outputs: [input.144 -> (1, 256, 90, 90)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_54 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.144
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_833
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_834
[04/25/2025-09:08:40] [V] [TRT] Conv_54 [Conv] inputs: [input.144 -> (1, 256, 90, 90)[FLOAT]], [onnx::Conv_833 -> (256, 256, 3, 3)[FLOAT]], [onnx::Conv_834 -> (256)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 256, 90, 90)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_54 for ONNX node: Conv_54
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 256
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 256, 90, 90)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.152 for ONNX tensor: input.152
[04/25/2025-09:08:40] [V] [TRT] Conv_54 [Conv] outputs: [input.152 -> (1, 256, 90, 90)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Relu_55 [Relu]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.152
[04/25/2025-09:08:40] [V] [TRT] Relu_55 [Relu] inputs: [input.152 -> (1, 256, 90, 90)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Relu_55 for ONNX node: Relu_55
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: onnx::ConvTranspose_644 for ONNX tensor: onnx::ConvTranspose_644
[04/25/2025-09:08:40] [V] [TRT] Relu_55 [Relu] outputs: [onnx::ConvTranspose_644 -> (1, 256, 90, 90)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: ConvTranspose_56 [ConvTranspose]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::ConvTranspose_644
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.neck.deblocks.1.0.weight
[04/25/2025-09:08:40] [V] [TRT] ConvTranspose_56 [ConvTranspose] inputs: [onnx::ConvTranspose_644 -> (1, 256, 90, 90)[FLOAT]], [model.neck.deblocks.1.0.weight -> (256, 256, 2, 2)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Running deconvolution with: 
Padding mode: NOTSET
Pre-padding: (0, 0)
Post-padding: (0, 0)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: ConvTranspose_56 for ONNX node: ConvTranspose_56
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.156 for ONNX tensor: input.156
[04/25/2025-09:08:40] [V] [TRT] ConvTranspose_56 [ConvTranspose] outputs: [input.156 -> (1, 256, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: BatchNormalization_57 [BatchNormalization]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.156
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.neck.deblocks.1.1.weight
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.neck.deblocks.1.1.bias
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.neck.deblocks.1.1.running_mean
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.neck.deblocks.1.1.running_var
[04/25/2025-09:08:40] [V] [TRT] BatchNormalization_57 [BatchNormalization] inputs: [input.156 -> (1, 256, 180, 180)[FLOAT]], [model.neck.deblocks.1.1.weight -> (256)[FLOAT]], [model.neck.deblocks.1.1.bias -> (256)[FLOAT]], [model.neck.deblocks.1.1.running_mean -> (256)[FLOAT]], [model.neck.deblocks.1.1.running_var -> (256)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Registering layer: BatchNormalization_57 for ONNX node: BatchNormalization_57
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.160 for ONNX tensor: input.160
[04/25/2025-09:08:40] [V] [TRT] BatchNormalization_57 [BatchNormalization] outputs: [input.160 -> (1, 256, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Relu_58 [Relu]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.160
[04/25/2025-09:08:40] [V] [TRT] Relu_58 [Relu] inputs: [input.160 -> (1, 256, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Relu_58 for ONNX node: Relu_58
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: onnx::Concat_647 for ONNX tensor: onnx::Concat_647
[04/25/2025-09:08:40] [V] [TRT] Relu_58 [Relu] outputs: [onnx::Concat_647 -> (1, 256, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Concat_59 [Concat]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Concat_602
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Concat_647
[04/25/2025-09:08:40] [V] [TRT] Concat_59 [Concat] inputs: [onnx::Concat_602 -> (1, 256, 180, 180)[FLOAT]], [onnx::Concat_647 -> (1, 256, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Concat_59 for ONNX node: Concat_59
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.164 for ONNX tensor: input.164
[04/25/2025-09:08:40] [V] [TRT] Concat_59 [Concat] outputs: [input.164 -> (1, 512, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_60 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.164
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_836
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_837
[04/25/2025-09:08:40] [V] [TRT] Conv_60 [Conv] inputs: [input.164 -> (1, 512, 180, 180)[FLOAT]], [onnx::Conv_836 -> (64, 512, 3, 3)[FLOAT]], [onnx::Conv_837 -> (64)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 512, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_60 for ONNX node: Conv_60
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.172 for ONNX tensor: input.172
[04/25/2025-09:08:40] [V] [TRT] Conv_60 [Conv] outputs: [input.172 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Relu_61 [Relu]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.172
[04/25/2025-09:08:40] [V] [TRT] Relu_61 [Relu] inputs: [input.172 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Relu_61 for ONNX node: Relu_61
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: onnx::Conv_651 for ONNX tensor: onnx::Conv_651
[04/25/2025-09:08:40] [V] [TRT] Relu_61 [Relu] outputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_62 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_651
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_839
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_840
[04/25/2025-09:08:40] [V] [TRT] Conv_62 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_839 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_840 -> (64)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_62 for ONNX node: Conv_62
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.180 for ONNX tensor: input.180
[04/25/2025-09:08:40] [V] [TRT] Conv_62 [Conv] outputs: [input.180 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Relu_63 [Relu]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.180
[04/25/2025-09:08:40] [V] [TRT] Relu_63 [Relu] inputs: [input.180 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Relu_63 for ONNX node: Relu_63
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.184 for ONNX tensor: input.184
[04/25/2025-09:08:40] [V] [TRT] Relu_63 [Relu] outputs: [input.184 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_64 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.184
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.0.reg.3.weight
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.0.reg.3.bias
[04/25/2025-09:08:40] [V] [TRT] Conv_64 [Conv] inputs: [input.184 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.0.reg.3.weight -> (2, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.0.reg.3.bias -> (2)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_64 for ONNX node: Conv_64
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 2, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: reg_0_1 for ONNX tensor: reg_0
[04/25/2025-09:08:40] [V] [TRT] Conv_64 [Conv] outputs: [reg_0 -> (1, 2, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_65 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_651
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_842
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_843
[04/25/2025-09:08:40] [V] [TRT] Conv_65 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_842 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_843 -> (64)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_65 for ONNX node: Conv_65
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.192 for ONNX tensor: input.192
[04/25/2025-09:08:40] [V] [TRT] Conv_65 [Conv] outputs: [input.192 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Relu_66 [Relu]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.192
[04/25/2025-09:08:40] [V] [TRT] Relu_66 [Relu] inputs: [input.192 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Relu_66 for ONNX node: Relu_66
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.196 for ONNX tensor: input.196
[04/25/2025-09:08:40] [V] [TRT] Relu_66 [Relu] outputs: [input.196 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_67 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.196
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.0.height.3.weight
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.0.height.3.bias
[04/25/2025-09:08:40] [V] [TRT] Conv_67 [Conv] inputs: [input.196 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.0.height.3.weight -> (1, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.0.height.3.bias -> (1)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_67 for ONNX node: Conv_67
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 1
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 1, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: height_0_2 for ONNX tensor: height_0
[04/25/2025-09:08:40] [V] [TRT] Conv_67 [Conv] outputs: [height_0 -> (1, 1, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_68 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_651
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_845
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_846
[04/25/2025-09:08:40] [V] [TRT] Conv_68 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_845 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_846 -> (64)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_68 for ONNX node: Conv_68
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.204 for ONNX tensor: input.204
[04/25/2025-09:08:40] [V] [TRT] Conv_68 [Conv] outputs: [input.204 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Relu_69 [Relu]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.204
[04/25/2025-09:08:40] [V] [TRT] Relu_69 [Relu] inputs: [input.204 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Relu_69 for ONNX node: Relu_69
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.208 for ONNX tensor: input.208
[04/25/2025-09:08:40] [V] [TRT] Relu_69 [Relu] outputs: [input.208 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_70 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.208
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.0.dim.3.weight
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.0.dim.3.bias
[04/25/2025-09:08:40] [V] [TRT] Conv_70 [Conv] inputs: [input.208 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.0.dim.3.weight -> (3, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.0.dim.3.bias -> (3)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_70 for ONNX node: Conv_70
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 3
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 3, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: dim_0_3 for ONNX tensor: dim_0
[04/25/2025-09:08:40] [V] [TRT] Conv_70 [Conv] outputs: [dim_0 -> (1, 3, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_71 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_651
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_848
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_849
[04/25/2025-09:08:40] [V] [TRT] Conv_71 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_848 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_849 -> (64)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_71 for ONNX node: Conv_71
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.216 for ONNX tensor: input.216
[04/25/2025-09:08:40] [V] [TRT] Conv_71 [Conv] outputs: [input.216 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Relu_72 [Relu]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.216
[04/25/2025-09:08:40] [V] [TRT] Relu_72 [Relu] inputs: [input.216 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Relu_72 for ONNX node: Relu_72
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.220 for ONNX tensor: input.220
[04/25/2025-09:08:40] [V] [TRT] Relu_72 [Relu] outputs: [input.220 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_73 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.220
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.0.rot.3.weight
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.0.rot.3.bias
[04/25/2025-09:08:40] [V] [TRT] Conv_73 [Conv] inputs: [input.220 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.0.rot.3.weight -> (2, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.0.rot.3.bias -> (2)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_73 for ONNX node: Conv_73
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 2, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: rot_0_4 for ONNX tensor: rot_0
[04/25/2025-09:08:40] [V] [TRT] Conv_73 [Conv] outputs: [rot_0 -> (1, 2, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_74 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_651
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_851
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_852
[04/25/2025-09:08:40] [V] [TRT] Conv_74 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_851 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_852 -> (64)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_74 for ONNX node: Conv_74
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.228 for ONNX tensor: input.228
[04/25/2025-09:08:40] [V] [TRT] Conv_74 [Conv] outputs: [input.228 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Relu_75 [Relu]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.228
[04/25/2025-09:08:40] [V] [TRT] Relu_75 [Relu] inputs: [input.228 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Relu_75 for ONNX node: Relu_75
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.232 for ONNX tensor: input.232
[04/25/2025-09:08:40] [V] [TRT] Relu_75 [Relu] outputs: [input.232 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_76 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.232
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.0.vel.3.weight
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.0.vel.3.bias
[04/25/2025-09:08:40] [V] [TRT] Conv_76 [Conv] inputs: [input.232 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.0.vel.3.weight -> (2, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.0.vel.3.bias -> (2)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_76 for ONNX node: Conv_76
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 2, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: vel_0_5 for ONNX tensor: vel_0
[04/25/2025-09:08:40] [V] [TRT] Conv_76 [Conv] outputs: [vel_0 -> (1, 2, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_77 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_651
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_854
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_855
[04/25/2025-09:08:40] [V] [TRT] Conv_77 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_854 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_855 -> (64)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_77 for ONNX node: Conv_77
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.240 for ONNX tensor: input.240
[04/25/2025-09:08:40] [V] [TRT] Conv_77 [Conv] outputs: [input.240 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Relu_78 [Relu]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.240
[04/25/2025-09:08:40] [V] [TRT] Relu_78 [Relu] inputs: [input.240 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Relu_78 for ONNX node: Relu_78
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.244 for ONNX tensor: input.244
[04/25/2025-09:08:40] [V] [TRT] Relu_78 [Relu] outputs: [input.244 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_79 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.244
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.0.hm.3.weight
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.0.hm.3.bias
[04/25/2025-09:08:40] [V] [TRT] Conv_79 [Conv] inputs: [input.244 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.0.hm.3.weight -> (1, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.0.hm.3.bias -> (1)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_79 for ONNX node: Conv_79
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 1
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 1, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: hm_0_6 for ONNX tensor: hm_0
[04/25/2025-09:08:40] [V] [TRT] Conv_79 [Conv] outputs: [hm_0 -> (1, 1, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_80 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_651
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_857
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_858
[04/25/2025-09:08:40] [V] [TRT] Conv_80 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_857 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_858 -> (64)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_80 for ONNX node: Conv_80
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.252 for ONNX tensor: input.252
[04/25/2025-09:08:40] [V] [TRT] Conv_80 [Conv] outputs: [input.252 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Relu_81 [Relu]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.252
[04/25/2025-09:08:40] [V] [TRT] Relu_81 [Relu] inputs: [input.252 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Relu_81 for ONNX node: Relu_81
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.256 for ONNX tensor: input.256
[04/25/2025-09:08:40] [V] [TRT] Relu_81 [Relu] outputs: [input.256 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_82 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.256
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.1.reg.3.weight
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.1.reg.3.bias
[04/25/2025-09:08:40] [V] [TRT] Conv_82 [Conv] inputs: [input.256 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.1.reg.3.weight -> (2, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.1.reg.3.bias -> (2)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_82 for ONNX node: Conv_82
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 2, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: reg_1_7 for ONNX tensor: reg_1
[04/25/2025-09:08:40] [V] [TRT] Conv_82 [Conv] outputs: [reg_1 -> (1, 2, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_83 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_651
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_860
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_861
[04/25/2025-09:08:40] [V] [TRT] Conv_83 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_860 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_861 -> (64)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_83 for ONNX node: Conv_83
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.264 for ONNX tensor: input.264
[04/25/2025-09:08:40] [V] [TRT] Conv_83 [Conv] outputs: [input.264 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Relu_84 [Relu]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.264
[04/25/2025-09:08:40] [V] [TRT] Relu_84 [Relu] inputs: [input.264 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Relu_84 for ONNX node: Relu_84
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.268 for ONNX tensor: input.268
[04/25/2025-09:08:40] [V] [TRT] Relu_84 [Relu] outputs: [input.268 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_85 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.268
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.1.height.3.weight
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.1.height.3.bias
[04/25/2025-09:08:40] [V] [TRT] Conv_85 [Conv] inputs: [input.268 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.1.height.3.weight -> (1, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.1.height.3.bias -> (1)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_85 for ONNX node: Conv_85
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 1
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 1, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: height_1_8 for ONNX tensor: height_1
[04/25/2025-09:08:40] [V] [TRT] Conv_85 [Conv] outputs: [height_1 -> (1, 1, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_86 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_651
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_863
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_864
[04/25/2025-09:08:40] [V] [TRT] Conv_86 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_863 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_864 -> (64)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_86 for ONNX node: Conv_86
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.276 for ONNX tensor: input.276
[04/25/2025-09:08:40] [V] [TRT] Conv_86 [Conv] outputs: [input.276 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Relu_87 [Relu]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.276
[04/25/2025-09:08:40] [V] [TRT] Relu_87 [Relu] inputs: [input.276 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Relu_87 for ONNX node: Relu_87
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.280 for ONNX tensor: input.280
[04/25/2025-09:08:40] [V] [TRT] Relu_87 [Relu] outputs: [input.280 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_88 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.280
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.1.dim.3.weight
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.1.dim.3.bias
[04/25/2025-09:08:40] [V] [TRT] Conv_88 [Conv] inputs: [input.280 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.1.dim.3.weight -> (3, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.1.dim.3.bias -> (3)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_88 for ONNX node: Conv_88
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 3
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 3, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: dim_1_9 for ONNX tensor: dim_1
[04/25/2025-09:08:40] [V] [TRT] Conv_88 [Conv] outputs: [dim_1 -> (1, 3, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_89 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_651
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_866
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_867
[04/25/2025-09:08:40] [V] [TRT] Conv_89 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_866 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_867 -> (64)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_89 for ONNX node: Conv_89
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.288 for ONNX tensor: input.288
[04/25/2025-09:08:40] [V] [TRT] Conv_89 [Conv] outputs: [input.288 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Relu_90 [Relu]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.288
[04/25/2025-09:08:40] [V] [TRT] Relu_90 [Relu] inputs: [input.288 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Relu_90 for ONNX node: Relu_90
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.292 for ONNX tensor: input.292
[04/25/2025-09:08:40] [V] [TRT] Relu_90 [Relu] outputs: [input.292 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_91 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.292
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.1.rot.3.weight
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.1.rot.3.bias
[04/25/2025-09:08:40] [V] [TRT] Conv_91 [Conv] inputs: [input.292 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.1.rot.3.weight -> (2, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.1.rot.3.bias -> (2)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_91 for ONNX node: Conv_91
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 2, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: rot_1_10 for ONNX tensor: rot_1
[04/25/2025-09:08:40] [V] [TRT] Conv_91 [Conv] outputs: [rot_1 -> (1, 2, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_92 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_651
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_869
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_870
[04/25/2025-09:08:40] [V] [TRT] Conv_92 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_869 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_870 -> (64)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_92 for ONNX node: Conv_92
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.300 for ONNX tensor: input.300
[04/25/2025-09:08:40] [V] [TRT] Conv_92 [Conv] outputs: [input.300 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Relu_93 [Relu]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.300
[04/25/2025-09:08:40] [V] [TRT] Relu_93 [Relu] inputs: [input.300 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Relu_93 for ONNX node: Relu_93
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.304 for ONNX tensor: input.304
[04/25/2025-09:08:40] [V] [TRT] Relu_93 [Relu] outputs: [input.304 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_94 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.304
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.1.vel.3.weight
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.1.vel.3.bias
[04/25/2025-09:08:40] [V] [TRT] Conv_94 [Conv] inputs: [input.304 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.1.vel.3.weight -> (2, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.1.vel.3.bias -> (2)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_94 for ONNX node: Conv_94
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 2, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: vel_1_11 for ONNX tensor: vel_1
[04/25/2025-09:08:40] [V] [TRT] Conv_94 [Conv] outputs: [vel_1 -> (1, 2, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_95 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_651
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_872
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_873
[04/25/2025-09:08:40] [V] [TRT] Conv_95 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_872 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_873 -> (64)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_95 for ONNX node: Conv_95
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.312 for ONNX tensor: input.312
[04/25/2025-09:08:40] [V] [TRT] Conv_95 [Conv] outputs: [input.312 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Relu_96 [Relu]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.312
[04/25/2025-09:08:40] [V] [TRT] Relu_96 [Relu] inputs: [input.312 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Relu_96 for ONNX node: Relu_96
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.316 for ONNX tensor: input.316
[04/25/2025-09:08:40] [V] [TRT] Relu_96 [Relu] outputs: [input.316 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_97 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.316
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.1.hm.3.weight
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.1.hm.3.bias
[04/25/2025-09:08:40] [V] [TRT] Conv_97 [Conv] inputs: [input.316 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.1.hm.3.weight -> (2, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.1.hm.3.bias -> (2)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_97 for ONNX node: Conv_97
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 2, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: hm_1_12 for ONNX tensor: hm_1
[04/25/2025-09:08:40] [V] [TRT] Conv_97 [Conv] outputs: [hm_1 -> (1, 2, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_98 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_651
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_875
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_876
[04/25/2025-09:08:40] [V] [TRT] Conv_98 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_875 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_876 -> (64)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_98 for ONNX node: Conv_98
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.324 for ONNX tensor: input.324
[04/25/2025-09:08:40] [V] [TRT] Conv_98 [Conv] outputs: [input.324 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Relu_99 [Relu]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.324
[04/25/2025-09:08:40] [V] [TRT] Relu_99 [Relu] inputs: [input.324 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Relu_99 for ONNX node: Relu_99
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.328 for ONNX tensor: input.328
[04/25/2025-09:08:40] [V] [TRT] Relu_99 [Relu] outputs: [input.328 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_100 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.328
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.2.reg.3.weight
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.2.reg.3.bias
[04/25/2025-09:08:40] [V] [TRT] Conv_100 [Conv] inputs: [input.328 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.2.reg.3.weight -> (2, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.2.reg.3.bias -> (2)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_100 for ONNX node: Conv_100
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 2, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: reg_2_13 for ONNX tensor: reg_2
[04/25/2025-09:08:40] [V] [TRT] Conv_100 [Conv] outputs: [reg_2 -> (1, 2, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_101 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_651
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_878
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_879
[04/25/2025-09:08:40] [V] [TRT] Conv_101 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_878 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_879 -> (64)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_101 for ONNX node: Conv_101
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.336 for ONNX tensor: input.336
[04/25/2025-09:08:40] [V] [TRT] Conv_101 [Conv] outputs: [input.336 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Relu_102 [Relu]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.336
[04/25/2025-09:08:40] [V] [TRT] Relu_102 [Relu] inputs: [input.336 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Relu_102 for ONNX node: Relu_102
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.340 for ONNX tensor: input.340
[04/25/2025-09:08:40] [V] [TRT] Relu_102 [Relu] outputs: [input.340 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_103 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.340
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.2.height.3.weight
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.2.height.3.bias
[04/25/2025-09:08:40] [V] [TRT] Conv_103 [Conv] inputs: [input.340 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.2.height.3.weight -> (1, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.2.height.3.bias -> (1)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_103 for ONNX node: Conv_103
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 1
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 1, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: height_2_14 for ONNX tensor: height_2
[04/25/2025-09:08:40] [V] [TRT] Conv_103 [Conv] outputs: [height_2 -> (1, 1, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_104 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_651
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_881
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_882
[04/25/2025-09:08:40] [V] [TRT] Conv_104 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_881 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_882 -> (64)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_104 for ONNX node: Conv_104
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.348 for ONNX tensor: input.348
[04/25/2025-09:08:40] [V] [TRT] Conv_104 [Conv] outputs: [input.348 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Relu_105 [Relu]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.348
[04/25/2025-09:08:40] [V] [TRT] Relu_105 [Relu] inputs: [input.348 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Relu_105 for ONNX node: Relu_105
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.352 for ONNX tensor: input.352
[04/25/2025-09:08:40] [V] [TRT] Relu_105 [Relu] outputs: [input.352 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_106 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.352
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.2.dim.3.weight
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.2.dim.3.bias
[04/25/2025-09:08:40] [V] [TRT] Conv_106 [Conv] inputs: [input.352 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.2.dim.3.weight -> (3, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.2.dim.3.bias -> (3)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_106 for ONNX node: Conv_106
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 3
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 3, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: dim_2_15 for ONNX tensor: dim_2
[04/25/2025-09:08:40] [V] [TRT] Conv_106 [Conv] outputs: [dim_2 -> (1, 3, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_107 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_651
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_884
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_885
[04/25/2025-09:08:40] [V] [TRT] Conv_107 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_884 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_885 -> (64)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_107 for ONNX node: Conv_107
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.360 for ONNX tensor: input.360
[04/25/2025-09:08:40] [V] [TRT] Conv_107 [Conv] outputs: [input.360 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Relu_108 [Relu]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.360
[04/25/2025-09:08:40] [V] [TRT] Relu_108 [Relu] inputs: [input.360 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Relu_108 for ONNX node: Relu_108
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.364 for ONNX tensor: input.364
[04/25/2025-09:08:40] [V] [TRT] Relu_108 [Relu] outputs: [input.364 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_109 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.364
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.2.rot.3.weight
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.2.rot.3.bias
[04/25/2025-09:08:40] [V] [TRT] Conv_109 [Conv] inputs: [input.364 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.2.rot.3.weight -> (2, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.2.rot.3.bias -> (2)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_109 for ONNX node: Conv_109
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 2, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: rot_2_16 for ONNX tensor: rot_2
[04/25/2025-09:08:40] [V] [TRT] Conv_109 [Conv] outputs: [rot_2 -> (1, 2, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_110 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_651
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_887
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_888
[04/25/2025-09:08:40] [V] [TRT] Conv_110 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_887 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_888 -> (64)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_110 for ONNX node: Conv_110
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.372 for ONNX tensor: input.372
[04/25/2025-09:08:40] [V] [TRT] Conv_110 [Conv] outputs: [input.372 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Relu_111 [Relu]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.372
[04/25/2025-09:08:40] [V] [TRT] Relu_111 [Relu] inputs: [input.372 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Relu_111 for ONNX node: Relu_111
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.376 for ONNX tensor: input.376
[04/25/2025-09:08:40] [V] [TRT] Relu_111 [Relu] outputs: [input.376 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_112 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.376
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.2.vel.3.weight
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.2.vel.3.bias
[04/25/2025-09:08:40] [V] [TRT] Conv_112 [Conv] inputs: [input.376 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.2.vel.3.weight -> (2, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.2.vel.3.bias -> (2)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_112 for ONNX node: Conv_112
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 2, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: vel_2_17 for ONNX tensor: vel_2
[04/25/2025-09:08:40] [V] [TRT] Conv_112 [Conv] outputs: [vel_2 -> (1, 2, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_113 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_651
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_890
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_891
[04/25/2025-09:08:40] [V] [TRT] Conv_113 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_890 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_891 -> (64)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_113 for ONNX node: Conv_113
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.384 for ONNX tensor: input.384
[04/25/2025-09:08:40] [V] [TRT] Conv_113 [Conv] outputs: [input.384 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Relu_114 [Relu]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.384
[04/25/2025-09:08:40] [V] [TRT] Relu_114 [Relu] inputs: [input.384 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Relu_114 for ONNX node: Relu_114
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.388 for ONNX tensor: input.388
[04/25/2025-09:08:40] [V] [TRT] Relu_114 [Relu] outputs: [input.388 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_115 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.388
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.2.hm.3.weight
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.2.hm.3.bias
[04/25/2025-09:08:40] [V] [TRT] Conv_115 [Conv] inputs: [input.388 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.2.hm.3.weight -> (2, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.2.hm.3.bias -> (2)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_115 for ONNX node: Conv_115
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 2, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: hm_2_18 for ONNX tensor: hm_2
[04/25/2025-09:08:40] [V] [TRT] Conv_115 [Conv] outputs: [hm_2 -> (1, 2, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_116 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_651
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_893
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_894
[04/25/2025-09:08:40] [V] [TRT] Conv_116 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_893 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_894 -> (64)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_116 for ONNX node: Conv_116
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.396 for ONNX tensor: input.396
[04/25/2025-09:08:40] [V] [TRT] Conv_116 [Conv] outputs: [input.396 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Relu_117 [Relu]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.396
[04/25/2025-09:08:40] [V] [TRT] Relu_117 [Relu] inputs: [input.396 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Relu_117 for ONNX node: Relu_117
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.400 for ONNX tensor: input.400
[04/25/2025-09:08:40] [V] [TRT] Relu_117 [Relu] outputs: [input.400 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_118 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.400
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.3.reg.3.weight
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.3.reg.3.bias
[04/25/2025-09:08:40] [V] [TRT] Conv_118 [Conv] inputs: [input.400 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.3.reg.3.weight -> (2, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.3.reg.3.bias -> (2)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_118 for ONNX node: Conv_118
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 2, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: reg_3_19 for ONNX tensor: reg_3
[04/25/2025-09:08:40] [V] [TRT] Conv_118 [Conv] outputs: [reg_3 -> (1, 2, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_119 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_651
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_896
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_897
[04/25/2025-09:08:40] [V] [TRT] Conv_119 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_896 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_897 -> (64)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_119 for ONNX node: Conv_119
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.408 for ONNX tensor: input.408
[04/25/2025-09:08:40] [V] [TRT] Conv_119 [Conv] outputs: [input.408 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Relu_120 [Relu]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.408
[04/25/2025-09:08:40] [V] [TRT] Relu_120 [Relu] inputs: [input.408 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Relu_120 for ONNX node: Relu_120
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.412 for ONNX tensor: input.412
[04/25/2025-09:08:40] [V] [TRT] Relu_120 [Relu] outputs: [input.412 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_121 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.412
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.3.height.3.weight
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.3.height.3.bias
[04/25/2025-09:08:40] [V] [TRT] Conv_121 [Conv] inputs: [input.412 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.3.height.3.weight -> (1, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.3.height.3.bias -> (1)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_121 for ONNX node: Conv_121
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 1
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 1, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: height_3_20 for ONNX tensor: height_3
[04/25/2025-09:08:40] [V] [TRT] Conv_121 [Conv] outputs: [height_3 -> (1, 1, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_122 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_651
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_899
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_900
[04/25/2025-09:08:40] [V] [TRT] Conv_122 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_899 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_900 -> (64)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_122 for ONNX node: Conv_122
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.420 for ONNX tensor: input.420
[04/25/2025-09:08:40] [V] [TRT] Conv_122 [Conv] outputs: [input.420 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Relu_123 [Relu]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.420
[04/25/2025-09:08:40] [V] [TRT] Relu_123 [Relu] inputs: [input.420 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Relu_123 for ONNX node: Relu_123
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.424 for ONNX tensor: input.424
[04/25/2025-09:08:40] [V] [TRT] Relu_123 [Relu] outputs: [input.424 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_124 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.424
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.3.dim.3.weight
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.3.dim.3.bias
[04/25/2025-09:08:40] [V] [TRT] Conv_124 [Conv] inputs: [input.424 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.3.dim.3.weight -> (3, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.3.dim.3.bias -> (3)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_124 for ONNX node: Conv_124
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 3
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 3, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: dim_3_21 for ONNX tensor: dim_3
[04/25/2025-09:08:40] [V] [TRT] Conv_124 [Conv] outputs: [dim_3 -> (1, 3, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_125 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_651
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_902
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_903
[04/25/2025-09:08:40] [V] [TRT] Conv_125 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_902 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_903 -> (64)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_125 for ONNX node: Conv_125
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.432 for ONNX tensor: input.432
[04/25/2025-09:08:40] [V] [TRT] Conv_125 [Conv] outputs: [input.432 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Relu_126 [Relu]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.432
[04/25/2025-09:08:40] [V] [TRT] Relu_126 [Relu] inputs: [input.432 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Relu_126 for ONNX node: Relu_126
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.436 for ONNX tensor: input.436
[04/25/2025-09:08:40] [V] [TRT] Relu_126 [Relu] outputs: [input.436 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_127 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.436
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.3.rot.3.weight
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.3.rot.3.bias
[04/25/2025-09:08:40] [V] [TRT] Conv_127 [Conv] inputs: [input.436 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.3.rot.3.weight -> (2, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.3.rot.3.bias -> (2)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_127 for ONNX node: Conv_127
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 2, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: rot_3_22 for ONNX tensor: rot_3
[04/25/2025-09:08:40] [V] [TRT] Conv_127 [Conv] outputs: [rot_3 -> (1, 2, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_128 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_651
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_905
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_906
[04/25/2025-09:08:40] [V] [TRT] Conv_128 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_905 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_906 -> (64)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_128 for ONNX node: Conv_128
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.444 for ONNX tensor: input.444
[04/25/2025-09:08:40] [V] [TRT] Conv_128 [Conv] outputs: [input.444 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Relu_129 [Relu]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.444
[04/25/2025-09:08:40] [V] [TRT] Relu_129 [Relu] inputs: [input.444 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Relu_129 for ONNX node: Relu_129
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.448 for ONNX tensor: input.448
[04/25/2025-09:08:40] [V] [TRT] Relu_129 [Relu] outputs: [input.448 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_130 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.448
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.3.vel.3.weight
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.3.vel.3.bias
[04/25/2025-09:08:40] [V] [TRT] Conv_130 [Conv] inputs: [input.448 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.3.vel.3.weight -> (2, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.3.vel.3.bias -> (2)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_130 for ONNX node: Conv_130
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 2, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: vel_3_23 for ONNX tensor: vel_3
[04/25/2025-09:08:40] [V] [TRT] Conv_130 [Conv] outputs: [vel_3 -> (1, 2, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_131 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_651
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_908
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_909
[04/25/2025-09:08:40] [V] [TRT] Conv_131 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_908 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_909 -> (64)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_131 for ONNX node: Conv_131
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.456 for ONNX tensor: input.456
[04/25/2025-09:08:40] [V] [TRT] Conv_131 [Conv] outputs: [input.456 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Relu_132 [Relu]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.456
[04/25/2025-09:08:40] [V] [TRT] Relu_132 [Relu] inputs: [input.456 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Relu_132 for ONNX node: Relu_132
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.460 for ONNX tensor: input.460
[04/25/2025-09:08:40] [V] [TRT] Relu_132 [Relu] outputs: [input.460 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_133 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.460
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.3.hm.3.weight
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.3.hm.3.bias
[04/25/2025-09:08:40] [V] [TRT] Conv_133 [Conv] inputs: [input.460 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.3.hm.3.weight -> (1, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.3.hm.3.bias -> (1)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_133 for ONNX node: Conv_133
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 1
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 1, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: hm_3_24 for ONNX tensor: hm_3
[04/25/2025-09:08:40] [V] [TRT] Conv_133 [Conv] outputs: [hm_3 -> (1, 1, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_134 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_651
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_911
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_912
[04/25/2025-09:08:40] [V] [TRT] Conv_134 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_911 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_912 -> (64)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_134 for ONNX node: Conv_134
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.468 for ONNX tensor: input.468
[04/25/2025-09:08:40] [V] [TRT] Conv_134 [Conv] outputs: [input.468 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Relu_135 [Relu]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.468
[04/25/2025-09:08:40] [V] [TRT] Relu_135 [Relu] inputs: [input.468 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Relu_135 for ONNX node: Relu_135
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.472 for ONNX tensor: input.472
[04/25/2025-09:08:40] [V] [TRT] Relu_135 [Relu] outputs: [input.472 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_136 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.472
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.4.reg.3.weight
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.4.reg.3.bias
[04/25/2025-09:08:40] [V] [TRT] Conv_136 [Conv] inputs: [input.472 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.4.reg.3.weight -> (2, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.4.reg.3.bias -> (2)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_136 for ONNX node: Conv_136
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 2, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: reg_4_25 for ONNX tensor: reg_4
[04/25/2025-09:08:40] [V] [TRT] Conv_136 [Conv] outputs: [reg_4 -> (1, 2, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_137 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_651
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_914
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_915
[04/25/2025-09:08:40] [V] [TRT] Conv_137 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_914 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_915 -> (64)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_137 for ONNX node: Conv_137
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.480 for ONNX tensor: input.480
[04/25/2025-09:08:40] [V] [TRT] Conv_137 [Conv] outputs: [input.480 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Relu_138 [Relu]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.480
[04/25/2025-09:08:40] [V] [TRT] Relu_138 [Relu] inputs: [input.480 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Relu_138 for ONNX node: Relu_138
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.484 for ONNX tensor: input.484
[04/25/2025-09:08:40] [V] [TRT] Relu_138 [Relu] outputs: [input.484 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_139 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.484
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.4.height.3.weight
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.4.height.3.bias
[04/25/2025-09:08:40] [V] [TRT] Conv_139 [Conv] inputs: [input.484 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.4.height.3.weight -> (1, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.4.height.3.bias -> (1)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_139 for ONNX node: Conv_139
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 1
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 1, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: height_4_26 for ONNX tensor: height_4
[04/25/2025-09:08:40] [V] [TRT] Conv_139 [Conv] outputs: [height_4 -> (1, 1, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_140 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_651
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_917
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_918
[04/25/2025-09:08:40] [V] [TRT] Conv_140 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_917 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_918 -> (64)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_140 for ONNX node: Conv_140
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.492 for ONNX tensor: input.492
[04/25/2025-09:08:40] [V] [TRT] Conv_140 [Conv] outputs: [input.492 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Relu_141 [Relu]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.492
[04/25/2025-09:08:40] [V] [TRT] Relu_141 [Relu] inputs: [input.492 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Relu_141 for ONNX node: Relu_141
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.496 for ONNX tensor: input.496
[04/25/2025-09:08:40] [V] [TRT] Relu_141 [Relu] outputs: [input.496 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_142 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.496
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.4.dim.3.weight
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.4.dim.3.bias
[04/25/2025-09:08:40] [V] [TRT] Conv_142 [Conv] inputs: [input.496 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.4.dim.3.weight -> (3, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.4.dim.3.bias -> (3)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_142 for ONNX node: Conv_142
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 3
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 3, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: dim_4_27 for ONNX tensor: dim_4
[04/25/2025-09:08:40] [V] [TRT] Conv_142 [Conv] outputs: [dim_4 -> (1, 3, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_143 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_651
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_920
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_921
[04/25/2025-09:08:40] [V] [TRT] Conv_143 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_920 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_921 -> (64)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_143 for ONNX node: Conv_143
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.504 for ONNX tensor: input.504
[04/25/2025-09:08:40] [V] [TRT] Conv_143 [Conv] outputs: [input.504 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Relu_144 [Relu]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.504
[04/25/2025-09:08:40] [V] [TRT] Relu_144 [Relu] inputs: [input.504 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Relu_144 for ONNX node: Relu_144
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.508 for ONNX tensor: input.508
[04/25/2025-09:08:40] [V] [TRT] Relu_144 [Relu] outputs: [input.508 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_145 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.508
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.4.rot.3.weight
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.4.rot.3.bias
[04/25/2025-09:08:40] [V] [TRT] Conv_145 [Conv] inputs: [input.508 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.4.rot.3.weight -> (2, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.4.rot.3.bias -> (2)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_145 for ONNX node: Conv_145
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 2, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: rot_4_28 for ONNX tensor: rot_4
[04/25/2025-09:08:40] [V] [TRT] Conv_145 [Conv] outputs: [rot_4 -> (1, 2, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_146 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_651
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_923
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_924
[04/25/2025-09:08:40] [V] [TRT] Conv_146 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_923 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_924 -> (64)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_146 for ONNX node: Conv_146
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.516 for ONNX tensor: input.516
[04/25/2025-09:08:40] [V] [TRT] Conv_146 [Conv] outputs: [input.516 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Relu_147 [Relu]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.516
[04/25/2025-09:08:40] [V] [TRT] Relu_147 [Relu] inputs: [input.516 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Relu_147 for ONNX node: Relu_147
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.520 for ONNX tensor: input.520
[04/25/2025-09:08:40] [V] [TRT] Relu_147 [Relu] outputs: [input.520 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_148 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.520
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.4.vel.3.weight
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.4.vel.3.bias
[04/25/2025-09:08:40] [V] [TRT] Conv_148 [Conv] inputs: [input.520 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.4.vel.3.weight -> (2, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.4.vel.3.bias -> (2)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_148 for ONNX node: Conv_148
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 2, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: vel_4_29 for ONNX tensor: vel_4
[04/25/2025-09:08:40] [V] [TRT] Conv_148 [Conv] outputs: [vel_4 -> (1, 2, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_149 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_651
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_926
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_927
[04/25/2025-09:08:40] [V] [TRT] Conv_149 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_926 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_927 -> (64)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_149 for ONNX node: Conv_149
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.528 for ONNX tensor: input.528
[04/25/2025-09:08:40] [V] [TRT] Conv_149 [Conv] outputs: [input.528 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Relu_150 [Relu]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.528
[04/25/2025-09:08:40] [V] [TRT] Relu_150 [Relu] inputs: [input.528 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Relu_150 for ONNX node: Relu_150
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.532 for ONNX tensor: input.532
[04/25/2025-09:08:40] [V] [TRT] Relu_150 [Relu] outputs: [input.532 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_151 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.532
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.4.hm.3.weight
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.4.hm.3.bias
[04/25/2025-09:08:40] [V] [TRT] Conv_151 [Conv] inputs: [input.532 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.4.hm.3.weight -> (2, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.4.hm.3.bias -> (2)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_151 for ONNX node: Conv_151
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 2, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: hm_4_30 for ONNX tensor: hm_4
[04/25/2025-09:08:40] [V] [TRT] Conv_151 [Conv] outputs: [hm_4 -> (1, 2, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_152 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_651
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_929
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_930
[04/25/2025-09:08:40] [V] [TRT] Conv_152 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_929 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_930 -> (64)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_152 for ONNX node: Conv_152
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.540 for ONNX tensor: input.540
[04/25/2025-09:08:40] [V] [TRT] Conv_152 [Conv] outputs: [input.540 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Relu_153 [Relu]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.540
[04/25/2025-09:08:40] [V] [TRT] Relu_153 [Relu] inputs: [input.540 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Relu_153 for ONNX node: Relu_153
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.544 for ONNX tensor: input.544
[04/25/2025-09:08:40] [V] [TRT] Relu_153 [Relu] outputs: [input.544 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_154 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.544
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.5.reg.3.weight
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.5.reg.3.bias
[04/25/2025-09:08:40] [V] [TRT] Conv_154 [Conv] inputs: [input.544 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.5.reg.3.weight -> (2, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.5.reg.3.bias -> (2)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_154 for ONNX node: Conv_154
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 2, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: reg_5_31 for ONNX tensor: reg_5
[04/25/2025-09:08:40] [V] [TRT] Conv_154 [Conv] outputs: [reg_5 -> (1, 2, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_155 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_651
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_932
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_933
[04/25/2025-09:08:40] [V] [TRT] Conv_155 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_932 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_933 -> (64)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_155 for ONNX node: Conv_155
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.552 for ONNX tensor: input.552
[04/25/2025-09:08:40] [V] [TRT] Conv_155 [Conv] outputs: [input.552 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Relu_156 [Relu]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.552
[04/25/2025-09:08:40] [V] [TRT] Relu_156 [Relu] inputs: [input.552 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Relu_156 for ONNX node: Relu_156
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.556 for ONNX tensor: input.556
[04/25/2025-09:08:40] [V] [TRT] Relu_156 [Relu] outputs: [input.556 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_157 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.556
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.5.height.3.weight
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.5.height.3.bias
[04/25/2025-09:08:40] [V] [TRT] Conv_157 [Conv] inputs: [input.556 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.5.height.3.weight -> (1, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.5.height.3.bias -> (1)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_157 for ONNX node: Conv_157
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 1
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 1, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: height_5_32 for ONNX tensor: height_5
[04/25/2025-09:08:40] [V] [TRT] Conv_157 [Conv] outputs: [height_5 -> (1, 1, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_158 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_651
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_935
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_936
[04/25/2025-09:08:40] [V] [TRT] Conv_158 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_935 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_936 -> (64)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_158 for ONNX node: Conv_158
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.564 for ONNX tensor: input.564
[04/25/2025-09:08:40] [V] [TRT] Conv_158 [Conv] outputs: [input.564 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Relu_159 [Relu]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.564
[04/25/2025-09:08:40] [V] [TRT] Relu_159 [Relu] inputs: [input.564 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Relu_159 for ONNX node: Relu_159
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.568 for ONNX tensor: input.568
[04/25/2025-09:08:40] [V] [TRT] Relu_159 [Relu] outputs: [input.568 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_160 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.568
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.5.dim.3.weight
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.5.dim.3.bias
[04/25/2025-09:08:40] [V] [TRT] Conv_160 [Conv] inputs: [input.568 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.5.dim.3.weight -> (3, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.5.dim.3.bias -> (3)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_160 for ONNX node: Conv_160
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 3
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 3, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: dim_5_33 for ONNX tensor: dim_5
[04/25/2025-09:08:40] [V] [TRT] Conv_160 [Conv] outputs: [dim_5 -> (1, 3, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_161 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_651
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_938
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_939
[04/25/2025-09:08:40] [V] [TRT] Conv_161 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_938 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_939 -> (64)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_161 for ONNX node: Conv_161
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.576 for ONNX tensor: input.576
[04/25/2025-09:08:40] [V] [TRT] Conv_161 [Conv] outputs: [input.576 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Relu_162 [Relu]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.576
[04/25/2025-09:08:40] [V] [TRT] Relu_162 [Relu] inputs: [input.576 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Relu_162 for ONNX node: Relu_162
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.580 for ONNX tensor: input.580
[04/25/2025-09:08:40] [V] [TRT] Relu_162 [Relu] outputs: [input.580 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_163 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.580
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.5.rot.3.weight
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.5.rot.3.bias
[04/25/2025-09:08:40] [V] [TRT] Conv_163 [Conv] inputs: [input.580 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.5.rot.3.weight -> (2, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.5.rot.3.bias -> (2)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_163 for ONNX node: Conv_163
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 2, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: rot_5_34 for ONNX tensor: rot_5
[04/25/2025-09:08:40] [V] [TRT] Conv_163 [Conv] outputs: [rot_5 -> (1, 2, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_164 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_651
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_941
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_942
[04/25/2025-09:08:40] [V] [TRT] Conv_164 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_941 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_942 -> (64)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_164 for ONNX node: Conv_164
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.588 for ONNX tensor: input.588
[04/25/2025-09:08:40] [V] [TRT] Conv_164 [Conv] outputs: [input.588 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Relu_165 [Relu]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.588
[04/25/2025-09:08:40] [V] [TRT] Relu_165 [Relu] inputs: [input.588 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Relu_165 for ONNX node: Relu_165
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.592 for ONNX tensor: input.592
[04/25/2025-09:08:40] [V] [TRT] Relu_165 [Relu] outputs: [input.592 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_166 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.592
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.5.vel.3.weight
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.5.vel.3.bias
[04/25/2025-09:08:40] [V] [TRT] Conv_166 [Conv] inputs: [input.592 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.5.vel.3.weight -> (2, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.5.vel.3.bias -> (2)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_166 for ONNX node: Conv_166
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 2, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: vel_5_35 for ONNX tensor: vel_5
[04/25/2025-09:08:40] [V] [TRT] Conv_166 [Conv] outputs: [vel_5 -> (1, 2, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_167 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_651
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_944
[04/25/2025-09:08:40] [V] [TRT] Searching for input: onnx::Conv_945
[04/25/2025-09:08:40] [V] [TRT] Conv_167 [Conv] inputs: [onnx::Conv_651 -> (1, 64, 180, 180)[FLOAT]], [onnx::Conv_944 -> (64, 64, 3, 3)[FLOAT]], [onnx::Conv_945 -> (64)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_167 for ONNX node: Conv_167
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 64
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.600 for ONNX tensor: input.600
[04/25/2025-09:08:40] [V] [TRT] Conv_167 [Conv] outputs: [input.600 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Relu_168 [Relu]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.600
[04/25/2025-09:08:40] [V] [TRT] Relu_168 [Relu] inputs: [input.600 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Relu_168 for ONNX node: Relu_168
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: input.604 for ONNX tensor: input.604
[04/25/2025-09:08:40] [V] [TRT] Relu_168 [Relu] outputs: [input.604 -> (1, 64, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Parsing node: Conv_169 [Conv]
[04/25/2025-09:08:40] [V] [TRT] Searching for input: input.604
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.5.hm.3.weight
[04/25/2025-09:08:40] [V] [TRT] Searching for input: model.bbox_head.tasks.5.hm.3.bias
[04/25/2025-09:08:40] [V] [TRT] Conv_169 [Conv] inputs: [input.604 -> (1, 64, 180, 180)[FLOAT]], [model.bbox_head.tasks.5.hm.3.weight -> (2, 64, 3, 3)[FLOAT]], [model.bbox_head.tasks.5.hm.3.bias -> (2)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Convolution input dimensions: (1, 64, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering layer: Conv_169 for ONNX node: Conv_169
[04/25/2025-09:08:40] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (1, 1), postpadding: (1, 1), dilations: (1, 1), numOutputs: 2
[04/25/2025-09:08:40] [V] [TRT] Convolution output dimensions: (1, 2, 180, 180)
[04/25/2025-09:08:40] [V] [TRT] Registering tensor: hm_5_36 for ONNX tensor: hm_5
[04/25/2025-09:08:40] [V] [TRT] Conv_169 [Conv] outputs: [hm_5 -> (1, 2, 180, 180)[FLOAT]], 
[04/25/2025-09:08:40] [V] [TRT] Marking reg_0_1 as output: reg_0
[04/25/2025-09:08:40] [V] [TRT] Marking height_0_2 as output: height_0
[04/25/2025-09:08:40] [V] [TRT] Marking dim_0_3 as output: dim_0
[04/25/2025-09:08:40] [V] [TRT] Marking rot_0_4 as output: rot_0
[04/25/2025-09:08:40] [V] [TRT] Marking vel_0_5 as output: vel_0
[04/25/2025-09:08:40] [V] [TRT] Marking hm_0_6 as output: hm_0
[04/25/2025-09:08:40] [V] [TRT] Marking reg_1_7 as output: reg_1
[04/25/2025-09:08:40] [V] [TRT] Marking height_1_8 as output: height_1
[04/25/2025-09:08:40] [V] [TRT] Marking dim_1_9 as output: dim_1
[04/25/2025-09:08:40] [V] [TRT] Marking rot_1_10 as output: rot_1
[04/25/2025-09:08:40] [V] [TRT] Marking vel_1_11 as output: vel_1
[04/25/2025-09:08:40] [V] [TRT] Marking hm_1_12 as output: hm_1
[04/25/2025-09:08:40] [V] [TRT] Marking reg_2_13 as output: reg_2
[04/25/2025-09:08:40] [V] [TRT] Marking height_2_14 as output: height_2
[04/25/2025-09:08:40] [V] [TRT] Marking dim_2_15 as output: dim_2
[04/25/2025-09:08:40] [V] [TRT] Marking rot_2_16 as output: rot_2
[04/25/2025-09:08:40] [V] [TRT] Marking vel_2_17 as output: vel_2
[04/25/2025-09:08:40] [V] [TRT] Marking hm_2_18 as output: hm_2
[04/25/2025-09:08:40] [V] [TRT] Marking reg_3_19 as output: reg_3
[04/25/2025-09:08:40] [V] [TRT] Marking height_3_20 as output: height_3
[04/25/2025-09:08:40] [V] [TRT] Marking dim_3_21 as output: dim_3
[04/25/2025-09:08:40] [V] [TRT] Marking rot_3_22 as output: rot_3
[04/25/2025-09:08:40] [V] [TRT] Marking vel_3_23 as output: vel_3
[04/25/2025-09:08:40] [V] [TRT] Marking hm_3_24 as output: hm_3
[04/25/2025-09:08:40] [V] [TRT] Marking reg_4_25 as output: reg_4
[04/25/2025-09:08:40] [V] [TRT] Marking height_4_26 as output: height_4
[04/25/2025-09:08:40] [V] [TRT] Marking dim_4_27 as output: dim_4
[04/25/2025-09:08:40] [V] [TRT] Marking rot_4_28 as output: rot_4
[04/25/2025-09:08:40] [V] [TRT] Marking vel_4_29 as output: vel_4
[04/25/2025-09:08:40] [V] [TRT] Marking hm_4_30 as output: hm_4
[04/25/2025-09:08:40] [V] [TRT] Marking reg_5_31 as output: reg_5
[04/25/2025-09:08:40] [V] [TRT] Marking height_5_32 as output: height_5
[04/25/2025-09:08:40] [V] [TRT] Marking dim_5_33 as output: dim_5
[04/25/2025-09:08:40] [V] [TRT] Marking rot_5_34 as output: rot_5
[04/25/2025-09:08:40] [V] [TRT] Marking vel_5_35 as output: vel_5
[04/25/2025-09:08:40] [V] [TRT] Marking hm_5_36 as output: hm_5
[04/25/2025-09:08:40] [I] Finished parsing network model. Parse time: 0.14285
[04/25/2025-09:08:40] [V] [TRT] Original: 140 layers
[04/25/2025-09:08:40] [V] [TRT] After dead-layer removal: 140 layers
[04/25/2025-09:08:40] [V] [TRT] Graph construction completed in 0.00700069 seconds.
[04/25/2025-09:08:40] [V] [TRT] After Myelin optimization: 140 layers
[04/25/2025-09:08:40] [V] [TRT] Applying ScaleNodes fusions.
[04/25/2025-09:08:40] [V] [TRT] After scale fusion: 140 layers
[04/25/2025-09:08:40] [V] [TRT] Running: ConvReluFusion on Conv_15
[04/25/2025-09:08:40] [V] [TRT] ConvReluFusion: Fusing Conv_15 with Relu_16
[04/25/2025-09:08:40] [V] [TRT] Running: ConvReluFusion on Conv_17
[04/25/2025-09:08:40] [V] [TRT] ConvReluFusion: Fusing Conv_17 with Relu_18
[04/25/2025-09:08:40] [V] [TRT] Running: ConvReluFusion on Conv_19
[04/25/2025-09:08:40] [V] [TRT] ConvReluFusion: Fusing Conv_19 with Relu_20
[04/25/2025-09:08:40] [V] [TRT] Running: ConvReluFusion on Conv_21
[04/25/2025-09:08:40] [V] [TRT] ConvReluFusion: Fusing Conv_21 with Relu_22
[04/25/2025-09:08:40] [V] [TRT] Running: ConvReluFusion on Conv_23
[04/25/2025-09:08:40] [V] [TRT] ConvReluFusion: Fusing Conv_23 with Relu_24
[04/25/2025-09:08:40] [V] [TRT] Running: ConvReluFusion on Conv_25
[04/25/2025-09:08:40] [V] [TRT] ConvReluFusion: Fusing Conv_25 with Relu_26
[04/25/2025-09:08:40] [V] [TRT] Running: ConvReluFusion on Conv_27
[04/25/2025-09:08:40] [V] [TRT] ConvReluFusion: Fusing Conv_27 with Relu_28
[04/25/2025-09:08:40] [V] [TRT] Running: ConvReluFusion on Conv_44
[04/25/2025-09:08:40] [V] [TRT] ConvReluFusion: Fusing Conv_44 with Relu_45
[04/25/2025-09:08:40] [V] [TRT] Running: ConvReluFusion on Conv_46
[04/25/2025-09:08:40] [V] [TRT] ConvReluFusion: Fusing Conv_46 with Relu_47
[04/25/2025-09:08:40] [V] [TRT] Running: ConvReluFusion on Conv_48
[04/25/2025-09:08:40] [V] [TRT] ConvReluFusion: Fusing Conv_48 with Relu_49
[04/25/2025-09:08:40] [V] [TRT] Running: ConvReluFusion on Conv_50
[04/25/2025-09:08:40] [V] [TRT] ConvReluFusion: Fusing Conv_50 with Relu_51
[04/25/2025-09:08:40] [V] [TRT] Running: ConvReluFusion on Conv_52
[04/25/2025-09:08:40] [V] [TRT] ConvReluFusion: Fusing Conv_52 with Relu_53
[04/25/2025-09:08:40] [V] [TRT] Running: ConvReluFusion on Conv_54
[04/25/2025-09:08:40] [V] [TRT] ConvReluFusion: Fusing Conv_54 with Relu_55
[04/25/2025-09:08:40] [V] [TRT] Running: DeconvScaleFusion on ConvTranspose_56
[04/25/2025-09:08:40] [V] [TRT] DeconvScaleFusion: Fusing ConvTranspose_56 with BatchNormalization_57
[04/25/2025-09:08:40] [V] [TRT] Running: DeconvReluClipReluFusion on ConvTranspose_56 + BatchNormalization_57
[04/25/2025-09:08:40] [V] [TRT] DeconvReluClipReluFusion: Fusing ConvTranspose_56 + BatchNormalization_57 with Relu_58
[04/25/2025-09:08:40] [V] [TRT] Running: ConvReluFusion on Conv_60
[04/25/2025-09:08:40] [V] [TRT] ConvReluFusion: Fusing Conv_60 with Relu_61
[04/25/2025-09:08:40] [V] [TRT] Running: ConvReluFusion on Conv_62
[04/25/2025-09:08:40] [V] [TRT] ConvReluFusion: Fusing Conv_62 with Relu_63
[04/25/2025-09:08:40] [V] [TRT] Running: ConvReluFusion on Conv_65
[04/25/2025-09:08:40] [V] [TRT] ConvReluFusion: Fusing Conv_65 with Relu_66
[04/25/2025-09:08:40] [V] [TRT] Running: ConvReluFusion on Conv_68
[04/25/2025-09:08:40] [V] [TRT] ConvReluFusion: Fusing Conv_68 with Relu_69
[04/25/2025-09:08:40] [V] [TRT] Running: ConvReluFusion on Conv_71
[04/25/2025-09:08:40] [V] [TRT] ConvReluFusion: Fusing Conv_71 with Relu_72
[04/25/2025-09:08:40] [V] [TRT] Running: ConvReluFusion on Conv_74
[04/25/2025-09:08:40] [V] [TRT] ConvReluFusion: Fusing Conv_74 with Relu_75
[04/25/2025-09:08:40] [V] [TRT] Running: ConvReluFusion on Conv_77
[04/25/2025-09:08:40] [V] [TRT] ConvReluFusion: Fusing Conv_77 with Relu_78
[04/25/2025-09:08:40] [V] [TRT] Running: ConvReluFusion on Conv_80
[04/25/2025-09:08:40] [V] [TRT] ConvReluFusion: Fusing Conv_80 with Relu_81
[04/25/2025-09:08:40] [V] [TRT] Running: ConvReluFusion on Conv_83
[04/25/2025-09:08:40] [V] [TRT] ConvReluFusion: Fusing Conv_83 with Relu_84
[04/25/2025-09:08:40] [V] [TRT] Running: ConvReluFusion on Conv_86
[04/25/2025-09:08:40] [V] [TRT] ConvReluFusion: Fusing Conv_86 with Relu_87
[04/25/2025-09:08:40] [V] [TRT] Running: ConvReluFusion on Conv_89
[04/25/2025-09:08:40] [V] [TRT] ConvReluFusion: Fusing Conv_89 with Relu_90
[04/25/2025-09:08:40] [V] [TRT] Running: ConvReluFusion on Conv_92
[04/25/2025-09:08:40] [V] [TRT] ConvReluFusion: Fusing Conv_92 with Relu_93
[04/25/2025-09:08:40] [V] [TRT] Running: ConvReluFusion on Conv_95
[04/25/2025-09:08:40] [V] [TRT] ConvReluFusion: Fusing Conv_95 with Relu_96
[04/25/2025-09:08:40] [V] [TRT] Running: ConvReluFusion on Conv_98
[04/25/2025-09:08:40] [V] [TRT] ConvReluFusion: Fusing Conv_98 with Relu_99
[04/25/2025-09:08:40] [V] [TRT] Running: ConvReluFusion on Conv_101
[04/25/2025-09:08:40] [V] [TRT] ConvReluFusion: Fusing Conv_101 with Relu_102
[04/25/2025-09:08:40] [V] [TRT] Running: ConvReluFusion on Conv_104
[04/25/2025-09:08:40] [V] [TRT] ConvReluFusion: Fusing Conv_104 with Relu_105
[04/25/2025-09:08:40] [V] [TRT] Running: ConvReluFusion on Conv_107
[04/25/2025-09:08:40] [V] [TRT] ConvReluFusion: Fusing Conv_107 with Relu_108
[04/25/2025-09:08:40] [V] [TRT] Running: ConvReluFusion on Conv_110
[04/25/2025-09:08:40] [V] [TRT] ConvReluFusion: Fusing Conv_110 with Relu_111
[04/25/2025-09:08:40] [V] [TRT] Running: ConvReluFusion on Conv_113
[04/25/2025-09:08:40] [V] [TRT] ConvReluFusion: Fusing Conv_113 with Relu_114
[04/25/2025-09:08:40] [V] [TRT] Running: ConvReluFusion on Conv_116
[04/25/2025-09:08:40] [V] [TRT] ConvReluFusion: Fusing Conv_116 with Relu_117
[04/25/2025-09:08:40] [V] [TRT] Running: ConvReluFusion on Conv_119
[04/25/2025-09:08:40] [V] [TRT] ConvReluFusion: Fusing Conv_119 with Relu_120
[04/25/2025-09:08:40] [V] [TRT] Running: ConvReluFusion on Conv_122
[04/25/2025-09:08:40] [V] [TRT] ConvReluFusion: Fusing Conv_122 with Relu_123
[04/25/2025-09:08:40] [V] [TRT] Running: ConvReluFusion on Conv_125
[04/25/2025-09:08:40] [V] [TRT] ConvReluFusion: Fusing Conv_125 with Relu_126
[04/25/2025-09:08:40] [V] [TRT] Running: ConvReluFusion on Conv_128
[04/25/2025-09:08:40] [V] [TRT] ConvReluFusion: Fusing Conv_128 with Relu_129
[04/25/2025-09:08:40] [V] [TRT] Running: ConvReluFusion on Conv_131
[04/25/2025-09:08:40] [V] [TRT] ConvReluFusion: Fusing Conv_131 with Relu_132
[04/25/2025-09:08:40] [V] [TRT] Running: ConvReluFusion on Conv_134
[04/25/2025-09:08:40] [V] [TRT] ConvReluFusion: Fusing Conv_134 with Relu_135
[04/25/2025-09:08:40] [V] [TRT] Running: ConvReluFusion on Conv_137
[04/25/2025-09:08:40] [V] [TRT] ConvReluFusion: Fusing Conv_137 with Relu_138
[04/25/2025-09:08:40] [V] [TRT] Running: ConvReluFusion on Conv_140
[04/25/2025-09:08:40] [V] [TRT] ConvReluFusion: Fusing Conv_140 with Relu_141
[04/25/2025-09:08:40] [V] [TRT] Running: ConvReluFusion on Conv_143
[04/25/2025-09:08:40] [V] [TRT] ConvReluFusion: Fusing Conv_143 with Relu_144
[04/25/2025-09:08:40] [V] [TRT] Running: ConvReluFusion on Conv_146
[04/25/2025-09:08:40] [V] [TRT] ConvReluFusion: Fusing Conv_146 with Relu_147
[04/25/2025-09:08:40] [V] [TRT] Running: ConvReluFusion on Conv_149
[04/25/2025-09:08:40] [V] [TRT] ConvReluFusion: Fusing Conv_149 with Relu_150
[04/25/2025-09:08:40] [V] [TRT] Running: ConvReluFusion on Conv_152
[04/25/2025-09:08:40] [V] [TRT] ConvReluFusion: Fusing Conv_152 with Relu_153
[04/25/2025-09:08:40] [V] [TRT] Running: ConvReluFusion on Conv_155
[04/25/2025-09:08:40] [V] [TRT] ConvReluFusion: Fusing Conv_155 with Relu_156
[04/25/2025-09:08:40] [V] [TRT] Running: ConvReluFusion on Conv_158
[04/25/2025-09:08:40] [V] [TRT] ConvReluFusion: Fusing Conv_158 with Relu_159
[04/25/2025-09:08:40] [V] [TRT] Running: ConvReluFusion on Conv_161
[04/25/2025-09:08:40] [V] [TRT] ConvReluFusion: Fusing Conv_161 with Relu_162
[04/25/2025-09:08:40] [V] [TRT] Running: ConvReluFusion on Conv_164
[04/25/2025-09:08:40] [V] [TRT] ConvReluFusion: Fusing Conv_164 with Relu_165
[04/25/2025-09:08:40] [V] [TRT] Running: ConvReluFusion on Conv_167
[04/25/2025-09:08:40] [V] [TRT] ConvReluFusion: Fusing Conv_167 with Relu_168
[04/25/2025-09:08:40] [V] [TRT] After dupe layer removal: 88 layers
[04/25/2025-09:08:40] [V] [TRT] After final dead-layer removal: 88 layers
[04/25/2025-09:08:40] [V] [TRT] After tensor merging: 88 layers
[04/25/2025-09:08:40] [V] [TRT] After vertical fusions: 88 layers
[04/25/2025-09:08:40] [V] [TRT] After dupe layer removal: 88 layers
[04/25/2025-09:08:40] [V] [TRT] After final dead-layer removal: 88 layers
[04/25/2025-09:08:40] [V] [TRT] Merging conv layers: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168
[04/25/2025-09:08:40] [V] [TRT] After tensor merging: 53 layers
[04/25/2025-09:08:40] [V] [TRT] After slice removal: 53 layers
[04/25/2025-09:08:40] [V] [TRT] Eliminating concatenation Concat_59
[04/25/2025-09:08:40] [V] [TRT] Retargeting onnx::Concat_602 to input.164
[04/25/2025-09:08:40] [V] [TRT] Retargeting onnx::Concat_647 to input.164
[04/25/2025-09:08:40] [V] [TRT] After concat removal: 52 layers
[04/25/2025-09:08:40] [V] [TRT] Trying to split Reshape and strided tensor
[04/25/2025-09:08:40] [I] [TRT] Graph optimization time: 0.0173509 seconds.
[04/25/2025-09:08:40] [V] [TRT] Building graph using backend strategy 2
[04/25/2025-09:08:40] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored.
[04/25/2025-09:08:40] [V] [TRT] Constructing optimization profile number 0 [1/1].
[04/25/2025-09:08:40] [V] [TRT] Applying generic optimizations to the graph for inference.
[04/25/2025-09:08:41] [V] [TRT] Reserving memory for host IO tensors. Host: 0 bytes
[04/25/2025-09:08:41] [V] [TRT] =============== Computing costs for Conv_15 + Relu_16
[04/25/2025-09:08:41] [V] [TRT] *************** Autotuning format combination: Float(8294400,32400,180,1) -> Float(4147200,32400,180,1) ***************
[04/25/2025-09:08:41] [V] [TRT] --------------- Timing Runner: Conv_15 + Relu_16 (CaskConvolution[0x80000009])
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: 0xf067e6205da31c2e Time: 0.383415
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 0x5deb29b7a8e275f7 Time: 0.448805
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 0x503619c69ae500ff Time: 0.380197
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 0x3f243c490d502deb Time: 0.445733
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize1x4x1_g1_ffma_aligna4_alignc4_beta0_packed_stride Tactic: 0xede36641840ce3d2 Time: 0.504393
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xa9366041633a5135 Time: 0.768293
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP5_TQ5_C1_R3_S3_U1_V1 Tactic: 0x4165f9dd71b6e38a Time: 0.646437
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP4_TQ7_C4_R3_S3_U1_V1 Tactic: 0x753397072379d6e9 Time: 0.653312
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize4x1x1_g1_ffma_aligna4_alignc4_beta0_packed_stride Tactic: 0x1673e3594ce11cea Time: 0.54389
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_wngd_f32f32_f32_f32_nchwkcrs_nchw_tilesize8x16x32x8_warpsize8x1x1_wngd2x2 Tactic: 0xe47e164f4a743900 Time: 0.362789
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP7_TQ4_C1_R3_S3_U1_V1 Tactic: 0xe2f49879bec27b91 Time: 0.928914
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ5_C1_R3_S3_U1_V1 Tactic: 0x5ac6bfe0a27fc97b Time: 0.977481
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP4_TQ8_C1_R3_S3_U1_V1 Tactic: 0x36209b75daa96278 Time: 0.776923
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xcb8a43f748d8a338 Time: 0.864841
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP4_TQ7_C2_R3_S3_U1_V1 Tactic: 0x57c1b87347e45486 Time: 0.89205
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x5aa723e0481da855 Time: 0.38283
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP5_TQ7_C8_R3_S3_U1_V1 Tactic: 0x688222fe126a1c16 Time: 0.715337
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4_beta0_packed_stride Tactic: 0x7fc93550f5b9c127 Time: 0.392046
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec1_1_TP7_TQ8_C8_R3_S3_U1_V1 Tactic: 0x06cd3594e0105153 Time: 0.443977
[04/25/2025-09:08:41] [V] [TRT] Fast skip Tactic:0x40a12e3938221818 which exceed time limit during pre-run
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x40a12e3938221818 Time: 1.16429
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x01cf8ce2da913006 Time: 0.375662
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xb0bf940d5e0f9f45 Time: 0.687104
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xd828f024626fa982 Time: 0.536869
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP6_TQ5_C2_R3_S3_U1_V1 Tactic: 0x1e01f84aaf51153a Time: 0.68608
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize2x2x1_g1_ffma_aligna4_alignc4_beta0_packed_stride Tactic: 0x31aa67f57c5aea77 Time: 0.492105
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ8_C4_R3_S3_U1_V1 Tactic: 0x4bb6b59660d316a7 Time: 0.812032
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP4_TQ5_C2_R3_S3_U1_V1 Tactic: 0xed12ab640715a7d9 Time: 0.557349
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x9d9fdb5fd9945f64 Time: 0.760247
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x4efce38acc876f5c Time: 0.330313
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP4_TQ5_C1_R3_S3_U1_V1 Tactic: 0x193012cc899e2dab Time: 0.656384
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x4727434768e46395 Time: 0.44149
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec1_1_TP6_TQ8_C8_R3_S3_U1_V1 Tactic: 0xee473898b5318f6e Time: 0.450267
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_wngd_f32f32_f32_f32_nchwkcrs_nchw_tilesize8x16x16x8_warpsize8x1x1_wngd2x2 Tactic: 0xe38e9dfd56c33779 Time: 0.331483
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP8_TQ7_C4_R3_S3_U1_V1 Tactic: 0x372f7588455e8e60 Time: 0.769024
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP5_TQ7_C2_R3_S3_U1_V1 Tactic: 0xbf4bb57f12c58abb Time: 0.912091
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP4_TQ7_C1_R3_S3_U1_V1 Tactic: 0xfb8cf2d51feb56fa Time: 0.747666
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP4_TQ8_C2_R3_S3_U1_V1 Tactic: 0xc20222dd5422e80a Time: 0.636197
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP8_TQ5_C2_R3_S3_U1_V1 Tactic: 0x1fd1aff6cc3bef4c Time: 0.947195
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ7_C2_R3_S3_U1_V1 Tactic: 0xfc87004c17882844 Time: 0.846702
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP2_TQ5_C2_R3_S3_U1_V1 Tactic: 0x2947743108c340d8 Time: 0.523703
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 0x94119b4c514b211a Time: 0.256146
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: 0xa8609adc4e0ceb90 Time: 0.475721
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ6_C8_R3_S3_U1_V1 Tactic: 0x937cb0540b9a0c03 Time: 0.67584
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP5_TQ7_C4_R3_S3_U1_V1 Tactic: 0x2d667c16db5118c8 Time: 0.537161
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: 0xf64396b97c889179 Time: 0.423936
[04/25/2025-09:08:41] [V] [TRT] Fast skip Tactic:0x732164c3c1a336e7 which exceed time limit during pre-run
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ7_C8_R3_S3_U1_V1 Tactic: 0x732164c3c1a336e7 Time: 1.00966
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize4x1x1_g1_ffma_t1r3s3_aligna4_alignc4_beta0_packed_stride Tactic: 0xe640ceafd7d34ca9 Time: 0.541257
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ7_C4_R3_S3_U1_V1 Tactic: 0x861adc36a5912225 Time: 0.734793
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x12dbf7d94ee3696d Time: 0.375808
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x8ad32616b1424be4 Time: 0.686811
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize2x2x1_g1_ffma_t1r3s3_aligna4_alignc4_beta0_packed_stride Tactic: 0x3712e3e595645874 Time: 0.489618
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_wngd_f32f32_f32_f32_nchwkcrs_nchw_tilesize8x16x64x8_warpsize8x1x1_wngd2x2 Tactic: 0x0190806602534cfd Time: 0.246491
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP3_TQ7_C8_R3_S3_U1_V1 Tactic: 0xacd7fdab1dbcfb17 Time: 0.548425
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP8_TQ5_C4_R3_S3_U1_V1 Tactic: 0x654c738c7e22e52d Time: 0.838949
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP7_TQ3_C1_R3_S3_U1_V1 Tactic: 0xf40c46e2397ffca2 Time: 0.52619
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP2_TQ7_C2_R3_S3_U1_V1 Tactic: 0x7b24723533bf2b95 Time: 0.54901
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP5_TQ7_C4_R3_S3_U1_V1 Tactic: 0xc5d66905a0dc80da Time: 0.630345
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP5_TQ8_C8_R3_S3_U1_V1 Tactic: 0xfd41b85001aca09a Time: 0.739035
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ4_C1_R3_S3_U1_V1 Tactic: 0xba9b6b776846f39f Time: 0.886784
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP8_TQ5_C8_R3_S3_U1_V1 Tactic: 0x9077cb791a10f1ef Time: 0.710656
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP5_TQ7_C2_R3_S3_U1_V1 Tactic: 0xe7244671c44102b5 Time: 0.678912
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP5_TQ7_C4_R3_S3_U1_V1 Tactic: 0x9db99a0b765808d4 Time: 0.606354
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP7_TQ5_C1_R3_S3_U1_V1 Tactic: 0x02a94cee74fb4175 Time: 0.783067
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP4_TQ8_C4_R3_S3_U1_V1 Tactic: 0xb89ffea7e63be26b Time: 0.593774
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec1_1_TP4_TQ7_C1_R3_S3_U1_V1 Tactic: 0x1ba3392c2d9e8dc2 Time: 0.497518
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xa31d27de74b895ff Time: 0.557202
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP5_TQ7_C1_R3_S3_U1_V1 Tactic: 0x1306ffd94aca88c7 Time: 0.780873
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xbb8c3889c7eacd30 Time: 0.377271
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec1_1_TP6_TQ8_C2_R3_S3_U1_V1 Tactic: 0x61e15c17631a91cd Time: 0.42496
[04/25/2025-09:08:41] [V] [TRT] Conv_15 + Relu_16 (CaskConvolution[0x80000009]) profiling completed in 0.671133 seconds. Fastest Tactic: 0x0190806602534cfd Time: 0.246491
[04/25/2025-09:08:41] [V] [TRT] --------------- Timing Runner: Conv_15 + Relu_16 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:41] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:41] [V] [TRT] --------------- Timing Runner: Conv_15 + Relu_16 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:41] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:41] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x0190806602534cfd
[04/25/2025-09:08:41] [V] [TRT] *************** Autotuning format combination: Float(8294400,1,46080,256) -> Float(4147200,1,23040,128) ***************
[04/25/2025-09:08:41] [V] [TRT] --------------- Timing Runner: Conv_15 + Relu_16 (CaskConvolution[0x80000009])
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x3f0c846d6379bc98 Time: 0.672183
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x19b688348f983aa0 Time: 0.632101
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0xf48db81f02eca9ee Time: 0.471333
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x92ed3100c35fc43e Time: 0.732745
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x5953bec563d26434 Time: 0.903022
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x8014228ec08b4d49 Time: 0.306176
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x1da91d865428f237 Time: 0.342894
[04/25/2025-09:08:41] [V] [TRT] Fast skip Tactic:0x4fd3c46622e98342 which exceed time limit during pre-run
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x4fd3c46622e98342 Time: 1.10899
[04/25/2025-09:08:41] [V] [TRT] Fast skip Tactic:0x32059de4888dfdda which exceed time limit during pre-run
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x32059de4888dfdda Time: 1.26464
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x7121ec1db3f80c67 Time: 0.898926
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0xd15dd11d64344e83 Time: 0.340407
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x0a143be7a52f301a Time: 0.893952
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x62835fce994f06dd Time: 0.566126
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xa6448a1e79f1ca6f Time: 0.662821
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x94a7db94ba744c45 Time: 0.413257
[04/25/2025-09:08:41] [V] [TRT] Conv_15 + Relu_16 (CaskConvolution[0x80000009]) profiling completed in 0.106767 seconds. Fastest Tactic: 0x8014228ec08b4d49 Time: 0.306176
[04/25/2025-09:08:41] [V] [TRT] --------------- Timing Runner: Conv_15 + Relu_16 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:41] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:41] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x8014228ec08b4d49
[04/25/2025-09:08:41] [V] [TRT] *************** Autotuning format combination: Float(2073600,1:4,11520,64) -> Float(4147200,32400,180,1) ***************
[04/25/2025-09:08:41] [V] [TRT] --------------- Timing Runner: Conv_15 + Relu_16 (CaskConvolution[0x80000009])
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 0x9787b83bedcff6a2 Time: 0.244736
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_alignc4 Tactic: 0xe8f7b6a5bab325f8 Time: 0.255415
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_alignc4 Tactic: 0x9fd9fe001908ce2e Time: 0.244151
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0xe0a307ffe0ffb6a5 Time: 0.250587
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3_alignc4 Tactic: 0x1323e48791e2f671 Time: 0.239616
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0x3104d85fecdd547c Time: 0.234642
[04/25/2025-09:08:41] [V] [TRT] Conv_15 + Relu_16 (CaskConvolution[0x80000009]) profiling completed in 0.0217636 seconds. Fastest Tactic: 0x3104d85fecdd547c Time: 0.234642
[04/25/2025-09:08:41] [V] [TRT] --------------- Timing Runner: Conv_15 + Relu_16 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:41] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:41] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x3104d85fecdd547c
[04/25/2025-09:08:41] [V] [TRT] *************** Autotuning format combination: Float(2073600,1:4,11520,64) -> Float(1036800,1:4,5760,32) ***************
[04/25/2025-09:08:41] [V] [TRT] --------------- Timing Runner: Conv_15 + Relu_16 (CaskConvolution[0x80000009])
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 0xbdfdef6b84f7ccc9 Time: 0.392192
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0x3e2b881168d9689d Time: 0.415305
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0xf90060ce8193b811 Time: 0.456558
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x7bc32c782b800c48 Time: 0.430373
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0xb443c221fcb1565b Time: 0.235813
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 0x999e005e3b016ea6 Time: 0.231278
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0x65e41d81f093b482 Time: 0.245906
[04/25/2025-09:08:41] [V] [TRT] Conv_15 + Relu_16 (CaskConvolution[0x80000009]) profiling completed in 0.0347636 seconds. Fastest Tactic: 0x999e005e3b016ea6 Time: 0.231278
[04/25/2025-09:08:41] [V] [TRT] --------------- Timing Runner: Conv_15 + Relu_16 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:41] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:41] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x999e005e3b016ea6
[04/25/2025-09:08:41] [V] [TRT] *************** Autotuning format combination: Half(8294400,32400,180,1) -> Half(4147200,32400,180,1) ***************
[04/25/2025-09:08:41] [V] [TRT] --------------- Timing Runner: Conv_15 + Relu_16 (CaskConvolution[0x80000009])
[04/25/2025-09:08:41] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:41] [V] [TRT] --------------- Timing Runner: Conv_15 + Relu_16 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:41] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:41] [V] [TRT] --------------- Timing Runner: Conv_15 + Relu_16 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:41] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:41] [V] [TRT] *************** Autotuning format combination: Half(4147200,1:2,23040,128) -> Half(2073600,1:2,11520,64) ***************
[04/25/2025-09:08:41] [V] [TRT] --------------- Timing Runner: Conv_15 + Relu_16 (CaskConvolution[0x80000009])
[04/25/2025-09:08:41] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:41] [V] [TRT] --------------- Timing Runner: Conv_15 + Relu_16 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:41] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:41] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:4,11520,64) -> Half(1036800,1:4,5760,32) ***************
[04/25/2025-09:08:41] [V] [TRT] --------------- Timing Runner: Conv_15 + Relu_16 (CaskConvolution[0x80000009])
[04/25/2025-09:08:41] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:41] [V] [TRT] --------------- Timing Runner: Conv_15 + Relu_16 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:41] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:41] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:8,5760,32) -> Float(4147200,32400,180,1) ***************
[04/25/2025-09:08:41] [V] [TRT] --------------- Timing Runner: Conv_15 + Relu_16 (CaskConvolution[0x80000009])
[04/25/2025-09:08:41] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:41] [V] [TRT] --------------- Timing Runner: Conv_15 + Relu_16 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:41] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:41] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:8,5760,32) -> Half(518400,1:8,2880,16) ***************
[04/25/2025-09:08:41] [V] [TRT] --------------- Timing Runner: Conv_15 + Relu_16 (CaskConvolution[0x80000009])
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xdce100b9fe609424 Time: 0.143067
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xa9177bbe4e767df8 Time: 0.117102
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x05b6220f243edacd Time: 0.100425
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 0x60da8c7151d91e47 Time: 0.0616351
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xdfa020ef435ef810 Time: 0.0720457
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_wngd_f16f16_f16_f16_nhwckrsc_nhwc_tilesize8x16x32x32_warpsize8x1x1_wngd2x2 Tactic: 0xded5318b4a444b84 Time: 0.128439
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x5568fd8a32f4a40f Time: 0.10101
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xc0a02dc6095497cc Time: 0.0732823
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xb4bec086187edcfc Time: 0.0984503
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x57c9a5ff682354a6 Time: 0.0738011
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xdb0b80f591d1bb6d Time: 0.103936
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x31d93dc22d2af081 Time: 0.132242
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x5820b3dda403c4d0 Time: 0.192658
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 0xb17d53d15dfbfc9e Time: 0.0633417
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x21b295c0c8f6c95a Time: 0.101083
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xe1ff5ad20f5c6bf6 Time: 0.191634
[04/25/2025-09:08:41] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xbd08239a9317f2fd Time: 0.0991086
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3_aACCESS Tactic: 0x0866ddee325d07a6 Time: 0.0723383
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xa570c55d303796ff Time: 0.0836023
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x4a81ea1e51436a30 Time: 0.131145
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x0e07ff4f4f7c1ac9 Time: 0.0723383
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xc9d24bd069159fa8 Time: 0.0989623
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3_aACCESS Tactic: 0x263a38afd75e3a43 Time: 0.072192
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x60c3421152ef8e10 Time: 0.0722651
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: 0xa1a20ea714d420f4 Time: 0.117175
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xf79479a62ea9f901 Time: 0.155794
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xa83b68f30462f971 Time: 0.143497
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0x834e11ecd4ab9454 Time: 0.156818
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_wngd_f16f16_f16_f16_nhwckrsc_nhwc_tilesize16x16x64x16_warpsize8x1x1_wngd2x2 Tactic: 0xe29800439b9d3cf7 Time: 0.116736
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: 0x7005d10718f6c22d Time: 0.119655
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xd1aaad17ca35fbaa Time: 0.0838949
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3_aACCESS Tactic: 0x245530c34bd6090f Time: 0.0642194
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x1x2_g1_tensor16x8x16_aACCESS Tactic: 0x841c601dec2a75bc Time: 0.0950126
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3_aACCESS Tactic: 0x30e8a8d7a953e5e9 Time: 0.0945737
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x048d6d0400f33439 Time: 0.0617326
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xafd1e8bf6bd3d638 Time: 0.10379
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xf35e0311fa1cc516 Time: 0.132535
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x529f4431bdae94f5 Time: 0.0838217
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xa40cb43c296a36a8 Time: 0.143506
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x3e7eb35b91b9fa63 Time: 0.156672
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage4_warpsize2x1x2_g1_tensor16x8x16 Tactic: 0x7273dde1d0cd3bd5 Time: 0.102107
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x17ebf0c9f418f10a Time: 0.10408
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xa033e20ae9f412b2 Time: 0.190903
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x866e7a5f6401b67f Time: 0.0740937
[04/25/2025-09:08:42] [V] [TRT] Conv_15 + Relu_16 (CaskConvolution[0x80000009]) profiling completed in 0.121266 seconds. Fastest Tactic: 0x60da8c7151d91e47 Time: 0.0616351
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_15 + Relu_16 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:42] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:42] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x60da8c7151d91e47
[04/25/2025-09:08:42] [V] [TRT] =============== Computing costs for Conv_17 + Relu_18
[04/25/2025-09:08:42] [V] [TRT] *************** Autotuning format combination: Float(4147200,32400,180,1) -> Float(4147200,32400,180,1) ***************
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_17 + Relu_18 (CaskConvolution[0x80000009])
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: 0xf067e6205da31c2e Time: 0.205824
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 0x5deb29b7a8e275f7 Time: 0.216649
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 0x503619c69ae500ff Time: 0.205678
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 0x3f243c490d502deb Time: 0.208896
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize1x4x1_g1_ffma_aligna4_alignc4_beta0_packed_stride Tactic: 0xede36641840ce3d2 Time: 0.235813
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xa9366041633a5135 Time: 0.356352
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP5_TQ5_C1_R3_S3_U1_V1 Tactic: 0x4165f9dd71b6e38a Time: 0.319781
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP4_TQ7_C4_R3_S3_U1_V1 Tactic: 0x753397072379d6e9 Time: 0.322999
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize4x1x1_g1_ffma_aligna4_alignc4_beta0_packed_stride Tactic: 0x1673e3594ce11cea Time: 0.252635
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_wngd_f32f32_f32_f32_nchwkcrs_nchw_tilesize8x16x32x8_warpsize8x1x1_wngd2x2 Tactic: 0xe47e164f4a743900 Time: 0.157257
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP7_TQ4_C1_R3_S3_U1_V1 Tactic: 0xe2f49879bec27b91 Time: 0.478062
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ5_C1_R3_S3_U1_V1 Tactic: 0x5ac6bfe0a27fc97b Time: 0.485522
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP4_TQ8_C1_R3_S3_U1_V1 Tactic: 0x36209b75daa96278 Time: 0.392631
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xcb8a43f748d8a338 Time: 0.414866
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP4_TQ7_C2_R3_S3_U1_V1 Tactic: 0x57c1b87347e45486 Time: 0.437833
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x5aa723e0481da855 Time: 0.216942
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP5_TQ7_C8_R3_S3_U1_V1 Tactic: 0x688222fe126a1c16 Time: 0.359424
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4_beta0_packed_stride Tactic: 0x7fc93550f5b9c127 Time: 0.221623
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec1_1_TP7_TQ8_C8_R3_S3_U1_V1 Tactic: 0x06cd3594e0105153 Time: 0.231259
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x40a12e3938221818 Time: 0.53877
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x01cf8ce2da913006 Time: 0.213285
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xb0bf940d5e0f9f45 Time: 0.340261
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xd828f024626fa982 Time: 0.274139
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP6_TQ5_C2_R3_S3_U1_V1 Tactic: 0x1e01f84aaf51153a Time: 0.355913
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize2x2x1_g1_ffma_aligna4_alignc4_beta0_packed_stride Tactic: 0x31aa67f57c5aea77 Time: 0.22923
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ8_C4_R3_S3_U1_V1 Tactic: 0x4bb6b59660d316a7 Time: 0.398336
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP4_TQ5_C2_R3_S3_U1_V1 Tactic: 0xed12ab640715a7d9 Time: 0.296521
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x9d9fdb5fd9945f64 Time: 0.356645
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x4efce38acc876f5c Time: 0.183003
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP4_TQ5_C1_R3_S3_U1_V1 Tactic: 0x193012cc899e2dab Time: 0.382098
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x4727434768e46395 Time: 0.298423
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec1_1_TP6_TQ8_C8_R3_S3_U1_V1 Tactic: 0xee473898b5318f6e Time: 0.23435
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_wngd_f32f32_f32_f32_nchwkcrs_nchw_tilesize8x16x16x8_warpsize8x1x1_wngd2x2 Tactic: 0xe38e9dfd56c33779 Time: 0.170862
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP8_TQ7_C4_R3_S3_U1_V1 Tactic: 0x372f7588455e8e60 Time: 0.379173
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP5_TQ7_C2_R3_S3_U1_V1 Tactic: 0xbf4bb57f12c58abb Time: 0.423936
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP4_TQ7_C1_R3_S3_U1_V1 Tactic: 0xfb8cf2d51feb56fa Time: 0.419401
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP4_TQ8_C2_R3_S3_U1_V1 Tactic: 0xc20222dd5422e80a Time: 0.349623
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP8_TQ5_C2_R3_S3_U1_V1 Tactic: 0x1fd1aff6cc3bef4c Time: 0.543451
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ7_C2_R3_S3_U1_V1 Tactic: 0xfc87004c17882844 Time: 0.456704
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP2_TQ5_C2_R3_S3_U1_V1 Tactic: 0x2947743108c340d8 Time: 0.289792
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 0x94119b4c514b211a Time: 0.136046
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: 0xa8609adc4e0ceb90 Time: 0.242103
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ6_C8_R3_S3_U1_V1 Tactic: 0x937cb0540b9a0c03 Time: 0.366446
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP5_TQ7_C4_R3_S3_U1_V1 Tactic: 0x2d667c16db5118c8 Time: 0.319195
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: 0xf64396b97c889179 Time: 0.215771
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ7_C8_R3_S3_U1_V1 Tactic: 0x732164c3c1a336e7 Time: 0.5632
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize4x1x1_g1_ffma_t1r3s3_aligna4_alignc4_beta0_packed_stride Tactic: 0xe640ceafd7d34ca9 Time: 0.25717
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ7_C4_R3_S3_U1_V1 Tactic: 0x861adc36a5912225 Time: 0.393947
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x12dbf7d94ee3696d Time: 0.194414
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x8ad32616b1424be4 Time: 0.343479
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize2x2x1_g1_ffma_t1r3s3_aligna4_alignc4_beta0_packed_stride Tactic: 0x3712e3e595645874 Time: 0.232448
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_wngd_f32f32_f32_f32_nchwkcrs_nchw_tilesize8x16x64x8_warpsize8x1x1_wngd2x2 Tactic: 0x0190806602534cfd Time: 0.132096
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP3_TQ7_C8_R3_S3_U1_V1 Tactic: 0xacd7fdab1dbcfb17 Time: 0.27136
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP8_TQ5_C4_R3_S3_U1_V1 Tactic: 0x654c738c7e22e52d Time: 0.441783
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP7_TQ3_C1_R3_S3_U1_V1 Tactic: 0xf40c46e2397ffca2 Time: 0.298715
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP2_TQ7_C2_R3_S3_U1_V1 Tactic: 0x7b24723533bf2b95 Time: 0.305006
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP5_TQ7_C4_R3_S3_U1_V1 Tactic: 0xc5d66905a0dc80da Time: 0.346405
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP5_TQ8_C8_R3_S3_U1_V1 Tactic: 0xfd41b85001aca09a Time: 0.382245
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ4_C1_R3_S3_U1_V1 Tactic: 0xba9b6b776846f39f Time: 0.483035
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP8_TQ5_C8_R3_S3_U1_V1 Tactic: 0x9077cb791a10f1ef Time: 0.38005
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP5_TQ7_C2_R3_S3_U1_V1 Tactic: 0xe7244671c44102b5 Time: 0.383122
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP5_TQ7_C4_R3_S3_U1_V1 Tactic: 0x9db99a0b765808d4 Time: 0.313051
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP7_TQ5_C1_R3_S3_U1_V1 Tactic: 0x02a94cee74fb4175 Time: 0.468407
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP4_TQ8_C4_R3_S3_U1_V1 Tactic: 0xb89ffea7e63be26b Time: 0.32651
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec1_1_TP4_TQ7_C1_R3_S3_U1_V1 Tactic: 0x1ba3392c2d9e8dc2 Time: 0.276919
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xa31d27de74b895ff Time: 0.304713
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP5_TQ7_C1_R3_S3_U1_V1 Tactic: 0x1306ffd94aca88c7 Time: 0.428032
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xbb8c3889c7eacd30 Time: 0.18827
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec1_1_TP6_TQ8_C2_R3_S3_U1_V1 Tactic: 0x61e15c17631a91cd Time: 0.247808
[04/25/2025-09:08:42] [V] [TRT] Conv_17 + Relu_18 (CaskConvolution[0x80000009]) profiling completed in 0.324037 seconds. Fastest Tactic: 0x0190806602534cfd Time: 0.132096
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_17 + Relu_18 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:42] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_17 + Relu_18 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:42] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:42] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x0190806602534cfd
[04/25/2025-09:08:42] [V] [TRT] *************** Autotuning format combination: Float(4147200,1,23040,128) -> Float(4147200,1,23040,128) ***************
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_17 + Relu_18 (CaskConvolution[0x80000009])
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x3f0c846d6379bc98 Time: 0.339822
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x19b688348f983aa0 Time: 0.319049
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0xf48db81f02eca9ee Time: 0.243566
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x92ed3100c35fc43e Time: 0.376539
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x5953bec563d26434 Time: 0.433591
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x8014228ec08b4d49 Time: 0.218853
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x1da91d865428f237 Time: 0.233326
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x4fd3c46622e98342 Time: 0.555886
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x32059de4888dfdda Time: 0.557202
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x7121ec1db3f80c67 Time: 0.444855
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0xd15dd11d64344e83 Time: 0.204357
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x0a143be7a52f301a Time: 0.449097
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x62835fce994f06dd Time: 0.277065
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xa6448a1e79f1ca6f Time: 0.307346
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x94a7db94ba744c45 Time: 0.28555
[04/25/2025-09:08:42] [V] [TRT] Conv_17 + Relu_18 (CaskConvolution[0x80000009]) profiling completed in 0.0707654 seconds. Fastest Tactic: 0xd15dd11d64344e83 Time: 0.204357
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_17 + Relu_18 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:42] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:42] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xd15dd11d64344e83
[04/25/2025-09:08:42] [V] [TRT] *************** Autotuning format combination: Float(1036800,1:4,5760,32) -> Float(4147200,32400,180,1) ***************
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_17 + Relu_18 (CaskConvolution[0x80000009])
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 0x9787b83bedcff6a2 Time: 0.124562
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_alignc4 Tactic: 0xe8f7b6a5bab325f8 Time: 0.130853
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_alignc4 Tactic: 0x9fd9fe001908ce2e Time: 0.124709
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0xe0a307ffe0ffb6a5 Time: 0.127488
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3_alignc4 Tactic: 0x1323e48791e2f671 Time: 0.122587
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0x3104d85fecdd547c Time: 0.123465
[04/25/2025-09:08:42] [V] [TRT] Conv_17 + Relu_18 (CaskConvolution[0x80000009]) profiling completed in 0.0199534 seconds. Fastest Tactic: 0x1323e48791e2f671 Time: 0.122587
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_17 + Relu_18 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:42] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:42] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x1323e48791e2f671
[04/25/2025-09:08:42] [V] [TRT] *************** Autotuning format combination: Float(1036800,1:4,5760,32) -> Float(1036800,1:4,5760,32) ***************
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_17 + Relu_18 (CaskConvolution[0x80000009])
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 0xbdfdef6b84f7ccc9 Time: 0.200119
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0x3e2b881168d9689d Time: 0.213577
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0xf90060ce8193b811 Time: 0.213138
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x7bc32c782b800c48 Time: 0.21899
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0xb443c221fcb1565b Time: 0.123831
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 0x999e005e3b016ea6 Time: 0.121125
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0x65e41d81f093b482 Time: 0.128366
[04/25/2025-09:08:42] [V] [TRT] Conv_17 + Relu_18 (CaskConvolution[0x80000009]) profiling completed in 0.0228828 seconds. Fastest Tactic: 0x999e005e3b016ea6 Time: 0.121125
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_17 + Relu_18 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:42] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:42] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x999e005e3b016ea6
[04/25/2025-09:08:42] [V] [TRT] *************** Autotuning format combination: Half(4147200,32400,180,1) -> Half(4147200,32400,180,1) ***************
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_17 + Relu_18 (CaskConvolution[0x80000009])
[04/25/2025-09:08:42] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_17 + Relu_18 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:42] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_17 + Relu_18 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:42] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:42] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:2,11520,64) -> Half(2073600,1:2,11520,64) ***************
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_17 + Relu_18 (CaskConvolution[0x80000009])
[04/25/2025-09:08:42] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_17 + Relu_18 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:42] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:42] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:4,5760,32) -> Half(1036800,1:4,5760,32) ***************
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_17 + Relu_18 (CaskConvolution[0x80000009])
[04/25/2025-09:08:42] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_17 + Relu_18 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:42] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:42] [V] [TRT] *************** Autotuning format combination: Half(518400,1:8,2880,16) -> Float(4147200,32400,180,1) ***************
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_17 + Relu_18 (CaskConvolution[0x80000009])
[04/25/2025-09:08:42] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_17 + Relu_18 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:42] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:42] [V] [TRT] *************** Autotuning format combination: Half(518400,1:8,2880,16) -> Half(518400,1:8,2880,16) ***************
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_17 + Relu_18 (CaskConvolution[0x80000009])
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xdce100b9fe609424 Time: 0.0729966
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xa9177bbe4e767df8 Time: 0.0625128
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x05b6220f243edacd Time: 0.0538331
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 0x60da8c7151d91e47 Time: 0.0346121
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xdfa020ef435ef810 Time: 0.0380697
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_wngd_f16f16_f16_f16_nhwckrsc_nhwc_tilesize8x16x32x32_warpsize8x1x1_wngd2x2 Tactic: 0xded5318b4a444b84 Time: 0.0717531
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x5568fd8a32f4a40f Time: 0.0542232
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xc0a02dc6095497cc Time: 0.0397166
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xb4bec086187edcfc Time: 0.0512488
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x57c9a5ff682354a6 Time: 0.0398994
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xdb0b80f591d1bb6d Time: 0.0512
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x31d93dc22d2af081 Time: 0.068803
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x5820b3dda403c4d0 Time: 0.104375
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 0xb17d53d15dfbfc9e Time: 0.0353719
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x21b295c0c8f6c95a Time: 0.0536869
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xe1ff5ad20f5c6bf6 Time: 0.101669
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xbd08239a9317f2fd Time: 0.0517364
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3_aACCESS Tactic: 0x0866ddee325d07a6 Time: 0.0394606
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xa570c55d303796ff Time: 0.0433006
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x4a81ea1e51436a30 Time: 0.0680229
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x0e07ff4f4f7c1ac9 Time: 0.0382903
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xc9d24bd069159fa8 Time: 0.0515901
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3_aACCESS Tactic: 0x263a38afd75e3a43 Time: 0.0403383
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x60c3421152ef8e10 Time: 0.0372663
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: 0xa1a20ea714d420f4 Time: 0.062659
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xf79479a62ea9f901 Time: 0.0782629
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xa83b68f30462f971 Time: 0.0734354
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0x834e11ecd4ab9454 Time: 0.078848
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_wngd_f16f16_f16_f16_nhwckrsc_nhwc_tilesize16x16x64x16_warpsize8x1x1_wngd2x2 Tactic: 0xe29800439b9d3cf7 Time: 0.0616351
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: 0x7005d10718f6c22d Time: 0.0637806
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xd1aaad17ca35fbaa Time: 0.04352
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3_aACCESS Tactic: 0x245530c34bd6090f Time: 0.0363154
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x1x2_g1_tensor16x8x16_aACCESS Tactic: 0x841c601dec2a75bc Time: 0.0517851
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3_aACCESS Tactic: 0x30e8a8d7a953e5e9 Time: 0.0514926
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x048d6d0400f33439 Time: 0.0345527
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xafd1e8bf6bd3d638 Time: 0.0509074
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xf35e0311fa1cc516 Time: 0.0692419
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x529f4431bdae94f5 Time: 0.0433006
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xa40cb43c296a36a8 Time: 0.0732823
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x3e7eb35b91b9fa63 Time: 0.0781166
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage4_warpsize2x1x2_g1_tensor16x8x16 Tactic: 0x7273dde1d0cd3bd5 Time: 0.0547124
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x17ebf0c9f418f10a Time: 0.0508587
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xa033e20ae9f412b2 Time: 0.102181
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x866e7a5f6401b67f Time: 0.0396069
[04/25/2025-09:08:42] [V] [TRT] Conv_17 + Relu_18 (CaskConvolution[0x80000009]) profiling completed in 0.10343 seconds. Fastest Tactic: 0x048d6d0400f33439 Time: 0.0345527
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_17 + Relu_18 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:42] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:42] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x048d6d0400f33439
[04/25/2025-09:08:42] [V] [TRT] =============== Computing costs for Conv_19 + Relu_20
[04/25/2025-09:08:42] [V] [TRT] *************** Autotuning format combination: Float(4147200,32400,180,1) -> Float(4147200,32400,180,1) ***************
[04/25/2025-09:08:42] [V] [TRT] *************** Autotuning format combination: Float(4147200,1,23040,128) -> Float(4147200,1,23040,128) ***************
[04/25/2025-09:08:42] [V] [TRT] *************** Autotuning format combination: Float(1036800,1:4,5760,32) -> Float(4147200,32400,180,1) ***************
[04/25/2025-09:08:42] [V] [TRT] *************** Autotuning format combination: Float(1036800,1:4,5760,32) -> Float(1036800,1:4,5760,32) ***************
[04/25/2025-09:08:42] [V] [TRT] *************** Autotuning format combination: Half(4147200,32400,180,1) -> Half(4147200,32400,180,1) ***************
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_19 + Relu_20 (CaskConvolution[0x80000009])
[04/25/2025-09:08:42] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_19 + Relu_20 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:42] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_19 + Relu_20 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:42] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:42] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:2,11520,64) -> Half(2073600,1:2,11520,64) ***************
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_19 + Relu_20 (CaskConvolution[0x80000009])
[04/25/2025-09:08:42] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_19 + Relu_20 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:42] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:42] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:4,5760,32) -> Half(1036800,1:4,5760,32) ***************
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_19 + Relu_20 (CaskConvolution[0x80000009])
[04/25/2025-09:08:42] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_19 + Relu_20 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:42] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:42] [V] [TRT] *************** Autotuning format combination: Half(518400,1:8,2880,16) -> Float(4147200,32400,180,1) ***************
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_19 + Relu_20 (CaskConvolution[0x80000009])
[04/25/2025-09:08:42] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_19 + Relu_20 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:42] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:42] [V] [TRT] *************** Autotuning format combination: Half(518400,1:8,2880,16) -> Half(518400,1:8,2880,16) ***************
[04/25/2025-09:08:42] [V] [TRT] =============== Computing costs for Conv_21 + Relu_22
[04/25/2025-09:08:42] [V] [TRT] *************** Autotuning format combination: Float(4147200,32400,180,1) -> Float(4147200,32400,180,1) ***************
[04/25/2025-09:08:42] [V] [TRT] *************** Autotuning format combination: Float(4147200,1,23040,128) -> Float(4147200,1,23040,128) ***************
[04/25/2025-09:08:42] [V] [TRT] *************** Autotuning format combination: Float(1036800,1:4,5760,32) -> Float(4147200,32400,180,1) ***************
[04/25/2025-09:08:42] [V] [TRT] *************** Autotuning format combination: Float(1036800,1:4,5760,32) -> Float(1036800,1:4,5760,32) ***************
[04/25/2025-09:08:42] [V] [TRT] *************** Autotuning format combination: Half(4147200,32400,180,1) -> Half(4147200,32400,180,1) ***************
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_21 + Relu_22 (CaskConvolution[0x80000009])
[04/25/2025-09:08:42] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_21 + Relu_22 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:42] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_21 + Relu_22 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:42] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:42] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:2,11520,64) -> Half(2073600,1:2,11520,64) ***************
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_21 + Relu_22 (CaskConvolution[0x80000009])
[04/25/2025-09:08:42] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_21 + Relu_22 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:42] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:42] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:4,5760,32) -> Half(1036800,1:4,5760,32) ***************
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_21 + Relu_22 (CaskConvolution[0x80000009])
[04/25/2025-09:08:42] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_21 + Relu_22 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:42] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:42] [V] [TRT] *************** Autotuning format combination: Half(518400,1:8,2880,16) -> Float(4147200,32400,180,1) ***************
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_21 + Relu_22 (CaskConvolution[0x80000009])
[04/25/2025-09:08:42] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_21 + Relu_22 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:42] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:42] [V] [TRT] *************** Autotuning format combination: Half(518400,1:8,2880,16) -> Half(518400,1:8,2880,16) ***************
[04/25/2025-09:08:42] [V] [TRT] =============== Computing costs for Conv_23 + Relu_24
[04/25/2025-09:08:42] [V] [TRT] *************** Autotuning format combination: Float(4147200,32400,180,1) -> Float(4147200,32400,180,1) ***************
[04/25/2025-09:08:42] [V] [TRT] *************** Autotuning format combination: Float(4147200,1,23040,128) -> Float(4147200,1,23040,128) ***************
[04/25/2025-09:08:42] [V] [TRT] *************** Autotuning format combination: Float(1036800,1:4,5760,32) -> Float(4147200,32400,180,1) ***************
[04/25/2025-09:08:42] [V] [TRT] *************** Autotuning format combination: Float(1036800,1:4,5760,32) -> Float(1036800,1:4,5760,32) ***************
[04/25/2025-09:08:42] [V] [TRT] *************** Autotuning format combination: Half(4147200,32400,180,1) -> Half(4147200,32400,180,1) ***************
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_23 + Relu_24 (CaskConvolution[0x80000009])
[04/25/2025-09:08:42] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_23 + Relu_24 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:42] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_23 + Relu_24 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:42] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:42] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:2,11520,64) -> Half(2073600,1:2,11520,64) ***************
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_23 + Relu_24 (CaskConvolution[0x80000009])
[04/25/2025-09:08:42] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_23 + Relu_24 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:42] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:42] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:4,5760,32) -> Half(1036800,1:4,5760,32) ***************
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_23 + Relu_24 (CaskConvolution[0x80000009])
[04/25/2025-09:08:42] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_23 + Relu_24 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:42] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:42] [V] [TRT] *************** Autotuning format combination: Half(518400,1:8,2880,16) -> Float(4147200,32400,180,1) ***************
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_23 + Relu_24 (CaskConvolution[0x80000009])
[04/25/2025-09:08:42] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_23 + Relu_24 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:42] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:42] [V] [TRT] *************** Autotuning format combination: Half(518400,1:8,2880,16) -> Half(518400,1:8,2880,16) ***************
[04/25/2025-09:08:42] [V] [TRT] =============== Computing costs for Conv_25 + Relu_26
[04/25/2025-09:08:42] [V] [TRT] *************** Autotuning format combination: Float(4147200,32400,180,1) -> Float(4147200,32400,180,1) ***************
[04/25/2025-09:08:42] [V] [TRT] *************** Autotuning format combination: Float(4147200,1,23040,128) -> Float(4147200,1,23040,128) ***************
[04/25/2025-09:08:42] [V] [TRT] *************** Autotuning format combination: Float(1036800,1:4,5760,32) -> Float(4147200,32400,180,1) ***************
[04/25/2025-09:08:42] [V] [TRT] *************** Autotuning format combination: Float(1036800,1:4,5760,32) -> Float(1036800,1:4,5760,32) ***************
[04/25/2025-09:08:42] [V] [TRT] *************** Autotuning format combination: Half(4147200,32400,180,1) -> Half(4147200,32400,180,1) ***************
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_25 + Relu_26 (CaskConvolution[0x80000009])
[04/25/2025-09:08:42] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_25 + Relu_26 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:42] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_25 + Relu_26 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:42] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:42] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:2,11520,64) -> Half(2073600,1:2,11520,64) ***************
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_25 + Relu_26 (CaskConvolution[0x80000009])
[04/25/2025-09:08:42] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_25 + Relu_26 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:42] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:42] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:4,5760,32) -> Half(1036800,1:4,5760,32) ***************
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_25 + Relu_26 (CaskConvolution[0x80000009])
[04/25/2025-09:08:42] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_25 + Relu_26 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:42] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:42] [V] [TRT] *************** Autotuning format combination: Half(518400,1:8,2880,16) -> Float(4147200,32400,180,1) ***************
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_25 + Relu_26 (CaskConvolution[0x80000009])
[04/25/2025-09:08:42] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_25 + Relu_26 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:42] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:42] [V] [TRT] *************** Autotuning format combination: Half(518400,1:8,2880,16) -> Half(518400,1:8,2880,16) ***************
[04/25/2025-09:08:42] [V] [TRT] =============== Computing costs for Conv_27 + Relu_28
[04/25/2025-09:08:42] [V] [TRT] *************** Autotuning format combination: Float(4147200,32400,180,1) -> Float(16588800,32400,180,1) long-strided ***************
[04/25/2025-09:08:42] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_27 + Relu_28
[04/25/2025-09:08:42] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CaskConvolution[0x80000009])
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: 0xf067e6205da31c2e Time: 0.052029
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 0x503619c69ae500ff Time: 0.0509074
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 0x3f243c490d502deb Time: 0.0551482
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: ampere_scudnn_128x128_relu_interior_nn_v1 Tactic: 0xa8ef60e712f8ad24 Time: 0.051296
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ4_C1_R1_S1_U1_V1 Tactic: 0x588a737570bcf22b Time: 0.301202
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP4_TQ8_C1_R1_S1_U1_V1 Tactic: 0xd646964a96ca001d Time: 0.260535
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP7_TQ2_C4_R1_S1_U1_V1 Tactic: 0xc0bfd75233df14d7 Time: 0.407259
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP4_TQ5_C8_R1_S1_U1_V1 Tactic: 0x80a5d7e9c9c4b8ce Time: 0.272238
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xa9366041633a5135 Time: 0.0928183
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP7_TQ2_C2_R1_S1_U1_V1 Tactic: 0x001526e231ae2e51 Time: 0.574007
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x2ee10e11d6651675 Time: 0.0557349
[04/25/2025-09:08:42] [V] [TRT] Fast skip Tactic:0x46094dd94e60f58a which exceed time limit during pre-run
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP7_TQ1_C1_R1_S1_U1_V1 Tactic: 0x46094dd94e60f58a Time: 1.84525
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP7_TQ4_C4_R1_S1_U1_V1 Tactic: 0x361add5e7e5ba900 Time: 0.27648
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP4_TQ7_C4_R1_S1_U1_V1 Tactic: 0x95559a386f1ab48c Time: 0.340407
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP3_TQ10_C8_R1_S1_U1_V1 Tactic: 0x06122dede8a04ac8 Time: 0.264192
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP3_TQ10_C8_R1_S1_U1_V1 Tactic: 0x77ff66671dd929ae Time: 0.293445
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xcb8a43f748d8a338 Time: 0.107008
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP7_TQ4_C4_R1_S1_U1_V1 Tactic: 0x8c2df094ce3399e7 Time: 0.322999
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP2_TQ7_C1_R1_S1_U1_V1 Tactic: 0xdfbf20bf5c5ed39e Time: 0.321975
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP3_TQ9_C8_R1_S1_U1_V1 Tactic: 0xdb776069eecca7f3 Time: 0.270043
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x5aa723e0481da855 Time: 0.0608061
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP2_TQ8_C2_R1_S1_U1_V1 Tactic: 0x5c06dd7da7ff5d89 Time: 0.273847
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP4_TQ4_C2_R1_S1_U1_V1 Tactic: 0xe7c1b91b9c2edfa3 Time: 0.303835
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec1_1_TP3_TQ10_C1_R1_S1_U1_V1 Tactic: 0x053bede31607189f Time: 0.268873
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x865894c4635db7fd Time: 0.0683642
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP4_TQ7_C4_R1_S1_U1_V1 Tactic: 0x2f62b7f2df72846b Time: 0.285257
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP4_TQ8_C8_R1_S1_U1_V1 Tactic: 0xadc24b6dce6a94cc Time: 0.296229
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP2_TQ7_C4_R1_S1_U1_V1 Tactic: 0xe3a8b64d995c2040 Time: 0.266825
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x40a12e3938221818 Time: 0.140071
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP2_TQ9_C4_R1_S1_U1_V1 Tactic: 0xc6c6d590dfdf6d0c Time: 0.27765
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP6_TQ5_C4_R1_S1_U1_V1 Tactic: 0x3652da2fa8bb0ef3 Time: 0.253367
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP8_TQ2_C8_R1_S1_U1_V1 Tactic: 0x84b1c619b722ac50 Time: 0.392777
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP4_TQ7_C4_R1_S1_U1_V1 Tactic: 0x27fd6918968ac741 Time: 0.25088
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP1_TQ7_C1_R1_S1_U1_V1 Tactic: 0x74f998800c32af5c Time: 0.499419
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP3_TQ7_C4_R1_S1_U1_V1 Tactic: 0x0b22bb41cc7dfe7d Time: 0.253806
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xb0bf940d5e0f9f45 Time: 0.0897463
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP4_TQ4_C8_R1_S1_U1_V1 Tactic: 0x6867dd944a05c100 Time: 0.324754
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xd828f024626fa982 Time: 0.0721189
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP4_TQ7_C8_R1_S1_U1_V1 Tactic: 0x606e22cd0b28a04e Time: 0.311296
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP1_TQ8_C2_R1_S1_U1_V1 Tactic: 0x4d77488847fb11ac Time: 0.413696
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec1_1_TP3_TQ10_C2_R1_S1_U1_V1 Tactic: 0xf119544b988c92ed Time: 0.273701
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0xc0b05b61d128e46e Time: 0.0619261
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0xe5603263b7f00303 Time: 0.0609524
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP5_TQ5_C1_R1_S1_U1_V1 Tactic: 0x1b34d9288dbdb108 Time: 0.266094
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x9d9fdb5fd9945f64 Time: 0.0983771
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP7_TQ4_C8_R1_S1_U1_V1 Tactic: 0xc32165ab1a69bdc2 Time: 0.28043
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP1_TQ10_C2_R1_S1_U1_V1 Tactic: 0x9140485476980e7c Time: 0.273262
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP6_TQ5_C2_R1_S1_U1_V1 Tactic: 0x4ccf06551aa20492 Time: 0.255707
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP2_TQ10_C1_R1_S1_U1_V1 Tactic: 0xc48d91bc4c36e826 Time: 0.259072
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_aligna4_alignc4 Tactic: 0x7f0145cb49517338 Time: 0.0537844
[04/25/2025-09:08:42] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec1_1_TP3_TQ10_C4_R1_S1_U1_V1 Tactic: 0x8b8488312a95988c Time: 0.285842
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP3_TQ9_C4_R1_S1_U1_V1 Tactic: 0x947bf5563a9683d6 Time: 0.295936
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP8_TQ2_C2_R1_S1_U1_V1 Tactic: 0xb1208f5cd1618214 Time: 0.517559
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP2_TQ7_C2_R1_S1_U1_V1 Tactic: 0x91aab4dd62bd690b Time: 0.292279
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP4_TQ5_C2_R1_S1_U1_V1 Tactic: 0xbdab4046e67fd5a0 Time: 0.340992
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: 0xa8609adc4e0ceb90 Time: 0.0618301
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP4_TQ4_C2_R1_S1_U1_V1 Tactic: 0x5df694d12c46ef44 Time: 0.375515
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP2_TQ9_C1_R1_S1_U1_V1 Tactic: 0x4879b042e34ded1f Time: 0.262437
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP5_TQ5_C4_R1_S1_U1_V1 Tactic: 0x2fbc9130014701fc Time: 0.333385
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP4_TQ4_C1_R1_S1_U1_V1 Tactic: 0x13e300b312a555d1 Time: 0.285257
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP2_TQ7_C2_R1_S1_U1_V1 Tactic: 0x2b9d9917d2d559ec Time: 0.359424
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP3_TQ8_C1_R1_S1_U1_V1 Tactic: 0x40ae69d97c5509c6 Time: 0.258633
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: 0xf64396b97c889179 Time: 0.0562712
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP3_TQ8_C2_R1_S1_U1_V1 Tactic: 0xbc130e9bbb26c09e Time: 0.256293
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP2_TQ8_C8_R1_S1_U1_V1 Tactic: 0xd3a0b9f271d4432a Time: 0.296667
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP2_TQ7_C4_R1_S1_U1_V1 Tactic: 0x5100456d60cc538d Time: 0.387072
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x12dbf7d94ee3696d Time: 0.0605623
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: ampere_scudnn_128x64_relu_interior_nn_v1 Tactic: 0xc3cf6e1d1c6aff27 Time: 0.0527604
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP2_TQ8_C2_R1_S1_U1_V1 Tactic: 0xe631f0b717976d6e Time: 0.319049
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP4_TQ7_C8_R1_S1_U1_V1 Tactic: 0xda590f07bb4090a9 Time: 0.272238
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP2_TQ7_C1_R1_S1_U1_V1 Tactic: 0x65880d75ec36e379 Time: 0.278967
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP7_TQ2_C2_R1_S1_U1_V1 Tactic: 0xba220b2881c61eb6 Time: 0.389106
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP2_TQ7_C4_R1_S1_U1_V1 Tactic: 0xeb3768a7d0a4636a Time: 0.30603
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP3_TQ10_C2_R1_S1_U1_V1 Tactic: 0x89b449623e8b546b Time: 0.250441
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP7_TQ4_C8_R1_S1_U1_V1 Tactic: 0x79164861aa018d25 Time: 0.325193
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP1_TQ7_C1_R1_S1_U1_V1 Tactic: 0xceceb54abc5a9fbb Time: 0.404334
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP2_TQ8_C4_R1_S1_U1_V1 Tactic: 0x269b010715e657e8 Time: 0.281893
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP3_TQ10_C4_R1_S1_U1_V1 Tactic: 0x0b33f9e893e376e6 Time: 0.247369
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP2_TQ9_C2_R1_S1_U1_V1 Tactic: 0xbc5b09ea6dc6676d Time: 0.269312
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP5_TQ5_C2_R1_S1_U1_V1 Tactic: 0x55214d4ab35e0b9d Time: 0.314807
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xa31d27de74b895ff Time: 0.066755
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP3_TQ7_C8_R1_S1_U1_V1 Tactic: 0xfe1903b4a84feabf Time: 0.260521
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP5_TQ5_C1_R1_S1_U1_V1 Tactic: 0x13ab07c2c445f222 Time: 0.260974
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP4_TQ7_C2_R1_S1_U1_V1 Tactic: 0xefc84642dd03beed Time: 0.286281
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec1_1_TP4_TQ8_C8_R1_S1_U1_V1 Tactic: 0x4f9a95a9a8862c25 Time: 0.284672
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP3_TQ7_C8_R1_S1_U1_V1 Tactic: 0x4ec6e5a90546faa3 Time: 0.285403
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: ampere_scudnn_128x32_relu_interior_nn_v1 Tactic: 0x9808072e706def96 Time: 0.0590019
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xbb8c3889c7eacd30 Time: 0.0557836
[04/25/2025-09:08:43] [V] [TRT] Conv_27 + Relu_28 (CaskConvolution[0x80000009]) profiling completed in 0.341365 seconds. Fastest Tactic: 0x503619c69ae500ff Time: 0.0509074
[04/25/2025-09:08:43] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CublasConvolution[0x80000029])
[04/25/2025-09:08:43] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:43] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:43] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:43] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:43] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:43] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x503619c69ae500ff
[04/25/2025-09:08:43] [V] [TRT] *************** Autotuning format combination: Float(4147200,32400,180,1) -> Float(8294400,32400,180,1) ***************
[04/25/2025-09:08:43] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CaskConvolution[0x80000009])
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: 0xf067e6205da31c2e Time: 0.0509074
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 0x503619c69ae500ff Time: 0.051005
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 0x3f243c490d502deb Time: 0.0547109
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: ampere_scudnn_128x128_relu_interior_nn_v1 Tactic: 0xa8ef60e712f8ad24 Time: 0.0519802
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ4_C1_R1_S1_U1_V1 Tactic: 0x588a737570bcf22b Time: 0.299008
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize1x4x1_g1_ffma_aligna4_alignc4_beta0_packed_stride Tactic: 0xede36641840ce3d2 Time: 0.0682179
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP4_TQ8_C1_R1_S1_U1_V1 Tactic: 0xd646964a96ca001d Time: 0.260974
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP7_TQ2_C4_R1_S1_U1_V1 Tactic: 0xc0bfd75233df14d7 Time: 0.44661
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP4_TQ5_C8_R1_S1_U1_V1 Tactic: 0x80a5d7e9c9c4b8ce Time: 0.272384
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xa9366041633a5135 Time: 0.092816
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize4x1x1_g1_ffma_aligna4_alignc4_beta0_packed_stride Tactic: 0x1673e3594ce11cea Time: 0.065731
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP7_TQ2_C2_R1_S1_U1_V1 Tactic: 0x001526e231ae2e51 Time: 0.573001
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x2ee10e11d6651675 Time: 0.0563688
[04/25/2025-09:08:43] [V] [TRT] Fast skip Tactic:0x46094dd94e60f58a which exceed time limit during pre-run
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP7_TQ1_C1_R1_S1_U1_V1 Tactic: 0x46094dd94e60f58a Time: 1.8432
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP7_TQ4_C4_R1_S1_U1_V1 Tactic: 0x361add5e7e5ba900 Time: 0.275895
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP4_TQ7_C4_R1_S1_U1_V1 Tactic: 0x95559a386f1ab48c Time: 0.301641
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP3_TQ10_C8_R1_S1_U1_V1 Tactic: 0x06122dede8a04ac8 Time: 0.264192
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP3_TQ10_C8_R1_S1_U1_V1 Tactic: 0x77ff66671dd929ae Time: 0.294034
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xcb8a43f748d8a338 Time: 0.107447
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP7_TQ4_C4_R1_S1_U1_V1 Tactic: 0x8c2df094ce3399e7 Time: 0.323145
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP2_TQ7_C1_R1_S1_U1_V1 Tactic: 0xdfbf20bf5c5ed39e Time: 0.321975
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP3_TQ9_C8_R1_S1_U1_V1 Tactic: 0xdb776069eecca7f3 Time: 0.269897
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x5aa723e0481da855 Time: 0.0607573
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP2_TQ8_C2_R1_S1_U1_V1 Tactic: 0x5c06dd7da7ff5d89 Time: 0.273701
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP4_TQ4_C2_R1_S1_U1_V1 Tactic: 0xe7c1b91b9c2edfa3 Time: 0.303397
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec1_1_TP3_TQ10_C1_R1_S1_U1_V1 Tactic: 0x053bede31607189f Time: 0.269166
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x865894c4635db7fd Time: 0.0687543
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP4_TQ7_C4_R1_S1_U1_V1 Tactic: 0x2f62b7f2df72846b Time: 0.263461
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP4_TQ8_C8_R1_S1_U1_V1 Tactic: 0xadc24b6dce6a94cc Time: 0.296521
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP2_TQ7_C4_R1_S1_U1_V1 Tactic: 0xe3a8b64d995c2040 Time: 0.266679
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x40a12e3938221818 Time: 0.139851
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP2_TQ9_C4_R1_S1_U1_V1 Tactic: 0xc6c6d590dfdf6d0c Time: 0.277504
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP6_TQ5_C4_R1_S1_U1_V1 Tactic: 0x3652da2fa8bb0ef3 Time: 0.253367
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP8_TQ2_C8_R1_S1_U1_V1 Tactic: 0x84b1c619b722ac50 Time: 0.392631
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP4_TQ7_C4_R1_S1_U1_V1 Tactic: 0x27fd6918968ac741 Time: 0.25088
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xfff46c7893896eb1 Time: 0.0549547
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP1_TQ7_C1_R1_S1_U1_V1 Tactic: 0x74f998800c32af5c Time: 0.498103
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP3_TQ7_C4_R1_S1_U1_V1 Tactic: 0x0b22bb41cc7dfe7d Time: 0.254245
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xb0bf940d5e0f9f45 Time: 0.0896686
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP4_TQ4_C8_R1_S1_U1_V1 Tactic: 0x6867dd944a05c100 Time: 0.324754
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xd828f024626fa982 Time: 0.0724114
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize2x2x1_g1_ffma_aligna4_alignc4_beta0_packed_stride Tactic: 0x31aa67f57c5aea77 Time: 0.0612495
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x9cd5cdc35441c505 Time: 0.0594408
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x828d0ea88c66fce7 Time: 0.0690956
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP4_TQ7_C8_R1_S1_U1_V1 Tactic: 0x606e22cd0b28a04e Time: 0.311003
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x1fc87d7eb370bb7a Time: 0.0695345
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP1_TQ8_C2_R1_S1_U1_V1 Tactic: 0x4d77488847fb11ac Time: 0.413989
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec1_1_TP3_TQ10_C2_R1_S1_U1_V1 Tactic: 0xf119544b988c92ed Time: 0.313344
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0xc0b05b61d128e46e Time: 0.0615863
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0xe5603263b7f00303 Time: 0.0620251
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1_aligna4_alignc4 Tactic: 0xa419b3b68f2da07b Time: 0.051491
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP5_TQ5_C1_R1_S1_U1_V1 Tactic: 0x1b34d9288dbdb108 Time: 0.267703
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x9d9fdb5fd9945f64 Time: 0.0985234
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP7_TQ4_C8_R1_S1_U1_V1 Tactic: 0xc32165ab1a69bdc2 Time: 0.281879
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP1_TQ10_C2_R1_S1_U1_V1 Tactic: 0x9140485476980e7c Time: 0.274432
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP6_TQ5_C2_R1_S1_U1_V1 Tactic: 0x4ccf06551aa20492 Time: 0.25717
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize128x64x16_stage2_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1_aligna4_alignc4 Tactic: 0xe52b0ddb126aa135 Time: 0.0425326
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP2_TQ10_C1_R1_S1_U1_V1 Tactic: 0xc48d91bc4c36e826 Time: 0.26112
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x9de226a0c44627c4 Time: 0.0543695
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_aligna4_alignc4 Tactic: 0x7f0145cb49517338 Time: 0.0540282
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec1_1_TP3_TQ10_C4_R1_S1_U1_V1 Tactic: 0x8b8488312a95988c Time: 0.322267
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP3_TQ9_C4_R1_S1_U1_V1 Tactic: 0x947bf5563a9683d6 Time: 0.297691
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x8e3884f0eaec3ecd Time: 0.0602209
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP8_TQ2_C2_R1_S1_U1_V1 Tactic: 0xb1208f5cd1618214 Time: 0.520338
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP2_TQ7_C2_R1_S1_U1_V1 Tactic: 0x91aab4dd62bd690b Time: 0.294034
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP4_TQ5_C2_R1_S1_U1_V1 Tactic: 0xbdab4046e67fd5a0 Time: 0.342747
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: 0xa8609adc4e0ceb90 Time: 0.0617326
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x90f8f2915f87ed77 Time: 0.0896
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP4_TQ4_C2_R1_S1_U1_V1 Tactic: 0x5df694d12c46ef44 Time: 0.377426
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP2_TQ9_C1_R1_S1_U1_V1 Tactic: 0x4879b042e34ded1f Time: 0.264192
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP5_TQ5_C4_R1_S1_U1_V1 Tactic: 0x2fbc9130014701fc Time: 0.373906
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP4_TQ4_C1_R1_S1_U1_V1 Tactic: 0x13e300b312a555d1 Time: 0.287013
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP2_TQ7_C2_R1_S1_U1_V1 Tactic: 0x2b9d9917d2d559ec Time: 0.361472
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP3_TQ8_C1_R1_S1_U1_V1 Tactic: 0x40ae69d97c5509c6 Time: 0.259511
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: 0xf64396b97c889179 Time: 0.0559787
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP3_TQ8_C2_R1_S1_U1_V1 Tactic: 0xbc130e9bbb26c09e Time: 0.257609
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP2_TQ8_C8_R1_S1_U1_V1 Tactic: 0xd3a0b9f271d4432a Time: 0.298853
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP2_TQ7_C4_R1_S1_U1_V1 Tactic: 0x5100456d60cc538d Time: 0.389413
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nchwkrsc_nchw_tilesize128x32x16_stage2_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1_aligna4_alignc4 Tactic: 0xb2c8ebee321e63d6 Time: 0.0525638
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x12dbf7d94ee3696d Time: 0.0603611
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: ampere_scudnn_128x64_relu_interior_nn_v1 Tactic: 0xc3cf6e1d1c6aff27 Time: 0.0526629
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP2_TQ8_C2_R1_S1_U1_V1 Tactic: 0xe631f0b717976d6e Time: 0.320658
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP4_TQ7_C8_R1_S1_U1_V1 Tactic: 0xda590f07bb4090a9 Time: 0.274139
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP2_TQ7_C1_R1_S1_U1_V1 Tactic: 0x65880d75ec36e379 Time: 0.28043
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP7_TQ2_C2_R1_S1_U1_V1 Tactic: 0xba220b2881c61eb6 Time: 0.391899
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP2_TQ7_C4_R1_S1_U1_V1 Tactic: 0xeb3768a7d0a4636a Time: 0.307346
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP3_TQ10_C2_R1_S1_U1_V1 Tactic: 0x89b449623e8b546b Time: 0.252635
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP7_TQ4_C8_R1_S1_U1_V1 Tactic: 0x79164861aa018d25 Time: 0.327241
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP1_TQ7_C1_R1_S1_U1_V1 Tactic: 0xceceb54abc5a9fbb Time: 0.367031
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP2_TQ8_C4_R1_S1_U1_V1 Tactic: 0x269b010715e657e8 Time: 0.283941
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP3_TQ10_C4_R1_S1_U1_V1 Tactic: 0x0b33f9e893e376e6 Time: 0.249856
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec2_2_TP2_TQ9_C2_R1_S1_U1_V1 Tactic: 0xbc5b09ea6dc6676d Time: 0.270921
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP5_TQ5_C2_R1_S1_U1_V1 Tactic: 0x55214d4ab35e0b9d Time: 0.316562
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xa31d27de74b895ff Time: 0.0643139
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP3_TQ7_C8_R1_S1_U1_V1 Tactic: 0xfe1903b4a84feabf Time: 0.261998
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP5_TQ5_C1_R1_S1_U1_V1 Tactic: 0x13ab07c2c445f222 Time: 0.263168
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec4_fltVec1_1_TP4_TQ7_C2_R1_S1_U1_V1 Tactic: 0xefc84642dd03beed Time: 0.28789
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec1_1_TP4_TQ8_C8_R1_S1_U1_V1 Tactic: 0x4f9a95a9a8862c25 Time: 0.286281
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP3_TQ7_C8_R1_S1_U1_V1 Tactic: 0x4ec6e5a90546faa3 Time: 0.287305
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: ampere_scudnn_128x32_relu_interior_nn_v1 Tactic: 0x9808072e706def96 Time: 0.0584655
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xbb8c3889c7eacd30 Time: 0.0545646
[04/25/2025-09:08:43] [V] [TRT] Conv_27 + Relu_28 (CaskConvolution[0x80000009]) profiling completed in 0.372744 seconds. Fastest Tactic: 0xe52b0ddb126aa135 Time: 0.0425326
[04/25/2025-09:08:43] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CublasConvolution[0x80000029])
[04/25/2025-09:08:43] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:43] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:43] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:43] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:43] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:43] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xe52b0ddb126aa135
[04/25/2025-09:08:43] [V] [TRT] *************** Autotuning format combination: Float(4147200,1,23040,128) -> Float(16588800,1,92160,512) long-strided ***************
[04/25/2025-09:08:43] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_27 + Relu_28
[04/25/2025-09:08:43] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CaskConvolution[0x80000009])
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x19b688348f983aa0 Time: 0.069827
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x92ed3100c35fc43e Time: 0.12288
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: ampere_scudnn_128x128_relu_exp_interior_nhwc_tn_v1 Tactic: 0x17173deba0b64484 Time: 0.053443
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x35f26f9c09557d86 Time: 0.0656823
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x8014228ec08b4d49 Time: 0.0604648
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x1022069e6f8d9aeb Time: 0.0615817
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x1da91d865428f237 Time: 0.0669501
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x4fd3c46622e98342 Time: 0.131072
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x7121ec1db3f80c67 Time: 0.106201
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x55d80c17b1cd982d Time: 0.0648046
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x0a143be7a52f301a Time: 0.109422
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x62835fce994f06dd Time: 0.0672427
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xa6448a1e79f1ca6f Time: 0.0806034
[04/25/2025-09:08:43] [V] [TRT] Conv_27 + Relu_28 (CaskConvolution[0x80000009]) profiling completed in 0.0348858 seconds. Fastest Tactic: 0x17173deba0b64484 Time: 0.053443
[04/25/2025-09:08:43] [V] [TRT] Conv_27 + Relu_28: 32 available tactics, 0 unparsable, 16 pruned, 16 remaining after tactic pruning.
[04/25/2025-09:08:43] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CaskGemmConvolution[0x8000002e])
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize64x128x16_stage4_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000203b0 Time: 0.0379966
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize64x128x16_stage4_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000205cd Time: 0.0356059
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize128x128x16_stage3_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000203a8 Time: 0.0356352
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize128x128x16_stage3_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020563 Time: 0.03584
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize128x128x16_stage4_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020273 Time: 0.0424229
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize128x128x16_stage4_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002028a Time: 0.042752
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize128x64x16_stage6_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002071d Time: 0.048323
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize128x64x16_stage6_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020541 Time: 0.0464823
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize128x128x32_stage3_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020109 Time: 0.0432274
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize128x128x32_stage3_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000203b2 Time: 0.0424594
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize128x64x32_stage4_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002030c Time: 0.046848
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize128x64x32_stage4_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000202de Time: 0.0469211
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize64x128x32_stage4_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000204b3 Time: 0.0469211
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize64x128x32_stage4_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020445 Time: 0.0472869
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize128x256x32_stage2_warpsize2x4x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000202d6 Time: 0.0430446
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize128x256x32_stage2_warpsize2x4x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002013b Time: 0.0433006
[04/25/2025-09:08:43] [V] [TRT] Conv_27 + Relu_28 (CaskGemmConvolution[0x8000002e]) profiling completed in 0.034961 seconds. Fastest Tactic: 0x00000000000205cd Time: 0.0356059
[04/25/2025-09:08:43] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CublasConvolution[0x80000029])
[04/25/2025-09:08:43] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:43] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:43] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:43] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskGemmConvolution Tactic: 0x00000000000205cd
[04/25/2025-09:08:43] [V] [TRT] *************** Autotuning format combination: Float(4147200,1,23040,128) -> Float(8294400,1,46080,256) ***************
[04/25/2025-09:08:43] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CaskConvolution[0x80000009])
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x19b688348f983aa0 Time: 0.0685105
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x92ed3100c35fc43e Time: 0.123026
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: ampere_scudnn_128x128_relu_exp_interior_nhwc_tn_v1 Tactic: 0x17173deba0b64484 Time: 0.0558811
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x35f26f9c09557d86 Time: 0.0658773
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x90898977fc8ce537 Time: 0.06656
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xc7b3afceb5fb03c0 Time: 0.0613425
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xd55ee6fd0b56f808 Time: 0.0649509
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x8014228ec08b4d49 Time: 0.060416
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x1022069e6f8d9aeb Time: 0.0625615
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x1da91d865428f237 Time: 0.066755
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x4fd3c46622e98342 Time: 0.131218
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xbc0bba0ff1a92939 Time: 0.0589044
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0xd9eb6ca56ddc3a22 Time: 0.0735086
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_simple_t1r1s1_aligna4_alignc4 Tactic: 0x1fb90698107bb33a Time: 0.105472
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x7121ec1db3f80c67 Time: 0.105838
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r1s1_aligna4_alignc4 Tactic: 0x55d80c17b1cd982d Time: 0.0658773
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x0a143be7a52f301a Time: 0.108471
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x62835fce994f06dd Time: 0.069632
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xa6448a1e79f1ca6f Time: 0.0807497
[04/25/2025-09:08:43] [V] [TRT] Conv_27 + Relu_28 (CaskConvolution[0x80000009]) profiling completed in 0.050362 seconds. Fastest Tactic: 0x17173deba0b64484 Time: 0.0558811
[04/25/2025-09:08:43] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CaskGemmConvolution[0x8000002e])
[04/25/2025-09:08:43] [V] [TRT] CaskGemmConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:43] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CublasConvolution[0x80000029])
[04/25/2025-09:08:43] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:43] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:43] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:43] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x17173deba0b64484
[04/25/2025-09:08:43] [V] [TRT] *************** Autotuning format combination: Float(1036800,1:4,5760,32) -> Float(16588800,32400,180,1) long-strided ***************
[04/25/2025-09:08:43] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_27 + Relu_28
[04/25/2025-09:08:43] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CaskConvolution[0x80000009])
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_alignc4 Tactic: 0xe8f7b6a5bab325f8 Time: 0.0473189
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_alignc4 Tactic: 0xc8ad2c0ce0af5623 Time: 0.0454971
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_alignc4 Tactic: 0x9fd9fe001908ce2e Time: 0.0461166
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0xe0a307ffe0ffb6a5 Time: 0.0454217
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x1d144cf9675b8d6f Time: 0.0439589
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0x3104d85fecdd547c Time: 0.0444343
[04/25/2025-09:08:43] [V] [TRT] Conv_27 + Relu_28 (CaskConvolution[0x80000009]) profiling completed in 0.0177443 seconds. Fastest Tactic: 0x1d144cf9675b8d6f Time: 0.0439589
[04/25/2025-09:08:43] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:43] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:43] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x1d144cf9675b8d6f
[04/25/2025-09:08:43] [V] [TRT] *************** Autotuning format combination: Float(1036800,1:4,5760,32) -> Float(4147200,1:4,23040,128) long-strided ***************
[04/25/2025-09:08:43] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_27 + Relu_28
[04/25/2025-09:08:43] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CaskConvolution[0x80000009])
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0x3e2b881168d9689d Time: 0.0669044
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0xf90060ce8193b811 Time: 0.0517364
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 0xe47307053a42b3e4 Time: 0.052125
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x7bc32c782b800c48 Time: 0.0518339
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 0xc7feb33970feefa7 Time: 0.0654872
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 0xae0c89d047932ba3 Time: 0.0523703
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x130df49cb195156b Time: 0.0434469
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0xb443c221fcb1565b Time: 0.043776
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0x65e41d81f093b482 Time: 0.0446903
[04/25/2025-09:08:43] [V] [TRT] Conv_27 + Relu_28 (CaskConvolution[0x80000009]) profiling completed in 0.0237787 seconds. Fastest Tactic: 0x130df49cb195156b Time: 0.0434469
[04/25/2025-09:08:43] [V] [TRT] Conv_27 + Relu_28: 32 available tactics, 0 unparsable, 16 pruned, 16 remaining after tactic pruning.
[04/25/2025-09:08:43] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CaskGemmConvolution[0x8000002e])
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize64x128x16_stage4_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000203b0 Time: 0.0381806
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize64x128x16_stage4_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000205cd Time: 0.0355474
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize128x128x16_stage3_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000203a8 Time: 0.0356645
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize128x128x16_stage3_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020563 Time: 0.0358046
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize128x128x16_stage4_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020273 Time: 0.0424594
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize128x128x16_stage4_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002028a Time: 0.0425691
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize128x64x16_stage6_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002071d Time: 0.0482255
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize128x64x16_stage6_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020541 Time: 0.0464823
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize128x128x32_stage3_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020109 Time: 0.0432274
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize128x128x32_stage3_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000203b2 Time: 0.0430046
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize128x64x32_stage4_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002030c Time: 0.0468491
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize128x64x32_stage4_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000202de Time: 0.04696
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize64x128x32_stage4_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000204b3 Time: 0.046848
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize64x128x32_stage4_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020445 Time: 0.0471771
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize128x256x32_stage2_warpsize2x4x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000202d6 Time: 0.0427886
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize128x256x32_stage2_warpsize2x4x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002013b Time: 0.043264
[04/25/2025-09:08:43] [V] [TRT] Conv_27 + Relu_28 (CaskGemmConvolution[0x8000002e]) profiling completed in 0.0383412 seconds. Fastest Tactic: 0x00000000000205cd Time: 0.0355474
[04/25/2025-09:08:43] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CublasConvolution[0x80000029])
[04/25/2025-09:08:43] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:43] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:43] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:43] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskGemmConvolution Tactic: 0x00000000000205cd
[04/25/2025-09:08:43] [V] [TRT] *************** Autotuning format combination: Float(1036800,1:4,5760,32) -> Float(8294400,32400,180,1) ***************
[04/25/2025-09:08:43] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CaskConvolution[0x80000009])
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_alignc4 Tactic: 0xe8f7b6a5bab325f8 Time: 0.0470994
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1_alignc4 Tactic: 0x440241d9c93d605d Time: 0.0434103
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1_alignc4 Tactic: 0xc8ad2c0ce0af5623 Time: 0.0454949
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_alignc4 Tactic: 0x9fd9fe001908ce2e Time: 0.0461166
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0x608ed7b5923d2355 Time: 0.0434469
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0xe0a307ffe0ffb6a5 Time: 0.0454571
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x1d144cf9675b8d6f Time: 0.044032
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0x3104d85fecdd547c Time: 0.0443623
[04/25/2025-09:08:43] [V] [TRT] Conv_27 + Relu_28 (CaskConvolution[0x80000009]) profiling completed in 0.0205302 seconds. Fastest Tactic: 0x440241d9c93d605d Time: 0.0434103
[04/25/2025-09:08:43] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:43] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:43] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x440241d9c93d605d
[04/25/2025-09:08:43] [V] [TRT] *************** Autotuning format combination: Float(1036800,1:4,5760,32) -> Float(2073600,1:4,11520,64) ***************
[04/25/2025-09:08:43] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CaskConvolution[0x80000009])
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0x3e2b881168d9689d Time: 0.0660251
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0xf90060ce8193b811 Time: 0.0526141
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 0xe47307053a42b3e4 Time: 0.0535406
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x7bc32c782b800c48 Time: 0.054077
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 0xc7feb33970feefa7 Time: 0.0645608
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 0xae0c89d047932ba3 Time: 0.0511512
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r1s1 Tactic: 0x130df49cb195156b Time: 0.0432263
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_simple_t1r1s1 Tactic: 0x9dece0dc37e90462 Time: 0.0431177
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0xb443c221fcb1565b Time: 0.04348
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0x65e41d81f093b482 Time: 0.0444709
[04/25/2025-09:08:43] [V] [TRT] Conv_27 + Relu_28 (CaskConvolution[0x80000009]) profiling completed in 0.026597 seconds. Fastest Tactic: 0x9dece0dc37e90462 Time: 0.0431177
[04/25/2025-09:08:43] [V] [TRT] Conv_27 + Relu_28: 32 available tactics, 0 unparsable, 16 pruned, 16 remaining after tactic pruning.
[04/25/2025-09:08:43] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CaskGemmConvolution[0x8000002e])
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize64x128x16_stage4_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000203b0 Time: 0.0379246
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize64x128x16_stage4_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000205cd Time: 0.0354597
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize128x128x16_stage3_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000203a8 Time: 0.0354889
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize128x128x16_stage3_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020563 Time: 0.0356937
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize128x128x16_stage4_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020273 Time: 0.0422034
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize128x128x16_stage4_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002028a Time: 0.0423497
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize128x64x16_stage6_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002071d Time: 0.0486156
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize128x64x16_stage6_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020541 Time: 0.0467017
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize128x128x32_stage3_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020109 Time: 0.0430446
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize128x128x32_stage3_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000203b2 Time: 0.0425326
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize128x64x32_stage4_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002030c Time: 0.0469211
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize128x64x32_stage4_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000202de Time: 0.0472869
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize64x128x32_stage4_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000204b3 Time: 0.048323
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize64x128x32_stage4_warpsize2x2x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020445 Time: 0.0492495
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_tn_n_tilesize128x256x32_stage2_warpsize2x4x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000202d6 Time: 0.0430446
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm86_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize128x256x32_stage2_warpsize2x4x1_tensor16x8x8 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002013b Time: 0.0431909
[04/25/2025-09:08:43] [V] [TRT] Conv_27 + Relu_28 (CaskGemmConvolution[0x8000002e]) profiling completed in 0.038263 seconds. Fastest Tactic: 0x00000000000205cd Time: 0.0354597
[04/25/2025-09:08:43] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CublasConvolution[0x80000029])
[04/25/2025-09:08:43] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:43] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:43] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:43] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskGemmConvolution Tactic: 0x00000000000205cd
[04/25/2025-09:08:43] [V] [TRT] *************** Autotuning format combination: Half(4147200,32400,180,1) -> Half(16588800,32400,180,1) long-strided ***************
[04/25/2025-09:08:43] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_27 + Relu_28
[04/25/2025-09:08:43] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CaskConvolution[0x80000009])
[04/25/2025-09:08:43] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:43] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CublasConvolution[0x80000029])
[04/25/2025-09:08:43] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:43] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:43] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:43] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:43] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:43] [V] [TRT] *************** Autotuning format combination: Half(4147200,32400,180,1) -> Half(8294400,32400,180,1) ***************
[04/25/2025-09:08:43] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CaskConvolution[0x80000009])
[04/25/2025-09:08:43] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:43] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CublasConvolution[0x80000029])
[04/25/2025-09:08:43] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:43] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:43] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:43] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:43] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:43] [V] [TRT] *************** Autotuning format combination: Half(2073600,32400:2,180,1) -> Half(8294400,32400:2,180,1) long-strided ***************
[04/25/2025-09:08:43] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_27 + Relu_28
[04/25/2025-09:08:43] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CublasConvolution[0x80000029])
[04/25/2025-09:08:43] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:43] [V] [TRT] *************** Autotuning format combination: Half(2073600,32400:2,180,1) -> Half(4147200,32400:2,180,1) ***************
[04/25/2025-09:08:43] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CublasConvolution[0x80000029])
[04/25/2025-09:08:43] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:43] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:2,11520,64) -> Half(8294400,1:2,46080,256) long-strided ***************
[04/25/2025-09:08:43] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_27 + Relu_28
[04/25/2025-09:08:43] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CaskConvolution[0x80000009])
[04/25/2025-09:08:43] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:43] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CublasConvolution[0x80000029])
[04/25/2025-09:08:43] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:43] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:43] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:43] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:2,11520,64) -> Half(4147200,1:2,23040,128) ***************
[04/25/2025-09:08:43] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CaskConvolution[0x80000009])
[04/25/2025-09:08:43] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:43] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CublasConvolution[0x80000029])
[04/25/2025-09:08:43] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:43] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:43] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:43] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:4,5760,32) -> Half(4147200,1:4,23040,128) long-strided ***************
[04/25/2025-09:08:43] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_27 + Relu_28
[04/25/2025-09:08:43] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CaskConvolution[0x80000009])
[04/25/2025-09:08:43] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:43] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CublasConvolution[0x80000029])
[04/25/2025-09:08:43] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:43] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:43] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:43] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:4,5760,32) -> Half(2073600,1:4,11520,64) ***************
[04/25/2025-09:08:43] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CaskConvolution[0x80000009])
[04/25/2025-09:08:43] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:43] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CublasConvolution[0x80000029])
[04/25/2025-09:08:43] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:43] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:43] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:43] [V] [TRT] *************** Autotuning format combination: Half(518400,1:8,2880,16) -> Float(16588800,32400,180,1) long-strided ***************
[04/25/2025-09:08:43] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_27 + Relu_28
[04/25/2025-09:08:43] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CaskConvolution[0x80000009])
[04/25/2025-09:08:43] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:43] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CublasConvolution[0x80000029])
[04/25/2025-09:08:43] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:43] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:43] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:43] [V] [TRT] *************** Autotuning format combination: Half(518400,1:8,2880,16) -> Half(2073600,1:8,11520,64) long-strided ***************
[04/25/2025-09:08:43] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_27 + Relu_28
[04/25/2025-09:08:43] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CaskConvolution[0x80000009])
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xdce100b9fe609424 Time: 0.0282331
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r1s1 Tactic: 0xb4ed47991b2d81ae Time: 0.026429
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r1s1 Tactic: 0x3e2d344492eaa731 Time: 0.023761
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 0x60da8c7151d91e47 Time: 0.017473
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r1s1 Tactic: 0x4a33d90483c0ec01 Time: 0.020689
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xdfa020ef435ef810 Time: 0.0194377
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x5568fd8a32f4a40f Time: 0.026723
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r1s1 Tactic: 0x8f25d6cdaeaaa100 Time: 0.0260145
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r1s1 Tactic: 0xd80cb0f3373aef38 Time: 0.0198949
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x57c9a5ff682354a6 Time: 0.0214204
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r1s1 Tactic: 0x2e9f40fea3fe4d65 Time: 0.028789
[04/25/2025-09:08:43] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xdb0b80f591d1bb6d Time: 0.0228624
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x5820b3dda403c4d0 Time: 0.048128
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 0xb17d53d15dfbfc9e Time: 0.0173592
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x21b295c0c8f6c95a Time: 0.0253562
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xe1ff5ad20f5c6bf6 Time: 0.0459703
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r1s1 Tactic: 0xbb4ac900a7be8b4c Time: 0.030837
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xbd08239a9317f2fd Time: 0.0238446
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xa570c55d303796ff Time: 0.0200594
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x4a81ea1e51436a30 Time: 0.0294034
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x0e07ff4f4f7c1ac9 Time: 0.0196206
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xc9d24bd069159fa8 Time: 0.0239429
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: 0xa1a20ea714d420f4 Time: 0.0175543
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xf79479a62ea9f901 Time: 0.0262827
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xa83b68f30462f971 Time: 0.0293449
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0x834e11ecd4ab9454 Time: 0.0265996
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r1s1 Tactic: 0xea50b6d3d87bf5dd Time: 0.0192731
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: 0x7005d10718f6c22d Time: 0.0174243
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xd1aaad17ca35fbaa Time: 0.0200589
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r1s1 Tactic: 0x2aa016c86360697f Time: 0.0453486
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x1x2_g1_tensor16x8x16_aACCESS Tactic: 0x841c601dec2a75bc Time: 0.031861
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r1s1 Tactic: 0x9d78040b7e8c8ac7 Time: 0.0227579
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xafd1e8bf6bd3d638 Time: 0.0223608
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xf35e0311fa1cc516 Time: 0.030923
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage4_warpsize2x1x2_g1_tensor16x8x16 Tactic: 0x7273dde1d0cd3bd5 Time: 0.0274042
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r1s1 Tactic: 0x8e1e99c68a674ff4 Time: 0.0173262
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x866e7a5f6401b67f Time: 0.0203703
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16_t1r1s1 Tactic: 0x23848f7cc4e20635 Time: 0.0175543
[04/25/2025-09:08:44] [V] [TRT] Conv_27 + Relu_28 (CaskConvolution[0x80000009]) profiling completed in 0.0828873 seconds. Fastest Tactic: 0x8e1e99c68a674ff4 Time: 0.0173262
[04/25/2025-09:08:44] [V] [TRT] Conv_27 + Relu_28: 88 available tactics, 0 unparsable, 44 pruned, 44 remaining after tactic pruning.
[04/25/2025-09:08:44] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CaskGemmConvolution[0x8000002e])
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_ldg8_relu_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020048 Time: 0.0194926
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_ldg8_relu_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020187 Time: 0.0204382
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_ldg8_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020054 Time: 0.0422766
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_ldg8_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020873 Time: 0.0424229
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_sliced1x2_ldg8_relu_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000206d6 Time: 0.0221518
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_sliced1x2_ldg8_relu_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002097a Time: 0.0233633
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_sliced1x2_ldg8_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002000b Time: 0.0449463
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_sliced1x2_ldg8_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000207db Time: 0.043264
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_64x64_ldg8_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020588 Time: 0.0468114
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_64x64_ldg8_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002082a Time: 0.04736
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_64x64_ldg8_relu_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020982 Time: 0.0252587
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_64x64_ldg8_relu_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020468 Time: 0.0256731
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_64x64_sliced1x2_ldg8_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020987 Time: 0.0439954
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_64x64_sliced1x2_ldg8_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002052f Time: 0.0438126
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_64x64_sliced1x2_ldg8_relu_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000203ea Time: 0.0229453
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_64x64_sliced1x2_ldg8_relu_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020056 Time: 0.0234893
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_128x128_ldg8_stages_32x5_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020369 Time: 0.0416183
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_128x128_ldg8_stages_32x5_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000200f9 Time: 0.0421669
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x128x32_stage4_warpsize2x2x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000207fc Time: 0.0182309
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize128x128x32_stage4_warpsize2x2x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002070b Time: 0.0187246
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_128x128_ldg8_relu_stages_32x5_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000208bc Time: 0.0206472
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_128x128_ldg8_relu_stages_32x5_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000209a3 Time: 0.0205009
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x256x32_stage3_warpsize2x4x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002062b Time: 0.0173917
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize128x256x32_stage3_warpsize2x4x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020430 Time: 0.0171317
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize256x128x32_stage3_warpsize4x2x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002008e Time: 0.0169041
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize256x128x32_stage3_warpsize4x2x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020719 Time: 0.0170022
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_256x128_ldg8_stages_32x3_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020745 Time: 0.0392777
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_256x128_ldg8_stages_32x3_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002081d Time: 0.0396434
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_256x128_ldg8_relu_stages_32x3_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002073b Time: 0.0171652
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_256x128_ldg8_relu_stages_32x3_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020817 Time: 0.0175055
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize256x64x32_stage3_warpsize4x1x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020707 Time: 0.0193097
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize256x64x32_stage3_warpsize4x1x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002071a Time: 0.01894
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_64x128_ldg8_stages_32x6_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002016b Time: 0.0472503
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_64x128_ldg8_stages_32x6_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000208f9 Time: 0.0469577
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize128x64x32_stage5_warpsize2x2x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002070e Time: 0.0224026
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x64x32_stage5_warpsize2x2x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020722 Time: 0.0224026
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_ldg8_stages_32x6_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000208d9 Time: 0.0449097
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_ldg8_stages_32x6_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000202c3 Time: 0.0452023
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize64x128x32_stage5_warpsize2x2x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020634 Time: 0.0218802
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize64x128x32_stage5_warpsize2x2x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000207f5 Time: 0.0222348
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_64x128_ldg8_relu_stages_32x6_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020799 Time: 0.0266728
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_64x128_ldg8_relu_stages_32x6_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020581 Time: 0.0274286
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_ldg8_relu_stages_32x6_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002004e Time: 0.0241128
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_ldg8_relu_stages_32x6_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000206a0 Time: 0.0249417
[04/25/2025-09:08:44] [V] [TRT] Conv_27 + Relu_28 (CaskGemmConvolution[0x8000002e]) profiling completed in 0.535757 seconds. Fastest Tactic: 0x000000000002008e Time: 0.0169041
[04/25/2025-09:08:44] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CublasConvolution[0x80000029])
[04/25/2025-09:08:44] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:44] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:44] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:44] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskGemmConvolution Tactic: 0x000000000002008e
[04/25/2025-09:08:44] [V] [TRT] *************** Autotuning format combination: Half(518400,1:8,2880,16) -> Float(8294400,32400,180,1) ***************
[04/25/2025-09:08:44] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CaskConvolution[0x80000009])
[04/25/2025-09:08:44] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:44] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CublasConvolution[0x80000029])
[04/25/2025-09:08:44] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:44] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:44] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:44] [V] [TRT] *************** Autotuning format combination: Half(518400,1:8,2880,16) -> Half(1036800,1:8,5760,32) ***************
[04/25/2025-09:08:44] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CaskConvolution[0x80000009])
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xdce100b9fe609424 Time: 0.0281356
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r1s1 Tactic: 0xb4ed47991b2d81ae Time: 0.0263558
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r1s1 Tactic: 0x3e2d344492eaa731 Time: 0.0234475
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 0x60da8c7151d91e47 Time: 0.0175218
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r1s1 Tactic: 0x4a33d90483c0ec01 Time: 0.0205636
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_simple_t1r1s1 Tactic: 0x8047bcfcebface4a Time: 0.0255756
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_simple_t1r1s1 Tactic: 0xa2121200e08f5391 Time: 0.0192914
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xdfa020ef435ef810 Time: 0.0193097
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x5568fd8a32f4a40f Time: 0.0265524
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r1s1 Tactic: 0x8f25d6cdaeaaa100 Time: 0.0260632
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r1s1 Tactic: 0xd80cb0f3373aef38 Time: 0.0197851
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x57c9a5ff682354a6 Time: 0.0211696
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r1s1 Tactic: 0x2e9f40fea3fe4d65 Time: 0.0286427
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16_simple_t1r1s1 Tactic: 0xfd2247f786006d58 Time: 0.020096
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xdb0b80f591d1bb6d Time: 0.022737
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x5820b3dda403c4d0 Time: 0.0478354
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 0xb17d53d15dfbfc9e Time: 0.0173592
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x21b295c0c8f6c95a Time: 0.0252343
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xe1ff5ad20f5c6bf6 Time: 0.0456777
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r1s1 Tactic: 0xbb4ac900a7be8b4c Time: 0.0306615
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xbd08239a9317f2fd Time: 0.0236983
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xa570c55d303796ff Time: 0.0199143
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x4a81ea1e51436a30 Time: 0.0291986
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x0e07ff4f4f7c1ac9 Time: 0.0192914
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16_simple_t1r1s1 Tactic: 0x3fc555ff414cee06 Time: 0.017408
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xc9d24bd069159fa8 Time: 0.0237819
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16_simple_t1r1s1 Tactic: 0x454d6448fb6e7fd1 Time: 0.022946
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: 0xa1a20ea714d420f4 Time: 0.0174568
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xf79479a62ea9f901 Time: 0.0261364
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xa83b68f30462f971 Time: 0.0295205
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0x834e11ecd4ab9454 Time: 0.0265021
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_simple_t1r1s1 Tactic: 0x3ca70d6b51bf2164 Time: 0.0270141
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_simple_t1r1s1 Tactic: 0x361d222e42fcb76c Time: 0.0299301
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r1s1 Tactic: 0xea50b6d3d87bf5dd Time: 0.0192183
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: 0x7005d10718f6c22d Time: 0.0173755
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xd1aaad17ca35fbaa Time: 0.019932
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16_simple_t1r1s1 Tactic: 0x5cf18273fea3db5c Time: 0.0224849
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r1s1 Tactic: 0x2aa016c86360697f Time: 0.0450926
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x1x2_g1_tensor16x8x16_aACCESS Tactic: 0x841c601dec2a75bc Time: 0.0316562
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r1s1 Tactic: 0x9d78040b7e8c8ac7 Time: 0.0226743
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xafd1e8bf6bd3d638 Time: 0.0221727
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xf35e0311fa1cc516 Time: 0.0307493
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16_simple_t1r1s1 Tactic: 0x3e55aa5fb58280dd Time: 0.017214
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage4_warpsize2x1x2_g1_tensor16x8x16 Tactic: 0x7273dde1d0cd3bd5 Time: 0.0272335
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16_simple_t1r1s1 Tactic: 0xe69f3e9fcc7b2069 Time: 0.042752
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_simple_t1r1s1 Tactic: 0x3eda3b336995a6f0 Time: 0.0197674
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_simple_t1r1s1 Tactic: 0x7a738fe099ae3c1e Time: 0.0244053
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r1s1 Tactic: 0x8e1e99c68a674ff4 Time: 0.0173105
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x866e7a5f6401b67f Time: 0.0204382
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16_t1r1s1 Tactic: 0x23848f7cc4e20635 Time: 0.0175055
[04/25/2025-09:08:44] [V] [TRT] Conv_27 + Relu_28 (CaskConvolution[0x80000009]) profiling completed in 0.0998984 seconds. Fastest Tactic: 0x3e55aa5fb58280dd Time: 0.017214
[04/25/2025-09:08:44] [V] [TRT] Conv_27 + Relu_28: 88 available tactics, 0 unparsable, 44 pruned, 44 remaining after tactic pruning.
[04/25/2025-09:08:44] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CaskGemmConvolution[0x8000002e])
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_ldg8_relu_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020048 Time: 0.019384
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_ldg8_relu_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020187 Time: 0.0204069
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_ldg8_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020054 Time: 0.0423131
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_ldg8_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020873 Time: 0.0415817
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_sliced1x2_ldg8_relu_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000206d6 Time: 0.0216085
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_sliced1x2_ldg8_relu_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002097a Time: 0.0226325
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_sliced1x2_ldg8_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002000b Time: 0.0437394
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_sliced1x2_ldg8_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000207db Time: 0.043008
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_64x64_ldg8_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020588 Time: 0.0460434
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_64x64_ldg8_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002082a Time: 0.0465897
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_64x64_ldg8_relu_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020982 Time: 0.024771
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_64x64_ldg8_relu_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020468 Time: 0.0252099
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_64x64_sliced1x2_ldg8_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020987 Time: 0.0443246
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_64x64_sliced1x2_ldg8_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002052f Time: 0.0437406
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_64x64_sliced1x2_ldg8_relu_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000203ea Time: 0.0230269
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_64x64_sliced1x2_ldg8_relu_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020056 Time: 0.0235311
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_128x128_ldg8_stages_32x5_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020369 Time: 0.0416914
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_128x128_ldg8_stages_32x5_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000200f9 Time: 0.0422
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x128x32_stage4_warpsize2x2x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000207fc Time: 0.0181217
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize128x128x32_stage4_warpsize2x2x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002070b Time: 0.0185429
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_128x128_ldg8_relu_stages_32x5_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000208bc Time: 0.0206054
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_128x128_ldg8_relu_stages_32x5_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000209a3 Time: 0.0204389
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x256x32_stage3_warpsize2x4x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002062b Time: 0.0173755
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize128x256x32_stage3_warpsize2x4x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020430 Time: 0.0171484
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize256x128x32_stage3_warpsize4x2x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002008e Time: 0.0169529
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize256x128x32_stage3_warpsize4x2x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020719 Time: 0.0170357
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_256x128_ldg8_stages_32x3_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020745 Time: 0.0394606
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_256x128_ldg8_stages_32x3_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002081d Time: 0.0397166
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_256x128_ldg8_relu_stages_32x3_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002073b Time: 0.017245
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_256x128_ldg8_relu_stages_32x3_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020817 Time: 0.0177006
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize256x64x32_stage3_warpsize4x1x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020707 Time: 0.019328
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize256x64x32_stage3_warpsize4x1x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002071a Time: 0.0189623
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_64x128_ldg8_stages_32x6_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002016b Time: 0.0474331
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_64x128_ldg8_stages_32x6_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000208f9 Time: 0.0470309
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize128x64x32_stage5_warpsize2x2x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002070e Time: 0.0224013
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x64x32_stage5_warpsize2x2x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020722 Time: 0.0224653
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_ldg8_stages_32x6_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000208d9 Time: 0.0450206
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_ldg8_stages_32x6_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000202c3 Time: 0.0454217
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize64x128x32_stage5_warpsize2x2x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020634 Time: 0.0218802
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize64x128x32_stage5_warpsize2x2x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000207f5 Time: 0.0222772
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_64x128_ldg8_relu_stages_32x6_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020799 Time: 0.0267459
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_64x128_ldg8_relu_stages_32x6_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020581 Time: 0.02704
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_ldg8_relu_stages_32x6_tn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002004e Time: 0.0241371
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_ldg8_relu_stages_32x6_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000206a0 Time: 0.0248442
[04/25/2025-09:08:44] [V] [TRT] Conv_27 + Relu_28 (CaskGemmConvolution[0x8000002e]) profiling completed in 0.111786 seconds. Fastest Tactic: 0x000000000002008e Time: 0.0169529
[04/25/2025-09:08:44] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CublasConvolution[0x80000029])
[04/25/2025-09:08:44] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:44] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:44] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:44] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskGemmConvolution Tactic: 0x000000000002008e
[04/25/2025-09:08:44] [V] [TRT] *************** Autotuning format combination: Half(259200,1:16,1440,8) -> Half(1036800,1:16,5760,32) long-strided ***************
[04/25/2025-09:08:44] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_27 + Relu_28
[04/25/2025-09:08:44] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CublasConvolution[0x80000029])
[04/25/2025-09:08:44] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:44] [V] [TRT] *************** Autotuning format combination: Half(259200,1:16,1440,8) -> Half(518400,1:16,2880,16) ***************
[04/25/2025-09:08:44] [V] [TRT] --------------- Timing Runner: Conv_27 + Relu_28 (CublasConvolution[0x80000029])
[04/25/2025-09:08:44] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:44] [V] [TRT] =============== Computing costs for Conv_44 + Relu_45
[04/25/2025-09:08:44] [V] [TRT] *************** Autotuning format combination: Float(4147200,32400,180,1) -> Float(2073600,8100,90,1) ***************
[04/25/2025-09:08:44] [V] [TRT] --------------- Timing Runner: Conv_44 + Relu_45 (CaskConvolution[0x80000009])
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: 0xf067e6205da31c2e Time: 0.100571
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 0x5deb29b7a8e275f7 Time: 0.103854
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 0x503619c69ae500ff Time: 0.100425
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 0x3f243c490d502deb Time: 0.105984
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize1x4x1_g1_ffma_aligna4_alignc4_beta0_packed_stride Tactic: 0xede36641840ce3d2 Time: 0.122149
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xa9366041633a5135 Time: 0.225865
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize4x1x1_g1_ffma_aligna4_alignc4_beta0_packed_stride Tactic: 0x1673e3594ce11cea Time: 0.135897
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xcb8a43f748d8a338 Time: 0.217234
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x5aa723e0481da855 Time: 0.109861
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4_beta0_packed_stride Tactic: 0x7fc93550f5b9c127 Time: 0.120832
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x40a12e3938221818 Time: 0.275456
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x01cf8ce2da913006 Time: 0.110229
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xb0bf940d5e0f9f45 Time: 0.184613
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xd828f024626fa982 Time: 0.154917
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize2x2x1_g1_ffma_aligna4_alignc4_beta0_packed_stride Tactic: 0x31aa67f57c5aea77 Time: 0.120466
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x9d9fdb5fd9945f64 Time: 0.187246
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x4efce38acc876f5c Time: 0.152283
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x4727434768e46395 Time: 0.152869
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ4_C1_R3_S3_U2_V2 Tactic: 0xdb028f7ca5d4eecf Time: 0.215625
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: 0xa8609adc4e0ceb90 Time: 0.130121
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: 0xf64396b97c889179 Time: 0.109275
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize4x1x1_g1_ffma_t1r3s3_aligna4_alignc4_beta0_packed_stride Tactic: 0xe640ceafd7d34ca9 Time: 0.113006
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x12dbf7d94ee3696d Time: 0.0991109
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x8ad32616b1424be4 Time: 0.186368
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize2x2x1_g1_ffma_t1r3s3_aligna4_alignc4_beta0_packed_stride Tactic: 0x3712e3e595645874 Time: 0.115934
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xa31d27de74b895ff Time: 0.135461
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xbb8c3889c7eacd30 Time: 0.152576
[04/25/2025-09:08:44] [V] [TRT] Conv_44 + Relu_45 (CaskConvolution[0x80000009]) profiling completed in 0.0987737 seconds. Fastest Tactic: 0x12dbf7d94ee3696d Time: 0.0991109
[04/25/2025-09:08:44] [V] [TRT] --------------- Timing Runner: Conv_44 + Relu_45 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:44] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:44] [V] [TRT] --------------- Timing Runner: Conv_44 + Relu_45 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:44] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:44] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x12dbf7d94ee3696d
[04/25/2025-09:08:44] [V] [TRT] *************** Autotuning format combination: Float(4147200,1,23040,128) -> Float(2073600,1,23040,256) ***************
[04/25/2025-09:08:44] [V] [TRT] --------------- Timing Runner: Conv_44 + Relu_45 (CaskConvolution[0x80000009])
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x3f0c846d6379bc98 Time: 0.102254
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x19b688348f983aa0 Time: 0.147602
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0xf48db81f02eca9ee Time: 0.126613
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x92ed3100c35fc43e Time: 0.256439
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x5953bec563d26434 Time: 0.227328
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x8014228ec08b4d49 Time: 0.098448
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x1da91d865428f237 Time: 0.125655
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x4fd3c46622e98342 Time: 0.276334
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x32059de4888dfdda Time: 0.270775
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x7121ec1db3f80c67 Time: 0.228498
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0xd15dd11d64344e83 Time: 0.122368
[04/25/2025-09:08:44] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x0a143be7a52f301a Time: 0.230839
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x62835fce994f06dd Time: 0.137289
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xa6448a1e79f1ca6f Time: 0.159159
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x94a7db94ba744c45 Time: 0.13824
[04/25/2025-09:08:45] [V] [TRT] Conv_44 + Relu_45 (CaskConvolution[0x80000009]) profiling completed in 0.0530674 seconds. Fastest Tactic: 0x8014228ec08b4d49 Time: 0.098448
[04/25/2025-09:08:45] [V] [TRT] --------------- Timing Runner: Conv_44 + Relu_45 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:45] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:45] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x8014228ec08b4d49
[04/25/2025-09:08:45] [V] [TRT] *************** Autotuning format combination: Float(1036800,1:4,5760,32) -> Float(2073600,8100,90,1) ***************
[04/25/2025-09:08:45] [V] [TRT] --------------- Timing Runner: Conv_44 + Relu_45 (CaskConvolution[0x80000009])
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_alignc4 Tactic: 0xe8f7b6a5bab325f8 Time: 0.0665646
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_alignc4 Tactic: 0x9fd9fe001908ce2e Time: 0.0638293
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3_alignc4 Tactic: 0x1323e48791e2f671 Time: 0.0628053
[04/25/2025-09:08:45] [V] [TRT] Conv_44 + Relu_45 (CaskConvolution[0x80000009]) profiling completed in 0.00891589 seconds. Fastest Tactic: 0x1323e48791e2f671 Time: 0.0628053
[04/25/2025-09:08:45] [V] [TRT] --------------- Timing Runner: Conv_44 + Relu_45 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:45] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:45] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x1323e48791e2f671
[04/25/2025-09:08:45] [V] [TRT] *************** Autotuning format combination: Float(1036800,1:4,5760,32) -> Float(518400,1:4,5760,64) ***************
[04/25/2025-09:08:45] [V] [TRT] --------------- Timing Runner: Conv_44 + Relu_45 (CaskConvolution[0x80000009])
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 0xbdfdef6b84f7ccc9 Time: 0.104009
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0x3e2b881168d9689d Time: 0.111689
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0xf90060ce8193b811 Time: 0.105326
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x7bc32c782b800c48 Time: 0.111177
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0xb443c221fcb1565b Time: 0.0630004
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 0x999e005e3b016ea6 Time: 0.0618301
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0x65e41d81f093b482 Time: 0.065341
[04/25/2025-09:08:45] [V] [TRT] Conv_44 + Relu_45 (CaskConvolution[0x80000009]) profiling completed in 0.0234963 seconds. Fastest Tactic: 0x999e005e3b016ea6 Time: 0.0618301
[04/25/2025-09:08:45] [V] [TRT] --------------- Timing Runner: Conv_44 + Relu_45 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:45] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:45] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x999e005e3b016ea6
[04/25/2025-09:08:45] [V] [TRT] *************** Autotuning format combination: Half(4147200,32400,180,1) -> Half(2073600,8100,90,1) ***************
[04/25/2025-09:08:45] [V] [TRT] --------------- Timing Runner: Conv_44 + Relu_45 (CaskConvolution[0x80000009])
[04/25/2025-09:08:45] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:45] [V] [TRT] --------------- Timing Runner: Conv_44 + Relu_45 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:45] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:45] [V] [TRT] --------------- Timing Runner: Conv_44 + Relu_45 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:45] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:45] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:2,11520,64) -> Half(1036800,1:2,11520,128) ***************
[04/25/2025-09:08:45] [V] [TRT] --------------- Timing Runner: Conv_44 + Relu_45 (CaskConvolution[0x80000009])
[04/25/2025-09:08:45] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:45] [V] [TRT] --------------- Timing Runner: Conv_44 + Relu_45 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:45] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:45] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:4,5760,32) -> Half(518400,1:4,5760,64) ***************
[04/25/2025-09:08:45] [V] [TRT] --------------- Timing Runner: Conv_44 + Relu_45 (CaskConvolution[0x80000009])
[04/25/2025-09:08:45] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:45] [V] [TRT] --------------- Timing Runner: Conv_44 + Relu_45 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:45] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:45] [V] [TRT] *************** Autotuning format combination: Half(518400,1:8,2880,16) -> Float(2073600,8100,90,1) ***************
[04/25/2025-09:08:45] [V] [TRT] --------------- Timing Runner: Conv_44 + Relu_45 (CaskConvolution[0x80000009])
[04/25/2025-09:08:45] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:45] [V] [TRT] --------------- Timing Runner: Conv_44 + Relu_45 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:45] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:45] [V] [TRT] *************** Autotuning format combination: Half(518400,1:8,2880,16) -> Half(259200,1:8,2880,32) ***************
[04/25/2025-09:08:45] [V] [TRT] --------------- Timing Runner: Conv_44 + Relu_45 (CaskConvolution[0x80000009])
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xdce100b9fe609424 Time: 0.0388389
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xa9177bbe4e767df8 Time: 0.0322121
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x05b6220f243edacd Time: 0.028789
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 0x60da8c7151d91e47 Time: 0.0322121
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xdfa020ef435ef810 Time: 0.0205864
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x5568fd8a32f4a40f Time: 0.0291109
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xc0a02dc6095497cc Time: 0.0211278
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xb4bec086187edcfc Time: 0.0279406
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x57c9a5ff682354a6 Time: 0.0215458
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xdb0b80f591d1bb6d Time: 0.0279893
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x31d93dc22d2af081 Time: 0.0372663
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x5820b3dda403c4d0 Time: 0.0556373
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 0xb17d53d15dfbfc9e Time: 0.0330898
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x21b295c0c8f6c95a Time: 0.0289353
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xe1ff5ad20f5c6bf6 Time: 0.0542232
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xbd08239a9317f2fd Time: 0.028672
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3_aACCESS Tactic: 0x0866ddee325d07a6 Time: 0.0254781
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xa570c55d303796ff Time: 0.0236774
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x4a81ea1e51436a30 Time: 0.036864
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x0e07ff4f4f7c1ac9 Time: 0.0205838
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xc9d24bd069159fa8 Time: 0.0287305
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3_aACCESS Tactic: 0x263a38afd75e3a43 Time: 0.0287598
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x60c3421152ef8e10 Time: 0.0211487
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: 0xa1a20ea714d420f4 Time: 0.0331191
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xf79479a62ea9f901 Time: 0.041728
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xa83b68f30462f971 Time: 0.0395337
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0x834e11ecd4ab9454 Time: 0.0415086
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: 0x7005d10718f6c22d Time: 0.0329143
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xd1aaad17ca35fbaa Time: 0.023552
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3_aACCESS Tactic: 0x245530c34bd6090f Time: 0.0207099
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x1x2_g1_tensor16x8x16_aACCESS Tactic: 0x841c601dec2a75bc Time: 0.0332361
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3_aACCESS Tactic: 0x30e8a8d7a953e5e9 Time: 0.032651
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x048d6d0400f33439 Time: 0.0322999
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xafd1e8bf6bd3d638 Time: 0.0275261
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xf35e0311fa1cc516 Time: 0.0374846
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x529f4431bdae94f5 Time: 0.0233855
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xa40cb43c296a36a8 Time: 0.0392046
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x3e7eb35b91b9fa63 Time: 0.0413623
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage4_warpsize2x1x2_g1_tensor16x8x16 Tactic: 0x7273dde1d0cd3bd5 Time: 0.0296667
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x17ebf0c9f418f10a Time: 0.0274286
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xa033e20ae9f412b2 Time: 0.0541745
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x866e7a5f6401b67f Time: 0.0207726
[04/25/2025-09:08:45] [V] [TRT] Conv_44 + Relu_45 (CaskConvolution[0x80000009]) profiling completed in 0.100676 seconds. Fastest Tactic: 0x0e07ff4f4f7c1ac9 Time: 0.0205838
[04/25/2025-09:08:45] [V] [TRT] --------------- Timing Runner: Conv_44 + Relu_45 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:45] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:45] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x0e07ff4f4f7c1ac9
[04/25/2025-09:08:45] [V] [TRT] =============== Computing costs for Conv_46 + Relu_47
[04/25/2025-09:08:45] [V] [TRT] *************** Autotuning format combination: Float(2073600,8100,90,1) -> Float(2073600,8100,90,1) ***************
[04/25/2025-09:08:45] [V] [TRT] --------------- Timing Runner: Conv_46 + Relu_47 (CaskConvolution[0x80000009])
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: 0xf067e6205da31c2e Time: 0.192951
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 0x5deb29b7a8e275f7 Time: 0.201728
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 0x503619c69ae500ff Time: 0.180078
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 0x3f243c490d502deb Time: 0.205678
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize1x4x1_g1_ffma_aligna4_alignc4_beta0_packed_stride Tactic: 0xede36641840ce3d2 Time: 0.232448
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xa9366041633a5135 Time: 0.444123
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP5_TQ5_C1_R3_S3_U1_V1 Tactic: 0x4165f9dd71b6e38a Time: 0.320951
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP4_TQ7_C4_R3_S3_U1_V1 Tactic: 0x753397072379d6e9 Time: 0.383122
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize4x1x1_g1_ffma_aligna4_alignc4_beta0_packed_stride Tactic: 0x1673e3594ce11cea Time: 0.249417
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_wngd_f32f32_f32_f32_nchwkcrs_nchw_tilesize8x16x32x8_warpsize8x1x1_wngd2x2 Tactic: 0xe47e164f4a743900 Time: 0.166619
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP7_TQ4_C1_R3_S3_U1_V1 Tactic: 0xe2f49879bec27b91 Time: 0.375954
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ5_C1_R3_S3_U1_V1 Tactic: 0x5ac6bfe0a27fc97b Time: 0.586752
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP4_TQ8_C1_R3_S3_U1_V1 Tactic: 0x36209b75daa96278 Time: 0.449243
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xcb8a43f748d8a338 Time: 0.41472
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP4_TQ7_C2_R3_S3_U1_V1 Tactic: 0x57c1b87347e45486 Time: 0.488302
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x5aa723e0481da855 Time: 0.213577
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP5_TQ7_C8_R3_S3_U1_V1 Tactic: 0x688222fe126a1c16 Time: 0.344649
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4_beta0_packed_stride Tactic: 0x7fc93550f5b9c127 Time: 0.193975
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec1_1_TP7_TQ8_C8_R3_S3_U1_V1 Tactic: 0x06cd3594e0105153 Time: 0.223232
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x40a12e3938221818 Time: 0.540965
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x01cf8ce2da913006 Time: 0.215186
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xb0bf940d5e0f9f45 Time: 0.338066
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xd828f024626fa982 Time: 0.339822
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP6_TQ5_C2_R3_S3_U1_V1 Tactic: 0x1e01f84aaf51153a Time: 0.407552
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize2x2x1_g1_ffma_aligna4_alignc4_beta0_packed_stride Tactic: 0x31aa67f57c5aea77 Time: 0.227319
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ8_C4_R3_S3_U1_V1 Tactic: 0x4bb6b59660d316a7 Time: 0.432128
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP4_TQ5_C2_R3_S3_U1_V1 Tactic: 0xed12ab640715a7d9 Time: 0.308809
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x9d9fdb5fd9945f64 Time: 0.391168
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x4efce38acc876f5c Time: 0.298277
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP4_TQ5_C1_R3_S3_U1_V1 Tactic: 0x193012cc899e2dab Time: 0.310126
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x4727434768e46395 Time: 0.293595
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec1_1_TP6_TQ8_C8_R3_S3_U1_V1 Tactic: 0xee473898b5318f6e Time: 0.228498
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_wngd_f32f32_f32_f32_nchwkcrs_nchw_tilesize8x16x16x8_warpsize8x1x1_wngd2x2 Tactic: 0xe38e9dfd56c33779 Time: 0.168814
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP8_TQ7_C4_R3_S3_U1_V1 Tactic: 0x372f7588455e8e60 Time: 0.412672
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP5_TQ7_C2_R3_S3_U1_V1 Tactic: 0xbf4bb57f12c58abb Time: 0.496347
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP4_TQ7_C1_R3_S3_U1_V1 Tactic: 0xfb8cf2d51feb56fa Time: 0.405797
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP4_TQ8_C2_R3_S3_U1_V1 Tactic: 0xc20222dd5422e80a Time: 0.396581
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP8_TQ5_C2_R3_S3_U1_V1 Tactic: 0x1fd1aff6cc3bef4c Time: 0.571538
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ7_C2_R3_S3_U1_V1 Tactic: 0xfc87004c17882844 Time: 0.451438
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP2_TQ5_C2_R3_S3_U1_V1 Tactic: 0x2947743108c340d8 Time: 0.332215
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 0x94119b4c514b211a Time: 0.14336
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: 0xa8609adc4e0ceb90 Time: 0.24971
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ6_C8_R3_S3_U1_V1 Tactic: 0x937cb0540b9a0c03 Time: 0.361765
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP5_TQ7_C4_R3_S3_U1_V1 Tactic: 0x2d667c16db5118c8 Time: 0.299593
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: 0xf64396b97c889179 Time: 0.213138
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ7_C8_R3_S3_U1_V1 Tactic: 0x732164c3c1a336e7 Time: 0.516389
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize4x1x1_g1_ffma_t1r3s3_aligna4_alignc4_beta0_packed_stride Tactic: 0xe640ceafd7d34ca9 Time: 0.232302
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ7_C4_R3_S3_U1_V1 Tactic: 0x861adc36a5912225 Time: 0.39819
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x12dbf7d94ee3696d Time: 0.190757
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x8ad32616b1424be4 Time: 0.351963
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize2x2x1_g1_ffma_t1r3s3_aligna4_alignc4_beta0_packed_stride Tactic: 0x3712e3e595645874 Time: 0.214601
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_wngd_f32f32_f32_f32_nchwkcrs_nchw_tilesize8x16x64x8_warpsize8x1x1_wngd2x2 Tactic: 0x0190806602534cfd Time: 0.145847
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP3_TQ7_C8_R3_S3_U1_V1 Tactic: 0xacd7fdab1dbcfb17 Time: 0.264347
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP8_TQ5_C4_R3_S3_U1_V1 Tactic: 0x654c738c7e22e52d Time: 0.473527
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP7_TQ3_C1_R3_S3_U1_V1 Tactic: 0xf40c46e2397ffca2 Time: 0.309541
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP2_TQ7_C2_R3_S3_U1_V1 Tactic: 0x7b24723533bf2b95 Time: 0.313783
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP5_TQ7_C4_R3_S3_U1_V1 Tactic: 0xc5d66905a0dc80da Time: 0.336165
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP5_TQ8_C8_R3_S3_U1_V1 Tactic: 0xfd41b85001aca09a Time: 0.377563
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ4_C1_R3_S3_U1_V1 Tactic: 0xba9b6b776846f39f Time: 0.599918
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP8_TQ5_C8_R3_S3_U1_V1 Tactic: 0x9077cb791a10f1ef Time: 0.380197
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP5_TQ7_C2_R3_S3_U1_V1 Tactic: 0xe7244671c44102b5 Time: 0.410917
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP5_TQ7_C4_R3_S3_U1_V1 Tactic: 0x9db99a0b765808d4 Time: 0.314368
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP7_TQ5_C1_R3_S3_U1_V1 Tactic: 0x02a94cee74fb4175 Time: 0.37771
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP4_TQ8_C4_R3_S3_U1_V1 Tactic: 0xb89ffea7e63be26b Time: 0.329874
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec1_1_TP4_TQ7_C1_R3_S3_U1_V1 Tactic: 0x1ba3392c2d9e8dc2 Time: 0.294912
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xa31d27de74b895ff Time: 0.307639
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP5_TQ7_C1_R3_S3_U1_V1 Tactic: 0x1306ffd94aca88c7 Time: 0.401262
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xbb8c3889c7eacd30 Time: 0.298281
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec1_1_TP6_TQ8_C2_R3_S3_U1_V1 Tactic: 0x61e15c17631a91cd Time: 0.237568
[04/25/2025-09:08:45] [V] [TRT] Conv_46 + Relu_47 (CaskConvolution[0x80000009]) profiling completed in 0.430941 seconds. Fastest Tactic: 0x94119b4c514b211a Time: 0.14336
[04/25/2025-09:08:45] [V] [TRT] --------------- Timing Runner: Conv_46 + Relu_47 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:45] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:45] [V] [TRT] --------------- Timing Runner: Conv_46 + Relu_47 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:45] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:45] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x94119b4c514b211a
[04/25/2025-09:08:45] [V] [TRT] *************** Autotuning format combination: Float(2073600,1,23040,256) -> Float(2073600,1,23040,256) ***************
[04/25/2025-09:08:45] [V] [TRT] --------------- Timing Runner: Conv_46 + Relu_47 (CaskConvolution[0x80000009])
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x3f0c846d6379bc98 Time: 0.181541
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x19b688348f983aa0 Time: 0.281454
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0xf48db81f02eca9ee Time: 0.238153
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x92ed3100c35fc43e Time: 0.341723
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x5953bec563d26434 Time: 0.424667
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x8014228ec08b4d49 Time: 0.183589
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x1da91d865428f237 Time: 0.242981
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x4fd3c46622e98342 Time: 0.536722
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x32059de4888dfdda Time: 0.507173
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x7121ec1db3f80c67 Time: 0.428178
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0xd15dd11d64344e83 Time: 0.242834
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x0a143be7a52f301a Time: 0.436809
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x62835fce994f06dd Time: 0.27648
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xa6448a1e79f1ca6f Time: 0.301787
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x94a7db94ba744c45 Time: 0.288183
[04/25/2025-09:08:45] [V] [TRT] Conv_46 + Relu_47 (CaskConvolution[0x80000009]) profiling completed in 0.0782698 seconds. Fastest Tactic: 0x3f0c846d6379bc98 Time: 0.181541
[04/25/2025-09:08:45] [V] [TRT] --------------- Timing Runner: Conv_46 + Relu_47 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:45] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:45] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x3f0c846d6379bc98
[04/25/2025-09:08:45] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,5760,64) -> Float(2073600,8100,90,1) ***************
[04/25/2025-09:08:45] [V] [TRT] --------------- Timing Runner: Conv_46 + Relu_47 (CaskConvolution[0x80000009])
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_alignc4 Tactic: 0xe8f7b6a5bab325f8 Time: 0.125733
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_alignc4 Tactic: 0x9fd9fe001908ce2e Time: 0.120101
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3_alignc4 Tactic: 0x1323e48791e2f671 Time: 0.118053
[04/25/2025-09:08:45] [V] [TRT] Conv_46 + Relu_47 (CaskConvolution[0x80000009]) profiling completed in 0.012323 seconds. Fastest Tactic: 0x1323e48791e2f671 Time: 0.118053
[04/25/2025-09:08:45] [V] [TRT] --------------- Timing Runner: Conv_46 + Relu_47 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:45] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:45] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x1323e48791e2f671
[04/25/2025-09:08:45] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,5760,64) -> Float(518400,1:4,5760,64) ***************
[04/25/2025-09:08:45] [V] [TRT] --------------- Timing Runner: Conv_46 + Relu_47 (CaskConvolution[0x80000009])
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 0xbdfdef6b84f7ccc9 Time: 0.202167
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0x3e2b881168d9689d Time: 0.210798
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0xf90060ce8193b811 Time: 0.204215
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x7bc32c782b800c48 Time: 0.18432
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0xb443c221fcb1565b Time: 0.118711
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 0x999e005e3b016ea6 Time: 0.116805
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0x65e41d81f093b482 Time: 0.124123
[04/25/2025-09:08:45] [V] [TRT] Conv_46 + Relu_47 (CaskConvolution[0x80000009]) profiling completed in 0.0259836 seconds. Fastest Tactic: 0x999e005e3b016ea6 Time: 0.116805
[04/25/2025-09:08:45] [V] [TRT] --------------- Timing Runner: Conv_46 + Relu_47 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:45] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:45] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x999e005e3b016ea6
[04/25/2025-09:08:45] [V] [TRT] *************** Autotuning format combination: Half(2073600,8100,90,1) -> Half(2073600,8100,90,1) ***************
[04/25/2025-09:08:45] [V] [TRT] --------------- Timing Runner: Conv_46 + Relu_47 (CaskConvolution[0x80000009])
[04/25/2025-09:08:45] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:45] [V] [TRT] --------------- Timing Runner: Conv_46 + Relu_47 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:45] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:45] [V] [TRT] --------------- Timing Runner: Conv_46 + Relu_47 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:45] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:45] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:2,11520,128) -> Half(1036800,1:2,11520,128) ***************
[04/25/2025-09:08:45] [V] [TRT] --------------- Timing Runner: Conv_46 + Relu_47 (CaskConvolution[0x80000009])
[04/25/2025-09:08:45] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:45] [V] [TRT] --------------- Timing Runner: Conv_46 + Relu_47 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:45] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:45] [V] [TRT] *************** Autotuning format combination: Half(518400,1:4,5760,64) -> Half(518400,1:4,5760,64) ***************
[04/25/2025-09:08:45] [V] [TRT] --------------- Timing Runner: Conv_46 + Relu_47 (CaskConvolution[0x80000009])
[04/25/2025-09:08:45] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:45] [V] [TRT] --------------- Timing Runner: Conv_46 + Relu_47 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:45] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:45] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,2880,32) -> Float(2073600,8100,90,1) ***************
[04/25/2025-09:08:45] [V] [TRT] --------------- Timing Runner: Conv_46 + Relu_47 (CaskConvolution[0x80000009])
[04/25/2025-09:08:45] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:45] [V] [TRT] --------------- Timing Runner: Conv_46 + Relu_47 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:45] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:45] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,2880,32) -> Half(259200,1:8,2880,32) ***************
[04/25/2025-09:08:45] [V] [TRT] --------------- Timing Runner: Conv_46 + Relu_47 (CaskConvolution[0x80000009])
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xdce100b9fe609424 Time: 0.0772389
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xa9177bbe4e767df8 Time: 0.0594895
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x05b6220f243edacd Time: 0.0506149
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 0x60da8c7151d91e47 Time: 0.059587
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xdfa020ef435ef810 Time: 0.0359863
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_wngd_f16f16_f16_f16_nhwckrsc_nhwc_tilesize8x16x32x32_warpsize8x1x1_wngd2x2 Tactic: 0xded5318b4a444b84 Time: 0.072704
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x5568fd8a32f4a40f Time: 0.0508099
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xc0a02dc6095497cc Time: 0.0362069
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xb4bec086187edcfc Time: 0.0500297
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x57c9a5ff682354a6 Time: 0.0366811
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xdb0b80f591d1bb6d Time: 0.0516389
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x31d93dc22d2af081 Time: 0.0671451
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x5820b3dda403c4d0 Time: 0.100279
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 0xb17d53d15dfbfc9e Time: 0.0609036
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x21b295c0c8f6c95a Time: 0.0508099
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xe1ff5ad20f5c6bf6 Time: 0.0999131
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xbd08239a9317f2fd Time: 0.050176
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3_aACCESS Tactic: 0x0866ddee325d07a6 Time: 0.0390583
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xa570c55d303796ff Time: 0.043776
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x4a81ea1e51436a30 Time: 0.0671939
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x0e07ff4f4f7c1ac9 Time: 0.0354322
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xc9d24bd069159fa8 Time: 0.0500297
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3_aACCESS Tactic: 0x263a38afd75e3a43 Time: 0.0373394
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x60c3421152ef8e10 Time: 0.0357303
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: 0xa1a20ea714d420f4 Time: 0.0594895
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xf79479a62ea9f901 Time: 0.0805303
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xa83b68f30462f971 Time: 0.0761417
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0x834e11ecd4ab9454 Time: 0.0800914
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_wngd_f16f16_f16_f16_nhwckrsc_nhwc_tilesize16x16x64x16_warpsize8x1x1_wngd2x2 Tactic: 0xe29800439b9d3cf7 Time: 0.0721966
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: 0x7005d10718f6c22d Time: 0.0605623
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xd1aaad17ca35fbaa Time: 0.0438126
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3_aACCESS Tactic: 0x245530c34bd6090f Time: 0.0333239
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x1x2_g1_tensor16x8x16_aACCESS Tactic: 0x841c601dec2a75bc Time: 0.0491032
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3_aACCESS Tactic: 0x30e8a8d7a953e5e9 Time: 0.0488122
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x048d6d0400f33439 Time: 0.0593432
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xafd1e8bf6bd3d638 Time: 0.0515444
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xf35e0311fa1cc516 Time: 0.0672914
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x529f4431bdae94f5 Time: 0.0435566
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xa40cb43c296a36a8 Time: 0.0759954
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x3e7eb35b91b9fa63 Time: 0.0806766
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage4_warpsize2x1x2_g1_tensor16x8x16 Tactic: 0x7273dde1d0cd3bd5 Time: 0.0511025
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x17ebf0c9f418f10a Time: 0.051395
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xa033e20ae9f412b2 Time: 0.0996206
[04/25/2025-09:08:45] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x866e7a5f6401b67f Time: 0.0361691
[04/25/2025-09:08:45] [V] [TRT] Conv_46 + Relu_47 (CaskConvolution[0x80000009]) profiling completed in 0.120987 seconds. Fastest Tactic: 0x245530c34bd6090f Time: 0.0333239
[04/25/2025-09:08:45] [V] [TRT] --------------- Timing Runner: Conv_46 + Relu_47 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:45] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:45] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x245530c34bd6090f
[04/25/2025-09:08:45] [V] [TRT] =============== Computing costs for Conv_48 + Relu_49
[04/25/2025-09:08:45] [V] [TRT] *************** Autotuning format combination: Float(2073600,8100,90,1) -> Float(2073600,8100,90,1) ***************
[04/25/2025-09:08:45] [V] [TRT] *************** Autotuning format combination: Float(2073600,1,23040,256) -> Float(2073600,1,23040,256) ***************
[04/25/2025-09:08:45] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,5760,64) -> Float(2073600,8100,90,1) ***************
[04/25/2025-09:08:45] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,5760,64) -> Float(518400,1:4,5760,64) ***************
[04/25/2025-09:08:45] [V] [TRT] *************** Autotuning format combination: Half(2073600,8100,90,1) -> Half(2073600,8100,90,1) ***************
[04/25/2025-09:08:45] [V] [TRT] --------------- Timing Runner: Conv_48 + Relu_49 (CaskConvolution[0x80000009])
[04/25/2025-09:08:45] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:45] [V] [TRT] --------------- Timing Runner: Conv_48 + Relu_49 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:45] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:45] [V] [TRT] --------------- Timing Runner: Conv_48 + Relu_49 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:45] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:45] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:2,11520,128) -> Half(1036800,1:2,11520,128) ***************
[04/25/2025-09:08:46] [V] [TRT] --------------- Timing Runner: Conv_48 + Relu_49 (CaskConvolution[0x80000009])
[04/25/2025-09:08:46] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:46] [V] [TRT] --------------- Timing Runner: Conv_48 + Relu_49 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:46] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:46] [V] [TRT] *************** Autotuning format combination: Half(518400,1:4,5760,64) -> Half(518400,1:4,5760,64) ***************
[04/25/2025-09:08:46] [V] [TRT] --------------- Timing Runner: Conv_48 + Relu_49 (CaskConvolution[0x80000009])
[04/25/2025-09:08:46] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:46] [V] [TRT] --------------- Timing Runner: Conv_48 + Relu_49 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:46] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:46] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,2880,32) -> Float(2073600,8100,90,1) ***************
[04/25/2025-09:08:46] [V] [TRT] --------------- Timing Runner: Conv_48 + Relu_49 (CaskConvolution[0x80000009])
[04/25/2025-09:08:46] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:46] [V] [TRT] --------------- Timing Runner: Conv_48 + Relu_49 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:46] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:46] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,2880,32) -> Half(259200,1:8,2880,32) ***************
[04/25/2025-09:08:46] [V] [TRT] =============== Computing costs for Conv_50 + Relu_51
[04/25/2025-09:08:46] [V] [TRT] *************** Autotuning format combination: Float(2073600,8100,90,1) -> Float(2073600,8100,90,1) ***************
[04/25/2025-09:08:46] [V] [TRT] *************** Autotuning format combination: Float(2073600,1,23040,256) -> Float(2073600,1,23040,256) ***************
[04/25/2025-09:08:46] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,5760,64) -> Float(2073600,8100,90,1) ***************
[04/25/2025-09:08:46] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,5760,64) -> Float(518400,1:4,5760,64) ***************
[04/25/2025-09:08:46] [V] [TRT] *************** Autotuning format combination: Half(2073600,8100,90,1) -> Half(2073600,8100,90,1) ***************
[04/25/2025-09:08:46] [V] [TRT] --------------- Timing Runner: Conv_50 + Relu_51 (CaskConvolution[0x80000009])
[04/25/2025-09:08:46] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:46] [V] [TRT] --------------- Timing Runner: Conv_50 + Relu_51 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:46] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:46] [V] [TRT] --------------- Timing Runner: Conv_50 + Relu_51 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:46] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:46] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:2,11520,128) -> Half(1036800,1:2,11520,128) ***************
[04/25/2025-09:08:46] [V] [TRT] --------------- Timing Runner: Conv_50 + Relu_51 (CaskConvolution[0x80000009])
[04/25/2025-09:08:46] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:46] [V] [TRT] --------------- Timing Runner: Conv_50 + Relu_51 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:46] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:46] [V] [TRT] *************** Autotuning format combination: Half(518400,1:4,5760,64) -> Half(518400,1:4,5760,64) ***************
[04/25/2025-09:08:46] [V] [TRT] --------------- Timing Runner: Conv_50 + Relu_51 (CaskConvolution[0x80000009])
[04/25/2025-09:08:46] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:46] [V] [TRT] --------------- Timing Runner: Conv_50 + Relu_51 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:46] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:46] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,2880,32) -> Float(2073600,8100,90,1) ***************
[04/25/2025-09:08:46] [V] [TRT] --------------- Timing Runner: Conv_50 + Relu_51 (CaskConvolution[0x80000009])
[04/25/2025-09:08:46] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:46] [V] [TRT] --------------- Timing Runner: Conv_50 + Relu_51 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:46] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:46] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,2880,32) -> Half(259200,1:8,2880,32) ***************
[04/25/2025-09:08:46] [V] [TRT] =============== Computing costs for Conv_52 + Relu_53
[04/25/2025-09:08:46] [V] [TRT] *************** Autotuning format combination: Float(2073600,8100,90,1) -> Float(2073600,8100,90,1) ***************
[04/25/2025-09:08:46] [V] [TRT] *************** Autotuning format combination: Float(2073600,1,23040,256) -> Float(2073600,1,23040,256) ***************
[04/25/2025-09:08:46] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,5760,64) -> Float(2073600,8100,90,1) ***************
[04/25/2025-09:08:46] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,5760,64) -> Float(518400,1:4,5760,64) ***************
[04/25/2025-09:08:46] [V] [TRT] *************** Autotuning format combination: Half(2073600,8100,90,1) -> Half(2073600,8100,90,1) ***************
[04/25/2025-09:08:46] [V] [TRT] --------------- Timing Runner: Conv_52 + Relu_53 (CaskConvolution[0x80000009])
[04/25/2025-09:08:46] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:46] [V] [TRT] --------------- Timing Runner: Conv_52 + Relu_53 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:46] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:46] [V] [TRT] --------------- Timing Runner: Conv_52 + Relu_53 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:46] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:46] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:2,11520,128) -> Half(1036800,1:2,11520,128) ***************
[04/25/2025-09:08:46] [V] [TRT] --------------- Timing Runner: Conv_52 + Relu_53 (CaskConvolution[0x80000009])
[04/25/2025-09:08:46] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:46] [V] [TRT] --------------- Timing Runner: Conv_52 + Relu_53 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:46] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:46] [V] [TRT] *************** Autotuning format combination: Half(518400,1:4,5760,64) -> Half(518400,1:4,5760,64) ***************
[04/25/2025-09:08:46] [V] [TRT] --------------- Timing Runner: Conv_52 + Relu_53 (CaskConvolution[0x80000009])
[04/25/2025-09:08:46] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:46] [V] [TRT] --------------- Timing Runner: Conv_52 + Relu_53 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:46] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:46] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,2880,32) -> Float(2073600,8100,90,1) ***************
[04/25/2025-09:08:46] [V] [TRT] --------------- Timing Runner: Conv_52 + Relu_53 (CaskConvolution[0x80000009])
[04/25/2025-09:08:46] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:46] [V] [TRT] --------------- Timing Runner: Conv_52 + Relu_53 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:46] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:46] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,2880,32) -> Half(259200,1:8,2880,32) ***************
[04/25/2025-09:08:46] [V] [TRT] =============== Computing costs for Conv_54 + Relu_55
[04/25/2025-09:08:46] [V] [TRT] *************** Autotuning format combination: Float(2073600,8100,90,1) -> Float(2073600,8100,90,1) ***************
[04/25/2025-09:08:46] [V] [TRT] *************** Autotuning format combination: Float(2073600,1,23040,256) -> Float(2073600,1,23040,256) ***************
[04/25/2025-09:08:46] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,5760,64) -> Float(2073600,8100,90,1) ***************
[04/25/2025-09:08:46] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,5760,64) -> Float(518400,1:4,5760,64) ***************
[04/25/2025-09:08:46] [V] [TRT] *************** Autotuning format combination: Half(2073600,8100,90,1) -> Half(2073600,8100,90,1) ***************
[04/25/2025-09:08:46] [V] [TRT] --------------- Timing Runner: Conv_54 + Relu_55 (CaskConvolution[0x80000009])
[04/25/2025-09:08:46] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:46] [V] [TRT] --------------- Timing Runner: Conv_54 + Relu_55 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:46] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:46] [V] [TRT] --------------- Timing Runner: Conv_54 + Relu_55 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:46] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:46] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:2,11520,128) -> Half(1036800,1:2,11520,128) ***************
[04/25/2025-09:08:46] [V] [TRT] --------------- Timing Runner: Conv_54 + Relu_55 (CaskConvolution[0x80000009])
[04/25/2025-09:08:46] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:46] [V] [TRT] --------------- Timing Runner: Conv_54 + Relu_55 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:46] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:46] [V] [TRT] *************** Autotuning format combination: Half(518400,1:4,5760,64) -> Half(518400,1:4,5760,64) ***************
[04/25/2025-09:08:46] [V] [TRT] --------------- Timing Runner: Conv_54 + Relu_55 (CaskConvolution[0x80000009])
[04/25/2025-09:08:46] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:46] [V] [TRT] --------------- Timing Runner: Conv_54 + Relu_55 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:46] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:46] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,2880,32) -> Float(2073600,8100,90,1) ***************
[04/25/2025-09:08:46] [V] [TRT] --------------- Timing Runner: Conv_54 + Relu_55 (CaskConvolution[0x80000009])
[04/25/2025-09:08:46] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:46] [V] [TRT] --------------- Timing Runner: Conv_54 + Relu_55 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:46] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:46] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,2880,32) -> Half(259200,1:8,2880,32) ***************
[04/25/2025-09:08:46] [V] [TRT] =============== Computing costs for ConvTranspose_56 + BatchNormalization_57 + Relu_58
[04/25/2025-09:08:46] [V] [TRT] *************** Autotuning format combination: Float(2073600,8100,90,1) -> Float(16588800,32400,180,1) long-strided ***************
[04/25/2025-09:08:46] [V] [TRT] RunnerBuilder of layer implementation CudnnDeconvolution cannot handle striding for node ConvTranspose_56 + BatchNormalization_57 + Relu_58
[04/25/2025-09:08:46] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (GemmDeconvolution[0x80000010])
[04/25/2025-09:08:46] [V] [TRT] GemmDeconvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:46] [V] [TRT] ConvTranspose_56 + BatchNormalization_57 + Relu_58: 66 available tactics, 0 unparsable, 33 pruned, 33 remaining after tactic pruning.
[04/25/2025-09:08:46] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskGemmDeconvolution[0x80000037])
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize64x128x16_stage4_warpsize2x2x1_tensor16x8x8_aligna4_alignc4 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020343 Time: 0.139849
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize128x128x16_stage4_warpsize2x2x1_tensor16x8x8_aligna4_alignc4 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020597 Time: 0.141019
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize128x64x16_stage6_warpsize2x2x1_tensor16x8x8_aligna4_alignc4 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000202ff Time: 0.165157
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize64x128x16_stage4_warpsize2x2x1_tensor16x8x8_aligna4_alignc4 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x0000000002040343 Time: 0.165595
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize64x128x16_stage4_warpsize2x2x1_tensor16x8x8_aligna4_alignc4 numSplitK: 2 numBuffers: 2 numKernels: 2 Tactic: 0x0000000204040343 Time: 0.230107
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize128x128x16_stage4_warpsize2x2x1_tensor16x8x8_aligna4_alignc4 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x0000000002040597 Time: 0.183296
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize32x64x64_stage4_warpsize2x2x1_tensor16x8x8_aligna4_alignc4 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020617 Time: 0.230546
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize128x64x16_stage6_warpsize2x2x1_tensor16x8x8_aligna4_alignc4 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x00000000020402ff Time: 0.213723
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize128x128x16_stage4_warpsize2x2x1_tensor16x8x8_aligna4_alignc4 numSplitK: 2 numBuffers: 2 numKernels: 2 Tactic: 0x0000000204040597 Time: 0.244443
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize128x64x16_stage6_warpsize2x2x1_tensor16x8x8_aligna4_alignc4 numSplitK: 2 numBuffers: 2 numKernels: 2 Tactic: 0x00000002040402ff Time: 0.267118
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize32x32x64_stage3_warpsize2x2x1_tensor16x8x8_aligna4_alignc4 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000203dd Time: 0.229376
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_nn_n_tilesize64x256x8_stage3_warpsize1x4x1_ffma_aligna4_alignc4 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000203da Time: 0.151259
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_nn_n_tilesize256x64x8_stage3_warpsize2x2x1_ffma_aligna4_alignc4 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000202e1 Time: 0.153454
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_nn_n_tilesize128x128x8_stage3_warpsize2x2x1_ffma_aligna4_alignc4 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000206e5 Time: 0.169838
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize32x32x64_stage3_warpsize2x2x1_tensor16x8x8_aligna4_alignc4 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x00000000020403dd Time: 0.305006
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_nn_n_tilesize128x256x8_stage3_warpsize2x4x1_ffma_aligna4_alignc4 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020176 Time: 0.162231
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_nn_n_tilesize256x128x8_stage3_warpsize4x2x1_ffma_aligna4_alignc4 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000202f9 Time: 0.156379
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize32x64x64_stage4_warpsize2x2x1_tensor16x8x8_aligna4_alignc4 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x0000000002040617 Time: 0.305591
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_nn_n_tilesize64x128x8_stage3_warpsize1x4x1_ffma_aligna4_alignc4 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000201a2 Time: 0.169691
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_nn_n_tilesize128x64x8_stage3_warpsize2x2x1_ffma_aligna4_alignc4 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000202e6 Time: 0.168814
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_nn_n_tilesize32x128x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020474 Time: 0.169399
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize32x32x64_stage3_warpsize2x2x1_tensor16x8x8_aligna4_alignc4 numSplitK: 2 numBuffers: 2 numKernels: 2 Tactic: 0x00000002040403dd Time: 0.350354
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize32x64x64_stage4_warpsize2x2x1_tensor16x8x8_aligna4_alignc4 numSplitK: 2 numBuffers: 2 numKernels: 2 Tactic: 0x0000000204040617 Time: 0.369957
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_nn_n_tilesize64x256x8_stage3_warpsize1x4x1_ffma_aligna4_alignc4 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x00000000020403da Time: 0.183735
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_nn_n_tilesize256x64x8_stage3_warpsize2x2x1_ffma_aligna4_alignc4 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x00000000020402e1 Time: 0.191195
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_nn_n_tilesize128x128x8_stage3_warpsize2x2x1_ffma_aligna4_alignc4 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x00000000020406e5 Time: 0.185637
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_nn_n_tilesize64x256x8_stage3_warpsize1x4x1_ffma_aligna4_alignc4 numSplitK: 2 numBuffers: 2 numKernels: 2 Tactic: 0x00000002040403da Time: 0.253513
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_nn_n_tilesize128x128x8_stage3_warpsize2x2x1_ffma_aligna4_alignc4 numSplitK: 2 numBuffers: 2 numKernels: 2 Tactic: 0x00000002040406e5 Time: 0.258487
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_nn_n_tilesize256x64x8_stage3_warpsize2x2x1_ffma_aligna4_alignc4 numSplitK: 2 numBuffers: 2 numKernels: 2 Tactic: 0x00000002040402e1 Time: 0.260681
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_nn_n_tilesize256x128x8_stage3_warpsize4x2x1_ffma_aligna4_alignc4 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x00000000020402f9 Time: 0.184613
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_nn_n_tilesize128x256x8_stage3_warpsize2x4x1_ffma_aligna4_alignc4 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x0000000002040176 Time: 0.183589
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_nn_n_tilesize64x128x8_stage3_warpsize1x4x1_ffma_aligna4_alignc4 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x00000000020401a2 Time: 0.177298
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_nn_n_tilesize128x64x8_stage3_warpsize2x2x1_ffma_aligna4_alignc4 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x00000000020402e6 Time: 0.182857
[04/25/2025-09:08:46] [V] [TRT] ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskGemmDeconvolution[0x80000037]) profiling completed in 0.169331 seconds. Fastest Tactic: 0x0000000000020343 Time: 0.139849
[04/25/2025-09:08:46] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskDeconvolution[0x8000000a])
[04/25/2025-09:08:46] [V] [TRT] CaskDeconvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:46] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskDeconvolutionV2[0x8000002d])
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm50_xmma_deconv_2d_stride_eq_filter_FP32FP32FP32NCHW_tilesize128x32x16_threadsize16x8_threadPixels4x4 Tactic: 0xbe93c53dd404a388 Time: 0.216357
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm50_xmma_deconv_3d_stride_eq_filter_FP32FP32FP32NCHW_tilesize128x32x16_threadsize16x8_threadPixels4x4 Tactic: 0xe57a5f08bb65a719 Time: 0.218834
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm50_xmma_deconv_2d_stride_eq_filter_FP32FP32FP32NCHW_tilesize128x128x32_threadsize16x16_threadPixels4x4 Tactic: 0xb4fe42a3eed4e892 Time: 0.224695
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm50_xmma_deconv_3d_stride_eq_filter_FP32FP32FP32NCHW_tilesize32x32x8_threadsize8x8_threadPixels4x4 Tactic: 0x5c1d65bb3bbd1490 Time: 0.21899
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm50_xmma_deconv_2d_stride_eq_filter_FP32FP32FP32NCHW_tilesize32x32x8_threadsize8x8_threadPixels4x4 Tactic: 0x63718a7552e7f5ad Time: 0.217819
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm50_xmma_deconv_3d_stride_eq_filter_FP32FP32FP32NCHW_tilesize128x128x32_threadsize16x16_threadPixels4x4 Tactic: 0x2b78a94a2ec1dff6 Time: 0.22528
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm50_xmma_deconv_2d_stride_eq_filter_FP32FP32FP32NCHW_tilesize32x128x16_threadsize8x16_threadPixels4x4 Tactic: 0xf1fc7e0537458603 Time: 0.202752
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm50_xmma_deconv_3d_stride_eq_filter_FP32FP32FP32NCHW_tilesize32x128x16_threadsize8x16_threadPixels4x4 Tactic: 0xaa15e43058248292 Time: 0.203191
[04/25/2025-09:08:46] [V] [TRT] ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskDeconvolutionV2[0x8000002d]) profiling completed in 0.0539753 seconds. Fastest Tactic: 0xf1fc7e0537458603 Time: 0.202752
[04/25/2025-09:08:46] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskGemmDeconvolution Tactic: 0x0000000000020343
[04/25/2025-09:08:46] [V] [TRT] *************** Autotuning format combination: Float(2073600,8100,90,1) -> Float(8294400,32400,180,1) ***************
[04/25/2025-09:08:46] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CudnnDeconvolution[0x80000002])
[04/25/2025-09:08:46] [V] [TRT] CudnnDeconvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:46] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (GemmDeconvolution[0x80000010])
[04/25/2025-09:08:46] [V] [TRT] GemmDeconvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:46] [V] [TRT] ConvTranspose_56 + BatchNormalization_57 + Relu_58: 66 available tactics, 0 unparsable, 33 pruned, 33 remaining after tactic pruning.
[04/25/2025-09:08:46] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskGemmDeconvolution[0x80000037])
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize64x128x16_stage4_warpsize2x2x1_tensor16x8x8_aligna4_alignc4 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020343 Time: 0.140654
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize128x128x16_stage4_warpsize2x2x1_tensor16x8x8_aligna4_alignc4 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020597 Time: 0.143506
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize128x64x16_stage6_warpsize2x2x1_tensor16x8x8_aligna4_alignc4 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000202ff Time: 0.167058
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize64x128x16_stage4_warpsize2x2x1_tensor16x8x8_aligna4_alignc4 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x0000000002040343 Time: 0.166766
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize64x128x16_stage4_warpsize2x2x1_tensor16x8x8_aligna4_alignc4 numSplitK: 2 numBuffers: 2 numKernels: 2 Tactic: 0x0000000204040343 Time: 0.229376
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize128x128x16_stage4_warpsize2x2x1_tensor16x8x8_aligna4_alignc4 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x0000000002040597 Time: 0.181541
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize32x64x64_stage4_warpsize2x2x1_tensor16x8x8_aligna4_alignc4 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020617 Time: 0.232741
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize128x64x16_stage6_warpsize2x2x1_tensor16x8x8_aligna4_alignc4 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x00000000020402ff Time: 0.214016
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize128x128x16_stage4_warpsize2x2x1_tensor16x8x8_aligna4_alignc4 numSplitK: 2 numBuffers: 2 numKernels: 2 Tactic: 0x0000000204040597 Time: 0.244443
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize128x64x16_stage6_warpsize2x2x1_tensor16x8x8_aligna4_alignc4 numSplitK: 2 numBuffers: 2 numKernels: 2 Tactic: 0x00000002040402ff Time: 0.308517
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize32x32x64_stage3_warpsize2x2x1_tensor16x8x8_aligna4_alignc4 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000203dd Time: 0.232155
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_nn_n_tilesize64x256x8_stage3_warpsize1x4x1_ffma_aligna4_alignc4 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000203da Time: 0.153746
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_nn_n_tilesize256x64x8_stage3_warpsize2x2x1_ffma_aligna4_alignc4 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000202e1 Time: 0.153015
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_nn_n_tilesize128x128x8_stage3_warpsize2x2x1_ffma_aligna4_alignc4 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000206e5 Time: 0.160037
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize32x32x64_stage3_warpsize2x2x1_tensor16x8x8_aligna4_alignc4 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x00000000020403dd Time: 0.302811
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_nn_n_tilesize128x256x8_stage3_warpsize2x4x1_ffma_aligna4_alignc4 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020176 Time: 0.156087
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_nn_n_tilesize256x128x8_stage3_warpsize4x2x1_ffma_aligna4_alignc4 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000202f9 Time: 0.157257
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize32x64x64_stage4_warpsize2x2x1_tensor16x8x8_aligna4_alignc4 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x0000000002040617 Time: 0.298569
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_nn_n_tilesize64x128x8_stage3_warpsize1x4x1_ffma_aligna4_alignc4 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000201a2 Time: 0.172032
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_nn_n_tilesize128x64x8_stage3_warpsize2x2x1_ffma_aligna4_alignc4 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000202e6 Time: 0.170578
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_nn_n_tilesize32x128x8_stage3_warpsize1x2x1_ffma_aligna4_alignc4 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020474 Time: 0.179639
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize32x32x64_stage3_warpsize2x2x1_tensor16x8x8_aligna4_alignc4 numSplitK: 2 numBuffers: 2 numKernels: 2 Tactic: 0x00000002040403dd Time: 0.353573
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_tf32f32_f32_nn_n_tilesize32x64x64_stage4_warpsize2x2x1_tensor16x8x8_aligna4_alignc4 numSplitK: 2 numBuffers: 2 numKernels: 2 Tactic: 0x0000000204040617 Time: 0.336613
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_nn_n_tilesize64x256x8_stage3_warpsize1x4x1_ffma_aligna4_alignc4 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x00000000020403da Time: 0.182126
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_nn_n_tilesize256x64x8_stage3_warpsize2x2x1_ffma_aligna4_alignc4 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x00000000020402e1 Time: 0.191191
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_nn_n_tilesize128x128x8_stage3_warpsize2x2x1_ffma_aligna4_alignc4 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x00000000020406e5 Time: 0.184466
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_nn_n_tilesize64x256x8_stage3_warpsize1x4x1_ffma_aligna4_alignc4 numSplitK: 2 numBuffers: 2 numKernels: 2 Tactic: 0x00000002040403da Time: 0.253367
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_nn_n_tilesize128x128x8_stage3_warpsize2x2x1_ffma_aligna4_alignc4 numSplitK: 2 numBuffers: 2 numKernels: 2 Tactic: 0x00000002040406e5 Time: 0.261413
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_nn_n_tilesize256x64x8_stage3_warpsize2x2x1_ffma_aligna4_alignc4 numSplitK: 2 numBuffers: 2 numKernels: 2 Tactic: 0x00000002040402e1 Time: 0.261559
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_nn_n_tilesize256x128x8_stage3_warpsize4x2x1_ffma_aligna4_alignc4 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x00000000020402f9 Time: 0.18315
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_nn_n_tilesize128x256x8_stage3_warpsize2x4x1_ffma_aligna4_alignc4 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x0000000002040176 Time: 0.180078
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_nn_n_tilesize64x128x8_stage3_warpsize1x4x1_ffma_aligna4_alignc4 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x00000000020401a2 Time: 0.182857
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_gemm_f32f32_f32f32_f32_nn_n_tilesize128x64x8_stage3_warpsize2x2x1_ffma_aligna4_alignc4 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x00000000020402e6 Time: 0.184905
[04/25/2025-09:08:46] [V] [TRT] ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskGemmDeconvolution[0x80000037]) profiling completed in 0.170321 seconds. Fastest Tactic: 0x0000000000020343 Time: 0.140654
[04/25/2025-09:08:46] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskDeconvolution[0x8000000a])
[04/25/2025-09:08:46] [V] [TRT] CaskDeconvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:46] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskDeconvolutionV2[0x8000002d])
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm50_xmma_deconv_2d_stride_eq_filter_FP32FP32FP32NCHW_tilesize128x32x16_threadsize16x8_threadPixels4x4 Tactic: 0xbe93c53dd404a388 Time: 0.216942
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm50_xmma_deconv_3d_stride_eq_filter_FP32FP32FP32NCHW_tilesize128x32x16_threadsize16x8_threadPixels4x4 Tactic: 0xe57a5f08bb65a719 Time: 0.217966
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm50_xmma_deconv_2d_stride_eq_filter_FP32FP32FP32NCHW_tilesize128x128x32_threadsize16x16_threadPixels4x4 Tactic: 0xb4fe42a3eed4e892 Time: 0.22411
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm50_xmma_deconv_3d_stride_eq_filter_FP32FP32FP32NCHW_tilesize32x32x8_threadsize8x8_threadPixels4x4 Tactic: 0x5c1d65bb3bbd1490 Time: 0.219867
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm50_xmma_deconv_2d_stride_eq_filter_FP32FP32FP32NCHW_tilesize32x32x8_threadsize8x8_threadPixels4x4 Tactic: 0x63718a7552e7f5ad Time: 0.218405
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm50_xmma_deconv_3d_stride_eq_filter_FP32FP32FP32NCHW_tilesize128x128x32_threadsize16x16_threadPixels4x4 Tactic: 0x2b78a94a2ec1dff6 Time: 0.225865
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm50_xmma_deconv_2d_stride_eq_filter_FP32FP32FP32NCHW_tilesize32x128x16_threadsize8x16_threadPixels4x4 Tactic: 0xf1fc7e0537458603 Time: 0.202898
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm50_xmma_deconv_3d_stride_eq_filter_FP32FP32FP32NCHW_tilesize32x128x16_threadsize8x16_threadPixels4x4 Tactic: 0xaa15e43058248292 Time: 0.203337
[04/25/2025-09:08:46] [V] [TRT] ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskDeconvolutionV2[0x8000002d]) profiling completed in 0.0541522 seconds. Fastest Tactic: 0xf1fc7e0537458603 Time: 0.202898
[04/25/2025-09:08:46] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskGemmDeconvolution Tactic: 0x0000000000020343
[04/25/2025-09:08:46] [V] [TRT] *************** Autotuning format combination: Float(2073600,1,23040,256) -> Float(16588800,1,92160,512) long-strided ***************
[04/25/2025-09:08:46] [V] [TRT] RunnerBuilder of layer implementation CudnnDeconvolution cannot handle striding for node ConvTranspose_56 + BatchNormalization_57 + Relu_58
[04/25/2025-09:08:46] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (GemmDeconvolution[0x80000010])
[04/25/2025-09:08:46] [V] [TRT] GemmDeconvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:46] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskDeconvolution[0x8000000a])
[04/25/2025-09:08:46] [V] [TRT] CaskDeconvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:46] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskDeconvolutionV2[0x8000002d])
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_strided_aligna4_alignc4 Tactic: 0x55c5f197e3b7e8aa Time: 0.137289
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xb1d8242d50afdff0 Time: 0.268434
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x14499f757787b157 Time: 0.643072
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x24bd5d7c8284eeec Time: 0.265216
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x32x8_stage3_warpsize1x2x1_g1_ffma_strided_aligna4_alignc4 Tactic: 0xf7c9fe3fcf824969 Time: 0.143214
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_strided_aligna4_alignc4 Tactic: 0xba791a7991b0361c Time: 0.107886
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_strided_aligna4_alignc4 Tactic: 0x043c81cea95f3c97 Time: 0.174665
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_strided_aligna4_alignc4 Tactic: 0x0af5b8971b78dc1f Time: 0.141824
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_strided_aligna4_alignc4 Tactic: 0x1a82ab99d94518f2 Time: 0.103131
[04/25/2025-09:08:46] [V] [TRT] ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskDeconvolutionV2[0x8000002d]) profiling completed in 0.0819977 seconds. Fastest Tactic: 0x1a82ab99d94518f2 Time: 0.103131
[04/25/2025-09:08:46] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskDeconvolutionV2 Tactic: 0x1a82ab99d94518f2
[04/25/2025-09:08:46] [V] [TRT] *************** Autotuning format combination: Float(2073600,1,23040,256) -> Float(8294400,1,46080,256) ***************
[04/25/2025-09:08:46] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CudnnDeconvolution[0x80000002])
[04/25/2025-09:08:46] [V] [TRT] CudnnDeconvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:46] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (GemmDeconvolution[0x80000010])
[04/25/2025-09:08:46] [V] [TRT] GemmDeconvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:46] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskDeconvolution[0x8000000a])
[04/25/2025-09:08:46] [V] [TRT] CaskDeconvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:46] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskDeconvolutionV2[0x8000002d])
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_strided_aligna4_alignc4 Tactic: 0x55c5f197e3b7e8aa Time: 0.136997
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xb1d8242d50afdff0 Time: 0.268581
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x14499f757787b157 Time: 0.642779
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x24bd5d7c8284eeec Time: 0.261705
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x32x8_stage3_warpsize1x2x1_g1_ffma_strided_aligna4_alignc4 Tactic: 0xf7c9fe3fcf824969 Time: 0.143945
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_strided_aligna4_alignc4 Tactic: 0xba791a7991b0361c Time: 0.107515
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_strided_aligna4_alignc4 Tactic: 0x043c81cea95f3c97 Time: 0.177152
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_strided_aligna4_alignc4 Tactic: 0x0af5b8971b78dc1f Time: 0.14197
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_strided_aligna4_alignc4 Tactic: 0x1a82ab99d94518f2 Time: 0.105911
[04/25/2025-09:08:46] [V] [TRT] ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskDeconvolutionV2[0x8000002d]) profiling completed in 0.0761239 seconds. Fastest Tactic: 0x1a82ab99d94518f2 Time: 0.105911
[04/25/2025-09:08:46] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskDeconvolutionV2 Tactic: 0x1a82ab99d94518f2
[04/25/2025-09:08:46] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,5760,64) -> Float(4147200,1:4,23040,128) long-strided ***************
[04/25/2025-09:08:46] [V] [TRT] RunnerBuilder of layer implementation CudnnDeconvolution cannot handle striding for node ConvTranspose_56 + BatchNormalization_57 + Relu_58
[04/25/2025-09:08:46] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (GemmDeconvolution[0x80000010])
[04/25/2025-09:08:46] [V] [TRT] GemmDeconvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:46] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskDeconvolution[0x8000000a])
[04/25/2025-09:08:46] [V] [TRT] CaskDeconvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:46] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskDeconvolutionV2[0x8000002d])
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_strided Tactic: 0xa17395d1f0a7b52b Time: 0.0705097
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_strided_aligna4_alignc4 Tactic: 0x55c5f197e3b7e8aa Time: 0.136338
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xb1d8242d50afdff0 Time: 0.269019
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x14499f757787b157 Time: 0.672914
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0x6f63be3116a0cf3a Time: 0.217234
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x24bd5d7c8284eeec Time: 0.262437
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm86_xmma_deconv_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x256x32_stage2_warpsize2x4x1_g1_tensor16x8x8 Tactic: 0x4298039fe7d925bf Time: 0.210213
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x32x8_stage3_warpsize1x2x1_g1_ffma_strided_aligna4_alignc4 Tactic: 0xf7c9fe3fcf824969 Time: 0.143653
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_strided_aligna4_alignc4 Tactic: 0xba791a7991b0361c Time: 0.108617
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_strided_aligna4_alignc4 Tactic: 0x043c81cea95f3c97 Time: 0.170715
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_strided_aligna4_alignc4 Tactic: 0x0af5b8971b78dc1f Time: 0.141824
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_strided_aligna4_alignc4 Tactic: 0x1a82ab99d94518f2 Time: 0.104375
[04/25/2025-09:08:46] [V] [TRT] ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskDeconvolutionV2[0x8000002d]) profiling completed in 0.108275 seconds. Fastest Tactic: 0xa17395d1f0a7b52b Time: 0.0705097
[04/25/2025-09:08:46] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskDeconvolutionV2 Tactic: 0xa17395d1f0a7b52b
[04/25/2025-09:08:46] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,5760,64) -> Float(2073600,1:4,11520,64) ***************
[04/25/2025-09:08:46] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CudnnDeconvolution[0x80000002])
[04/25/2025-09:08:46] [V] [TRT] CudnnDeconvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:46] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (GemmDeconvolution[0x80000010])
[04/25/2025-09:08:46] [V] [TRT] GemmDeconvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:46] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskDeconvolution[0x8000000a])
[04/25/2025-09:08:46] [V] [TRT] CaskDeconvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:46] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskDeconvolutionV2[0x8000002d])
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_strided Tactic: 0xa17395d1f0a7b52b Time: 0.0713387
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_strided_aligna4_alignc4 Tactic: 0x55c5f197e3b7e8aa Time: 0.136629
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xb1d8242d50afdff0 Time: 0.268873
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x14499f757787b157 Time: 0.642779
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0x6f63be3116a0cf3a Time: 0.217088
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x128x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x24bd5d7c8284eeec Time: 0.261993
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm86_xmma_deconv_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x256x32_stage2_warpsize2x4x1_g1_tensor16x8x8 Tactic: 0x4298039fe7d925bf Time: 0.20992
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x32x8_stage3_warpsize1x2x1_g1_ffma_strided_aligna4_alignc4 Tactic: 0xf7c9fe3fcf824969 Time: 0.143214
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_strided_aligna4_alignc4 Tactic: 0xba791a7991b0361c Time: 0.106862
[04/25/2025-09:08:46] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_strided_aligna4_alignc4 Tactic: 0x043c81cea95f3c97 Time: 0.173074
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_strided_aligna4_alignc4 Tactic: 0x0af5b8971b78dc1f Time: 0.141897
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_strided_aligna4_alignc4 Tactic: 0x1a82ab99d94518f2 Time: 0.102839
[04/25/2025-09:08:47] [V] [TRT] ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskDeconvolutionV2[0x8000002d]) profiling completed in 0.106694 seconds. Fastest Tactic: 0xa17395d1f0a7b52b Time: 0.0713387
[04/25/2025-09:08:47] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskDeconvolutionV2 Tactic: 0xa17395d1f0a7b52b
[04/25/2025-09:08:47] [V] [TRT] *************** Autotuning format combination: Half(2073600,8100,90,1) -> Half(16588800,32400,180,1) long-strided ***************
[04/25/2025-09:08:47] [V] [TRT] RunnerBuilder of layer implementation CudnnDeconvolution cannot handle striding for node ConvTranspose_56 + BatchNormalization_57 + Relu_58
[04/25/2025-09:08:47] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (GemmDeconvolution[0x80000010])
[04/25/2025-09:08:47] [V] [TRT] GemmDeconvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:47] [V] [TRT] ConvTranspose_56 + BatchNormalization_57 + Relu_58: 78 available tactics, 0 unparsable, 39 pruned, 39 remaining after tactic pruning.
[04/25/2025-09:08:47] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskGemmDeconvolution[0x80000037])
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x128x32_stage4_warpsize2x2x1_tensor16x8x16_aligna2_alignc2 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020340 Time: 0.103058
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize256x128x32_stage3_warpsize4x2x1_tensor16x8x16_aligna2_alignc2 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002053d Time: 0.0927451
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x256x32_stage3_warpsize2x4x1_tensor16x8x16_aligna2_alignc2 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000205b8 Time: 0.0902583
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize256x64x32_stage3_warpsize4x1x1_tensor16x8x16_aligna2_alignc2 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002091d Time: 0.121929
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x64x32_stage5_warpsize2x2x1_tensor16x8x16_aligna2_alignc2 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002058a Time: 0.132974
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize64x128x32_stage5_warpsize2x2x1_tensor16x8x16_aligna2_alignc2 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020467 Time: 0.125733
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x128x64_stage3_warpsize2x2x1_tensor16x8x16_aligna2_alignc2 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000202f3 Time: 0.117467
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x64x64_stage3_warpsize2x2x1_tensor16x8x16_aligna2_alignc2 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002053a Time: 0.118491
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize64x64x64_stage4_warpsize2x2x1_tensor16x8x16_aligna2_alignc2 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000206f0 Time: 0.145403
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize64x32x64_stage5_warpsize2x2x1_tensor16x8x16_aligna2_alignc2 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002093f Time: 0.20085
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x128x32_stage4_warpsize2x2x1_tensor16x8x16_aligna2_alignc2 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x0000000002040340 Time: 0.126537
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x256x32_stage3_warpsize2x4x1_tensor16x8x16_aligna2_alignc2 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x00000000020405b8 Time: 0.107593
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize256x128x32_stage3_warpsize4x2x1_tensor16x8x16_aligna2_alignc2 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x000000000204053d Time: 0.111397
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize256x64x32_stage3_warpsize4x1x1_tensor16x8x16_aligna2_alignc2 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x000000000204091d Time: 0.142267
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x64x32_stage5_warpsize2x2x1_tensor16x8x16_aligna2_alignc2 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x000000000204058a Time: 0.165449
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize64x128x32_stage5_warpsize2x2x1_tensor16x8x16_aligna2_alignc2 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x0000000002040467 Time: 0.158281
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x128x32_stage4_warpsize2x2x1_tensor16x8x16_aligna2_alignc2 numSplitK: 2 numBuffers: 2 numKernels: 2 Tactic: 0x0000000204040340 Time: 0.130633
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x256x32_stage3_warpsize2x4x1_tensor16x8x16_aligna2_alignc2 numSplitK: 2 numBuffers: 2 numKernels: 2 Tactic: 0x00000002040405b8 Time: 0.119877
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize256x128x32_stage3_warpsize4x2x1_tensor16x8x16_aligna2_alignc2 numSplitK: 2 numBuffers: 2 numKernels: 2 Tactic: 0x000000020404053d Time: 0.123026
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize256x64x32_stage3_warpsize4x1x1_tensor16x8x16_aligna2_alignc2 numSplitK: 2 numBuffers: 2 numKernels: 2 Tactic: 0x000000020404091d Time: 0.145408
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x128x64_stage3_warpsize2x2x1_tensor16x8x16_aligna2_alignc2 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x00000000020402f3 Time: 0.141899
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x64x32_stage5_warpsize2x2x1_tensor16x8x16_aligna2_alignc2 numSplitK: 2 numBuffers: 2 numKernels: 2 Tactic: 0x000000020404058a Time: 0.160475
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize64x128x32_stage5_warpsize2x2x1_tensor16x8x16_aligna2_alignc2 numSplitK: 2 numBuffers: 2 numKernels: 2 Tactic: 0x0000000204040467 Time: 0.155648
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x64x64_stage3_warpsize2x2x1_tensor16x8x16_aligna2_alignc2 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x000000000204053a Time: 0.150674
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x128x64_stage3_warpsize2x2x1_tensor16x8x16_aligna2_alignc2 numSplitK: 2 numBuffers: 2 numKernels: 2 Tactic: 0x00000002040402f3 Time: 0.143945
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x16_aligna2_alignc2 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000206f4 Time: 0.21109
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x64x64_stage3_warpsize2x2x1_tensor16x8x16_aligna2_alignc2 numSplitK: 2 numBuffers: 2 numKernels: 2 Tactic: 0x000000020404053a Time: 0.146578
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize64x64x64_stage4_warpsize2x2x1_tensor16x8x16_aligna2_alignc2 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x00000000020406f0 Time: 0.186953
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize64x64x64_stage4_warpsize2x2x1_tensor16x8x16_aligna2_alignc2 numSplitK: 2 numBuffers: 2 numKernels: 2 Tactic: 0x00000002040406f0 Time: 0.176279
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x16_aligna2_alignc2 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x00000000020406f4 Time: 0.256718
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x16_aligna2_alignc2 numSplitK: 2 numBuffers: 2 numKernels: 2 Tactic: 0x00000002040406f4 Time: 0.243849
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize64x32x64_stage5_warpsize2x2x1_tensor16x8x16_aligna2_alignc2 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x000000000204093f Time: 0.267118
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize64x32x64_stage5_warpsize2x2x1_tensor16x8x16_aligna2_alignc2 numSplitK: 2 numBuffers: 2 numKernels: 2 Tactic: 0x000000020404093f Time: 0.244005
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f32f32_f32_nn_n_tilesize64x32x8_stage3_warpsize1x2x1_ffma_aligna2_alignc2 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020669 Time: 0.163109
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f32f32_f32_nn_n_tilesize32x64x8_stage3_warpsize1x2x1_ffma_aligna2_alignc2 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020277 Time: 0.173641
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f32f32_f32_nn_n_tilesize32x128x8_stage3_warpsize1x2x1_ffma_aligna2_alignc2 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020635 Time: 0.160037
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f32f32_f32_nn_n_tilesize64x64x8_stage3_warpsize1x4x1_ffma_aligna2_alignc2 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000203f2 Time: 0.162962
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f32f32_f32_nn_n_tilesize128x32x8_stage3_warpsize2x2x1_ffma_aligna2_alignc2 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000204f9 Time: 0.180663
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f32f32_f32_nn_n_tilesize64x128x8_stage3_warpsize1x4x1_ffma_aligna2_alignc2 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020317 Time: 0.142848
[04/25/2025-09:08:47] [V] [TRT] ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskGemmDeconvolution[0x80000037]) profiling completed in 0.162908 seconds. Fastest Tactic: 0x00000000000205b8 Time: 0.0902583
[04/25/2025-09:08:47] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskDeconvolution[0x8000000a])
[04/25/2025-09:08:47] [V] [TRT] CaskDeconvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:47] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskDeconvolutionV2[0x8000002d])
[04/25/2025-09:08:47] [V] [TRT] CaskDeconvolutionV2 has no valid tactics for this config, skipping
[04/25/2025-09:08:47] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskGemmDeconvolution Tactic: 0x00000000000205b8
[04/25/2025-09:08:47] [V] [TRT] *************** Autotuning format combination: Half(2073600,8100,90,1) -> Half(8294400,32400,180,1) ***************
[04/25/2025-09:08:47] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CudnnDeconvolution[0x80000002])
[04/25/2025-09:08:47] [V] [TRT] CudnnDeconvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:47] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (GemmDeconvolution[0x80000010])
[04/25/2025-09:08:47] [V] [TRT] GemmDeconvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:47] [V] [TRT] ConvTranspose_56 + BatchNormalization_57 + Relu_58: 78 available tactics, 0 unparsable, 39 pruned, 39 remaining after tactic pruning.
[04/25/2025-09:08:47] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskGemmDeconvolution[0x80000037])
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x128x32_stage4_warpsize2x2x1_tensor16x8x16_aligna2_alignc2 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020340 Time: 0.103424
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize256x128x32_stage3_warpsize4x2x1_tensor16x8x16_aligna2_alignc2 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002053d Time: 0.0931109
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x256x32_stage3_warpsize2x4x1_tensor16x8x16_aligna2_alignc2 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000205b8 Time: 0.0906971
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize256x64x32_stage3_warpsize4x1x1_tensor16x8x16_aligna2_alignc2 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002091d Time: 0.122002
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x64x32_stage5_warpsize2x2x1_tensor16x8x16_aligna2_alignc2 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002058a Time: 0.133632
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize64x128x32_stage5_warpsize2x2x1_tensor16x8x16_aligna2_alignc2 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020467 Time: 0.125659
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x128x64_stage3_warpsize2x2x1_tensor16x8x16_aligna2_alignc2 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000202f3 Time: 0.117467
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x64x64_stage3_warpsize2x2x1_tensor16x8x16_aligna2_alignc2 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002053a Time: 0.118711
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize64x64x64_stage4_warpsize2x2x1_tensor16x8x16_aligna2_alignc2 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000206f0 Time: 0.145847
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize64x32x64_stage5_warpsize2x2x1_tensor16x8x16_aligna2_alignc2 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002093f Time: 0.201289
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x128x32_stage4_warpsize2x2x1_tensor16x8x16_aligna2_alignc2 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x0000000002040340 Time: 0.126757
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x256x32_stage3_warpsize2x4x1_tensor16x8x16_aligna2_alignc2 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x00000000020405b8 Time: 0.107301
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize256x128x32_stage3_warpsize4x2x1_tensor16x8x16_aligna2_alignc2 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x000000000204053d Time: 0.110153
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize256x64x32_stage3_warpsize4x1x1_tensor16x8x16_aligna2_alignc2 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x000000000204091d Time: 0.14219
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x64x32_stage5_warpsize2x2x1_tensor16x8x16_aligna2_alignc2 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x000000000204058a Time: 0.165303
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize64x128x32_stage5_warpsize2x2x1_tensor16x8x16_aligna2_alignc2 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x0000000002040467 Time: 0.157842
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x128x32_stage4_warpsize2x2x1_tensor16x8x16_aligna2_alignc2 numSplitK: 2 numBuffers: 2 numKernels: 2 Tactic: 0x0000000204040340 Time: 0.130267
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x256x32_stage3_warpsize2x4x1_tensor16x8x16_aligna2_alignc2 numSplitK: 2 numBuffers: 2 numKernels: 2 Tactic: 0x00000002040405b8 Time: 0.119077
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize256x128x32_stage3_warpsize4x2x1_tensor16x8x16_aligna2_alignc2 numSplitK: 2 numBuffers: 2 numKernels: 2 Tactic: 0x000000020404053d Time: 0.123319
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize256x64x32_stage3_warpsize4x1x1_tensor16x8x16_aligna2_alignc2 numSplitK: 2 numBuffers: 2 numKernels: 2 Tactic: 0x000000020404091d Time: 0.145262
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x128x64_stage3_warpsize2x2x1_tensor16x8x16_aligna2_alignc2 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x00000000020402f3 Time: 0.141531
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x64x32_stage5_warpsize2x2x1_tensor16x8x16_aligna2_alignc2 numSplitK: 2 numBuffers: 2 numKernels: 2 Tactic: 0x000000020404058a Time: 0.160475
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize64x128x32_stage5_warpsize2x2x1_tensor16x8x16_aligna2_alignc2 numSplitK: 2 numBuffers: 2 numKernels: 2 Tactic: 0x0000000204040467 Time: 0.156087
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x64x64_stage3_warpsize2x2x1_tensor16x8x16_aligna2_alignc2 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x000000000204053a Time: 0.150528
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x128x64_stage3_warpsize2x2x1_tensor16x8x16_aligna2_alignc2 numSplitK: 2 numBuffers: 2 numKernels: 2 Tactic: 0x00000002040402f3 Time: 0.14453
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x16_aligna2_alignc2 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000206f4 Time: 0.211383
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x64x64_stage3_warpsize2x2x1_tensor16x8x16_aligna2_alignc2 numSplitK: 2 numBuffers: 2 numKernels: 2 Tactic: 0x000000020404053a Time: 0.146725
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize64x64x64_stage4_warpsize2x2x1_tensor16x8x16_aligna2_alignc2 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x00000000020406f0 Time: 0.187099
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize64x64x64_stage4_warpsize2x2x1_tensor16x8x16_aligna2_alignc2 numSplitK: 2 numBuffers: 2 numKernels: 2 Tactic: 0x00000002040406f0 Time: 0.176713
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x16_aligna2_alignc2 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x00000000020406f4 Time: 0.256293
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x16_aligna2_alignc2 numSplitK: 2 numBuffers: 2 numKernels: 2 Tactic: 0x00000002040406f4 Time: 0.243566
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize64x32x64_stage5_warpsize2x2x1_tensor16x8x16_aligna2_alignc2 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x000000000204093f Time: 0.266386
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize64x32x64_stage5_warpsize2x2x1_tensor16x8x16_aligna2_alignc2 numSplitK: 2 numBuffers: 2 numKernels: 2 Tactic: 0x000000020404093f Time: 0.243858
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f32f32_f32_nn_n_tilesize64x32x8_stage3_warpsize1x2x1_ffma_aligna2_alignc2 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020669 Time: 0.168082
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f32f32_f32_nn_n_tilesize32x64x8_stage3_warpsize1x2x1_ffma_aligna2_alignc2 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020277 Time: 0.174226
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f32f32_f32_nn_n_tilesize32x128x8_stage3_warpsize1x2x1_ffma_aligna2_alignc2 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020635 Time: 0.162231
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f32f32_f32_nn_n_tilesize64x64x8_stage3_warpsize1x4x1_ffma_aligna2_alignc2 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000203f2 Time: 0.166766
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f32f32_f32_nn_n_tilesize128x32x8_stage3_warpsize2x2x1_ffma_aligna2_alignc2 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000204f9 Time: 0.180955
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f32f32_f32_nn_n_tilesize64x128x8_stage3_warpsize1x4x1_ffma_aligna2_alignc2 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020317 Time: 0.142848
[04/25/2025-09:08:47] [V] [TRT] ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskGemmDeconvolution[0x80000037]) profiling completed in 0.155691 seconds. Fastest Tactic: 0x00000000000205b8 Time: 0.0906971
[04/25/2025-09:08:47] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskDeconvolution[0x8000000a])
[04/25/2025-09:08:47] [V] [TRT] CaskDeconvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:47] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskDeconvolutionV2[0x8000002d])
[04/25/2025-09:08:47] [V] [TRT] CaskDeconvolutionV2 has no valid tactics for this config, skipping
[04/25/2025-09:08:47] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskGemmDeconvolution Tactic: 0x00000000000205b8
[04/25/2025-09:08:47] [V] [TRT] *************** Autotuning format combination: Half(1036800,8100:2,90,1) -> Half(8294400,32400:2,180,1) long-strided ***************
[04/25/2025-09:08:47] [V] [TRT] RunnerBuilder of layer implementation CudnnDeconvolution cannot handle striding for node ConvTranspose_56 + BatchNormalization_57 + Relu_58
[04/25/2025-09:08:47] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (GemmDeconvolution[0x80000010])
[04/25/2025-09:08:47] [V] [TRT] GemmDeconvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:47] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskDeconvolution[0x8000000a])
[04/25/2025-09:08:47] [V] [TRT] CaskDeconvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:47] [V] [TRT] *************** Autotuning format combination: Half(1036800,8100:2,90,1) -> Half(4147200,32400:2,180,1) ***************
[04/25/2025-09:08:47] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CudnnDeconvolution[0x80000002])
[04/25/2025-09:08:47] [V] [TRT] CudnnDeconvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:47] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (GemmDeconvolution[0x80000010])
[04/25/2025-09:08:47] [V] [TRT] GemmDeconvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:47] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskDeconvolution[0x8000000a])
[04/25/2025-09:08:47] [V] [TRT] CaskDeconvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:47] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:2,11520,128) -> Half(8294400,1:2,46080,256) long-strided ***************
[04/25/2025-09:08:47] [V] [TRT] RunnerBuilder of layer implementation CudnnDeconvolution cannot handle striding for node ConvTranspose_56 + BatchNormalization_57 + Relu_58
[04/25/2025-09:08:47] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (GemmDeconvolution[0x80000010])
[04/25/2025-09:08:47] [V] [TRT] GemmDeconvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:47] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskDeconvolution[0x8000000a])
[04/25/2025-09:08:47] [V] [TRT] CaskDeconvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:47] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskDeconvolutionV2[0x8000002d])
[04/25/2025-09:08:47] [V] [TRT] CaskDeconvolutionV2 has no valid tactics for this config, skipping
[04/25/2025-09:08:47] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:2,11520,128) -> Half(4147200,1:2,23040,128) ***************
[04/25/2025-09:08:47] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CudnnDeconvolution[0x80000002])
[04/25/2025-09:08:47] [V] [TRT] CudnnDeconvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:47] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (GemmDeconvolution[0x80000010])
[04/25/2025-09:08:47] [V] [TRT] GemmDeconvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:47] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskDeconvolution[0x8000000a])
[04/25/2025-09:08:47] [V] [TRT] CaskDeconvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:47] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskDeconvolutionV2[0x8000002d])
[04/25/2025-09:08:47] [V] [TRT] CaskDeconvolutionV2 has no valid tactics for this config, skipping
[04/25/2025-09:08:47] [V] [TRT] *************** Autotuning format combination: Half(518400,1:4,5760,64) -> Half(4147200,1:4,23040,128) long-strided ***************
[04/25/2025-09:08:47] [V] [TRT] RunnerBuilder of layer implementation CudnnDeconvolution cannot handle striding for node ConvTranspose_56 + BatchNormalization_57 + Relu_58
[04/25/2025-09:08:47] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (GemmDeconvolution[0x80000010])
[04/25/2025-09:08:47] [V] [TRT] GemmDeconvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:47] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskDeconvolution[0x8000000a])
[04/25/2025-09:08:47] [V] [TRT] CaskDeconvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:47] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskDeconvolutionV2[0x8000002d])
[04/25/2025-09:08:47] [V] [TRT] CaskDeconvolutionV2 has no valid tactics for this config, skipping
[04/25/2025-09:08:47] [V] [TRT] *************** Autotuning format combination: Half(518400,1:4,5760,64) -> Half(2073600,1:4,11520,64) ***************
[04/25/2025-09:08:47] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CudnnDeconvolution[0x80000002])
[04/25/2025-09:08:47] [V] [TRT] CudnnDeconvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:47] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (GemmDeconvolution[0x80000010])
[04/25/2025-09:08:47] [V] [TRT] GemmDeconvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:47] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskDeconvolution[0x8000000a])
[04/25/2025-09:08:47] [V] [TRT] CaskDeconvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:47] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskDeconvolutionV2[0x8000002d])
[04/25/2025-09:08:47] [V] [TRT] CaskDeconvolutionV2 has no valid tactics for this config, skipping
[04/25/2025-09:08:47] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,2880,32) -> Half(2073600,1:8,11520,64) long-strided ***************
[04/25/2025-09:08:47] [V] [TRT] RunnerBuilder of layer implementation CudnnDeconvolution cannot handle striding for node ConvTranspose_56 + BatchNormalization_57 + Relu_58
[04/25/2025-09:08:47] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (GemmDeconvolution[0x80000010])
[04/25/2025-09:08:47] [V] [TRT] GemmDeconvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:47] [V] [TRT] ConvTranspose_56 + BatchNormalization_57 + Relu_58: 133 available tactics, 0 unparsable, 66 pruned, 67 remaining after tactic pruning.
[04/25/2025-09:08:47] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskGemmDeconvolution[0x80000037])
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_ldg8_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020054 Time: 0.0418743
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_ldg8_relu_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020187 Time: 0.0422034
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_sliced1x2_ldg8_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002000b Time: 0.0436263
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_sliced1x2_ldg8_relu_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002097a Time: 0.0448366
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_64x64_ldg8_relu_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020468 Time: 0.0521265
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_64x64_ldg8_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002082a Time: 0.0503223
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x128x32_stage4_warpsize2x2x1_tensor16x8x16_aligna4_alignc4 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020672 Time: 0.042496
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_128x128_ldg8_stages_32x5_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020369 Time: 0.040192
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x128x32_stage4_warpsize2x2x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000207fc Time: 0.0386926
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_128x128_ldg8_relu_stages_32x5_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000209a3 Time: 0.0415451
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x256x32_stage3_warpsize2x4x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002062b Time: 0.0373017
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize256x128x32_stage3_warpsize4x2x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020719 Time: 0.0373394
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_256x128_ldg8_relu_stages_32x3_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020817 Time: 0.301787
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_256x128_ldg8_stages_32x3_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002081d Time: 0.0370091
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize256x128x32_stage3_warpsize4x2x1_tensor16x8x16_aligna4_alignc4 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000202a8 Time: 0.0393874
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x256x32_stage3_warpsize2x4x1_tensor16x8x16_aligna4_alignc4 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020929 Time: 0.0383269
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize256x64x32_stage3_warpsize4x1x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002071a Time: 0.0414354
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize256x64x32_stage3_warpsize4x1x1_tensor16x8x16_aligna4_alignc4 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000201bc Time: 0.0477379
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_64x64_sliced1x2_ldg8_relu_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020056 Time: 0.0496396
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_64x64_sliced1x2_ldg8_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020987 Time: 0.0476526
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_64x128_ldg8_relu_stages_32x6_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020581 Time: 0.0514438
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x64x32_stage5_warpsize2x2x1_tensor16x8x16_aligna4_alignc4 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020342 Time: 0.0557318
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x64x32_stage5_warpsize2x2x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020722 Time: 0.0443246
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_64x128_ldg8_stages_32x6_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002016b Time: 0.0497371
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize64x128x32_stage5_warpsize2x2x1_tensor16x8x16_aligna4_alignc4 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002024c Time: 0.052419
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_ldg8_relu_stages_32x6_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000206a0 Time: 0.0484206
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize64x128x32_stage5_warpsize2x2x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000207f5 Time: 0.0446537
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_ldg8_stages_32x6_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000202c3 Time: 0.046408
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x128x64_stage3_warpsize2x2x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020097 Time: 0.0403749
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x128x64_stage3_warpsize2x2x1_tensor16x8x16_aligna4_alignc4 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002071e Time: 0.048128
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_64x128_ldg8_relu_stages_64x4_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000207ef Time: 0.0549059
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_64x128_ldg8_stages_64x4_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002001d Time: 0.0525669
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x64x64_stage3_warpsize2x2x1_tensor16x8x16_aligna4_alignc4 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000200eb Time: 0.053053
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x64x64_stage3_warpsize2x2x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020720 Time: 0.0469943
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_ldg8_relu_stages_64x4_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000207a5 Time: 0.051395
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_ldg8_stages_64x4_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020155 Time: 0.049152
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_ldg8_relu_nn_v1 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x0000000002040187 Time: 0.0518339
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_ldg8_nn_v1 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x0000000002040054 Time: 0.0508587
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_64x64_sliced1x2_ldg8_relu_stages_64x5_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020763 Time: 0.0642164
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize64x64x64_stage4_warpsize2x2x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000205d8 Time: 0.0579779
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_64x64_ldg8_stages_64x5_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000200c7 Time: 0.0590507
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize64x64x64_stage4_warpsize2x2x1_tensor16x8x16_aligna4_alignc4 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020576 Time: 0.070461
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_64x64_sliced1x2_ldg8_stages_64x5_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020902 Time: 0.0618789
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_64x64_ldg8_relu_stages_64x5_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020924 Time: 0.061632
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm86_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize256x128x32_stage2_warpsize4x2x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020405 Time: 0.0378514
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_sliced1x2_ldg8_nn_v1 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x000000000204000b Time: 0.0535406
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_sliced1x2_ldg8_relu_nn_v1 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x000000000204097a Time: 0.0552472
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_128x256_ldg8_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002080c Time: 0.0386194
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_128x256_ldg8_relu_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020853 Time: 0.0389497
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_256x128_ldg8_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020335 Time: 0.038656
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_256x128_ldg8_relu_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000208e0 Time: 0.0389109
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_256x64_ldg8_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020777 Time: 0.0476526
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_256x64_ldg8_relu_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020974 Time: 0.0490545
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_128x128_ldg8_relu_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000205d1 Time: 0.045056
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_128x128_ldg8_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002089e Time: 0.0433006
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_64x64_ldg8_relu_nn_v1 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x0000000002040468 Time: 0.0601204
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_64x64_ldg8_nn_v1 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x000000000204082a Time: 0.0586606
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_64x64_sliced1x2_ldg8_relu_nn_v1 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x0000000002040056 Time: 0.059587
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_64x64_sliced1x2_ldg8_nn_v1 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x0000000002040987 Time: 0.0573928
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize64x32x64_stage5_warpsize2x2x1_tensor16x8x16_aligna4_alignc4 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020323 Time: 0.119586
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize64x32x64_stage5_warpsize2x2x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002063b Time: 0.0766537
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x128x32_stage4_warpsize2x2x1_tensor16x8x16_aligna4_alignc4 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x0000000002040672 Time: 0.0612937
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x128x32_stage4_warpsize2x2x1_tensor16x8x16 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x00000000020407fc Time: 0.0553448
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_128x128_ldg8_relu_stages_32x5_nn_v1 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x00000000020409a3 Time: 0.0606598
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_128x128_ldg8_stages_32x5_nn_v1 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x0000000002040369 Time: 0.0589531
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x256x32_stage3_warpsize2x4x1_tensor16x8x16 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x000000000204062b Time: 0.0519314
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x256x32_stage3_warpsize2x4x1_tensor16x8x16_aligna4_alignc4 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x0000000002040929 Time: 0.0536381
[04/25/2025-09:08:47] [V] [TRT] ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskGemmDeconvolution[0x80000037]) profiling completed in 0.223223 seconds. Fastest Tactic: 0x000000000002081d Time: 0.0370091
[04/25/2025-09:08:47] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskDeconvolution[0x8000000a])
[04/25/2025-09:08:47] [V] [TRT] CaskDeconvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:47] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskDeconvolutionV2[0x8000002d])
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16_strided Tactic: 0xdec24e75875e331b Time: 0.0245272
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_strided Tactic: 0x9c2afe40f043a2af Time: 0.0293157
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0x86e575ac0953a218 Time: 0.083968
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xad900cb3d99acf3d Time: 0.0920869
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16_strided Tactic: 0x3d8e7318766eb7dc Time: 0.0310418
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_strided Tactic: 0xa7e51cc94b1422a2 Time: 0.0420914
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16_strided Tactic: 0xd8431473bb5f91ee Time: 0.0360594
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x93d63ec59e26a994 Time: 0.0676815
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x7bb6e0d53fc5ff66 Time: 0.0662156
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xff74b048c704a0c3 Time: 0.0594362
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16_strided Tactic: 0xbe1fd751d1abb95e Time: 0.0820663
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x9e7119e6665ed23e Time: 0.119442
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_strided Tactic: 0x7f88a42f41dd3253 Time: 0.0534903
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_strided Tactic: 0x611e899dccd3003a Time: 0.0285745
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16_strided Tactic: 0x7cc22b876c6d2b93 Time: 0.0353426
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x350fa92a3841d3f8 Time: 0.0827246
[04/25/2025-09:08:47] [V] [TRT] ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskDeconvolutionV2[0x8000002d]) profiling completed in 0.108588 seconds. Fastest Tactic: 0xdec24e75875e331b Time: 0.0245272
[04/25/2025-09:08:47] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskDeconvolutionV2 Tactic: 0xdec24e75875e331b
[04/25/2025-09:08:47] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,2880,32) -> Half(1036800,1:8,5760,32) ***************
[04/25/2025-09:08:47] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CudnnDeconvolution[0x80000002])
[04/25/2025-09:08:47] [V] [TRT] CudnnDeconvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:47] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (GemmDeconvolution[0x80000010])
[04/25/2025-09:08:47] [V] [TRT] GemmDeconvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:47] [V] [TRT] ConvTranspose_56 + BatchNormalization_57 + Relu_58: 133 available tactics, 0 unparsable, 66 pruned, 67 remaining after tactic pruning.
[04/25/2025-09:08:47] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskGemmDeconvolution[0x80000037])
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_ldg8_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020054 Time: 0.041728
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_ldg8_relu_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020187 Time: 0.0421669
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_sliced1x2_ldg8_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002000b Time: 0.0433737
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_sliced1x2_ldg8_relu_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002097a Time: 0.0445806
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_64x64_ldg8_relu_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020468 Time: 0.0515413
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_64x64_ldg8_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002082a Time: 0.0504686
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x128x32_stage4_warpsize2x2x1_tensor16x8x16_aligna4_alignc4 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020672 Time: 0.0425326
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_128x128_ldg8_stages_32x5_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020369 Time: 0.040192
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x128x32_stage4_warpsize2x2x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000207fc Time: 0.0385829
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_128x128_ldg8_relu_stages_32x5_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000209a3 Time: 0.041544
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x256x32_stage3_warpsize2x4x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002062b Time: 0.0370469
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize256x128x32_stage3_warpsize4x2x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020719 Time: 0.0375223
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_256x128_ldg8_relu_stages_32x3_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020817 Time: 0.0372663
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_256x128_ldg8_stages_32x3_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002081d Time: 0.036864
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize256x128x32_stage3_warpsize4x2x1_tensor16x8x16_aligna4_alignc4 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000202a8 Time: 0.0390949
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x256x32_stage3_warpsize2x4x1_tensor16x8x16_aligna4_alignc4 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020929 Time: 0.038144
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize256x64x32_stage3_warpsize4x1x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002071a Time: 0.0408503
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize256x64x32_stage3_warpsize4x1x1_tensor16x8x16_aligna4_alignc4 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000201bc Time: 0.0476171
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_64x64_sliced1x2_ldg8_relu_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020056 Time: 0.0493958
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_64x64_sliced1x2_ldg8_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020987 Time: 0.0476404
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_64x128_ldg8_relu_stages_32x6_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020581 Time: 0.0512975
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x64x32_stage5_warpsize2x2x1_tensor16x8x16_aligna4_alignc4 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020342 Time: 0.0554423
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x64x32_stage5_warpsize2x2x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020722 Time: 0.0444709
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_64x128_ldg8_stages_32x6_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002016b Time: 0.0492495
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize64x128x32_stage5_warpsize2x2x1_tensor16x8x16_aligna4_alignc4 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002024c Time: 0.0528579
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_ldg8_relu_stages_32x6_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000206a0 Time: 0.0487619
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize64x128x32_stage5_warpsize2x2x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000207f5 Time: 0.0444709
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_ldg8_stages_32x6_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000202c3 Time: 0.0462263
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x128x64_stage3_warpsize2x2x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020097 Time: 0.0402651
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x128x64_stage3_warpsize2x2x1_tensor16x8x16_aligna4_alignc4 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002071e Time: 0.048128
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_64x128_ldg8_relu_stages_64x4_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000207ef Time: 0.055101
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_64x128_ldg8_stages_64x4_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002001d Time: 0.0527116
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x64x64_stage3_warpsize2x2x1_tensor16x8x16_aligna4_alignc4 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000200eb Time: 0.0532968
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x64x64_stage3_warpsize2x2x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020720 Time: 0.0471771
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_ldg8_relu_stages_64x4_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000207a5 Time: 0.0515413
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_ldg8_stages_64x4_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020155 Time: 0.0489569
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_ldg8_relu_nn_v1 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x0000000002040187 Time: 0.0526141
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_ldg8_nn_v1 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x0000000002040054 Time: 0.0519802
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_64x64_sliced1x2_ldg8_relu_stages_64x5_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020763 Time: 0.0641707
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize64x64x64_stage4_warpsize2x2x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000205d8 Time: 0.0578804
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_64x64_ldg8_stages_64x5_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000200c7 Time: 0.0588556
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize64x64x64_stage4_warpsize2x2x1_tensor16x8x16_aligna4_alignc4 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020576 Time: 0.0705097
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_64x64_sliced1x2_ldg8_stages_64x5_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020902 Time: 0.0618331
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_64x64_ldg8_relu_stages_64x5_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020924 Time: 0.0615863
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm86_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize256x128x32_stage2_warpsize4x2x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020405 Time: 0.0375223
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_sliced1x2_ldg8_nn_v1 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x000000000204000b Time: 0.0531017
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_128x64_sliced1x2_ldg8_relu_nn_v1 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x000000000204097a Time: 0.055101
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_128x256_ldg8_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002080c Time: 0.0385463
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_128x256_ldg8_relu_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020853 Time: 0.038656
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_256x128_ldg8_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020335 Time: 0.039424
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_256x128_ldg8_relu_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000208e0 Time: 0.0390217
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_256x64_ldg8_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020777 Time: 0.0472503
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_256x64_ldg8_relu_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020974 Time: 0.0490545
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_128x128_ldg8_relu_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x00000000000205d1 Time: 0.0451657
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_128x128_ldg8_nn_v1 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002089e Time: 0.0433006
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_64x64_ldg8_relu_nn_v1 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x0000000002040468 Time: 0.0600747
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_64x64_ldg8_nn_v1 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x000000000204082a Time: 0.0587581
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_64x64_sliced1x2_ldg8_relu_nn_v1 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x0000000002040056 Time: 0.0595383
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_64x64_sliced1x2_ldg8_nn_v1 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x0000000002040987 Time: 0.0572952
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize64x32x64_stage5_warpsize2x2x1_tensor16x8x16_aligna4_alignc4 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x0000000000020323 Time: 0.119515
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize64x32x64_stage5_warpsize2x2x1_tensor16x8x16 numSplitK: 1 numBuffers: 0 numKernels: 1 Tactic: 0x000000000002063b Time: 0.0764343
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x128x32_stage4_warpsize2x2x1_tensor16x8x16_aligna4_alignc4 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x0000000002040672 Time: 0.0610499
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x128x32_stage4_warpsize2x2x1_tensor16x8x16 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x00000000020407fc Time: 0.0549547
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_128x128_ldg8_relu_stages_32x5_nn_v1 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x00000000020409a3 Time: 0.0605623
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: ampere_h16816gemm_128x128_ldg8_stages_32x5_nn_v1 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x0000000002040369 Time: 0.0585143
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x256x32_stage3_warpsize2x4x1_tensor16x8x16 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x000000000204062b Time: 0.0505173
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize128x256x32_stage3_warpsize2x4x1_tensor16x8x16_aligna4_alignc4 numSplitK: 2 numBuffers: 1 numKernels: 1 Tactic: 0x0000000002040929 Time: 0.0531505
[04/25/2025-09:08:47] [V] [TRT] ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskGemmDeconvolution[0x80000037]) profiling completed in 0.215217 seconds. Fastest Tactic: 0x000000000002081d Time: 0.036864
[04/25/2025-09:08:47] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskDeconvolution[0x8000000a])
[04/25/2025-09:08:47] [V] [TRT] CaskDeconvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:47] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskDeconvolutionV2[0x8000002d])
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16_strided Tactic: 0xdec24e75875e331b Time: 0.024381
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_strided Tactic: 0x9c2afe40f043a2af Time: 0.0290542
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0x86e575ac0953a218 Time: 0.0840411
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xad900cb3d99acf3d Time: 0.09216
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16_strided Tactic: 0x3d8e7318766eb7dc Time: 0.0302519
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_strided Tactic: 0xa7e51cc94b1422a2 Time: 0.0420206
[04/25/2025-09:08:47] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16_strided Tactic: 0xd8431473bb5f91ee Time: 0.0360594
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x93d63ec59e26a994 Time: 0.0672427
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x7bb6e0d53fc5ff66 Time: 0.06656
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xff74b048c704a0c3 Time: 0.0594895
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16_strided Tactic: 0xbe1fd751d1abb95e Time: 0.0816274
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x9e7119e6665ed23e Time: 0.119442
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_strided Tactic: 0x7f88a42f41dd3253 Time: 0.0533455
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_strided Tactic: 0x611e899dccd3003a Time: 0.0281356
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16_strided Tactic: 0x7cc22b876c6d2b93 Time: 0.0360229
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_deconv_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x350fa92a3841d3f8 Time: 0.0827246
[04/25/2025-09:08:48] [V] [TRT] ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskDeconvolutionV2[0x8000002d]) profiling completed in 0.10993 seconds. Fastest Tactic: 0xdec24e75875e331b Time: 0.024381
[04/25/2025-09:08:48] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskDeconvolutionV2 Tactic: 0xdec24e75875e331b
[04/25/2025-09:08:48] [V] [TRT] *************** Autotuning format combination: Half(129600,1:16,1440,16) -> Half(1036800,1:16,5760,32) long-strided ***************
[04/25/2025-09:08:48] [V] [TRT] RunnerBuilder of layer implementation CudnnDeconvolution cannot handle striding for node ConvTranspose_56 + BatchNormalization_57 + Relu_58
[04/25/2025-09:08:48] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (GemmDeconvolution[0x80000010])
[04/25/2025-09:08:48] [V] [TRT] GemmDeconvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:48] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskDeconvolution[0x8000000a])
[04/25/2025-09:08:48] [V] [TRT] CaskDeconvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:48] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskDeconvolutionV2[0x8000002d])
[04/25/2025-09:08:48] [V] [TRT] CaskDeconvolutionV2 has no valid tactics for this config, skipping
[04/25/2025-09:08:48] [V] [TRT] *************** Autotuning format combination: Half(129600,1:16,1440,16) -> Half(518400,1:16,2880,16) ***************
[04/25/2025-09:08:48] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CudnnDeconvolution[0x80000002])
[04/25/2025-09:08:48] [V] [TRT] CudnnDeconvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:48] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (GemmDeconvolution[0x80000010])
[04/25/2025-09:08:48] [V] [TRT] GemmDeconvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:48] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskDeconvolution[0x8000000a])
[04/25/2025-09:08:48] [V] [TRT] CaskDeconvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:48] [V] [TRT] --------------- Timing Runner: ConvTranspose_56 + BatchNormalization_57 + Relu_58 (CaskDeconvolutionV2[0x8000002d])
[04/25/2025-09:08:48] [V] [TRT] CaskDeconvolutionV2 has no valid tactics for this config, skipping
[04/25/2025-09:08:48] [V] [TRT] =============== Computing costs for Conv_60 + Relu_61
[04/25/2025-09:08:48] [V] [TRT] *************** Autotuning format combination: Float(16588800,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:48] [V] [TRT] --------------- Timing Runner: Conv_60 + Relu_61 (CaskConvolution[0x80000009])
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: 0xf067e6205da31c2e Time: 0.689445
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 0x5deb29b7a8e275f7 Time: 0.404773
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 0x503619c69ae500ff Time: 0.682569
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 0x3f243c490d502deb Time: 0.402725
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize1x4x1_g1_ffma_aligna4_alignc4_beta0_packed_stride Tactic: 0xede36641840ce3d2 Time: 0.455973
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xa9366041633a5135 Time: 0.876837
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP5_TQ5_C1_R3_S3_U1_V1 Tactic: 0x4165f9dd71b6e38a Time: 0.636343
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP4_TQ7_C4_R3_S3_U1_V1 Tactic: 0x753397072379d6e9 Time: 0.604599
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize4x1x1_g1_ffma_aligna4_alignc4_beta0_packed_stride Tactic: 0x1673e3594ce11cea Time: 0.49269
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_wngd_f32f32_f32_f32_nchwkcrs_nchw_tilesize8x16x32x8_warpsize8x1x1_wngd2x2 Tactic: 0xe47e164f4a743900 Time: 0.337774
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP7_TQ4_C1_R3_S3_U1_V1 Tactic: 0xe2f49879bec27b91 Time: 0.855918
[04/25/2025-09:08:48] [V] [TRT] Fast skip Tactic:0x5ac6bfe0a27fc97b which exceed time limit during pre-run
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ5_C1_R3_S3_U1_V1 Tactic: 0x5ac6bfe0a27fc97b Time: 1.14893
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP4_TQ8_C1_R3_S3_U1_V1 Tactic: 0x36209b75daa96278 Time: 0.889257
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xcb8a43f748d8a338 Time: 0.845239
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP4_TQ7_C2_R3_S3_U1_V1 Tactic: 0x57c1b87347e45486 Time: 0.97909
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x5aa723e0481da855 Time: 0.717385
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP5_TQ7_C8_R3_S3_U1_V1 Tactic: 0x688222fe126a1c16 Time: 0.683301
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4_beta0_packed_stride Tactic: 0x7fc93550f5b9c127 Time: 0.396288
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec1_1_TP7_TQ8_C8_R3_S3_U1_V1 Tactic: 0x06cd3594e0105153 Time: 0.42613
[04/25/2025-09:08:48] [V] [TRT] Fast skip Tactic:0x40a12e3938221818 which exceed time limit during pre-run
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x40a12e3938221818 Time: 1.0752
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x01cf8ce2da913006 Time: 0.67467
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xb0bf940d5e0f9f45 Time: 0.697198
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xd828f024626fa982 Time: 0.603282
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP6_TQ5_C2_R3_S3_U1_V1 Tactic: 0x1e01f84aaf51153a Time: 0.744009
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize2x2x1_g1_ffma_aligna4_alignc4_beta0_packed_stride Tactic: 0x31aa67f57c5aea77 Time: 0.465042
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ8_C4_R3_S3_U1_V1 Tactic: 0x4bb6b59660d316a7 Time: 0.875959
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP4_TQ5_C2_R3_S3_U1_V1 Tactic: 0xed12ab640715a7d9 Time: 0.907264
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x9d9fdb5fd9945f64 Time: 0.714313
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x4efce38acc876f5c Time: 0.590994
[04/25/2025-09:08:48] [V] [TRT] Fast skip Tactic:0x193012cc899e2dab which exceed time limit during pre-run
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP4_TQ5_C1_R3_S3_U1_V1 Tactic: 0x193012cc899e2dab Time: 1.0793
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x4727434768e46395 Time: 0.586313
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec1_1_TP6_TQ8_C8_R3_S3_U1_V1 Tactic: 0xee473898b5318f6e Time: 0.425253
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_wngd_f32f32_f32_f32_nchwkcrs_nchw_tilesize8x16x16x8_warpsize8x1x1_wngd2x2 Tactic: 0xe38e9dfd56c33779 Time: 0.338651
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP8_TQ7_C4_R3_S3_U1_V1 Tactic: 0x372f7588455e8e60 Time: 0.755273
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP5_TQ7_C2_R3_S3_U1_V1 Tactic: 0xbf4bb57f12c58abb Time: 0.941349
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP4_TQ7_C1_R3_S3_U1_V1 Tactic: 0xfb8cf2d51feb56fa Time: 0.816128
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP4_TQ8_C2_R3_S3_U1_V1 Tactic: 0xc20222dd5422e80a Time: 0.748983
[04/25/2025-09:08:48] [V] [TRT] Fast skip Tactic:0x1fd1aff6cc3bef4c which exceed time limit during pre-run
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP8_TQ5_C2_R3_S3_U1_V1 Tactic: 0x1fd1aff6cc3bef4c Time: 1.12845
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ7_C2_R3_S3_U1_V1 Tactic: 0xfc87004c17882844 Time: 0.890295
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP2_TQ5_C2_R3_S3_U1_V1 Tactic: 0x2947743108c340d8 Time: 0.989038
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 0x94119b4c514b211a Time: 0.286135
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: 0xa8609adc4e0ceb90 Time: 0.49781
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ6_C8_R3_S3_U1_V1 Tactic: 0x937cb0540b9a0c03 Time: 0.681399
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP5_TQ7_C4_R3_S3_U1_V1 Tactic: 0x2d667c16db5118c8 Time: 0.862354
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: 0xf64396b97c889179 Time: 0.449536
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ7_C8_R3_S3_U1_V1 Tactic: 0x732164c3c1a336e7 Time: 0.997522
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize4x1x1_g1_ffma_t1r3s3_aligna4_alignc4_beta0_packed_stride Tactic: 0xe640ceafd7d34ca9 Time: 0.430958
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ7_C4_R3_S3_U1_V1 Tactic: 0x861adc36a5912225 Time: 0.759223
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x12dbf7d94ee3696d Time: 0.374345
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x8ad32616b1424be4 Time: 0.699685
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize2x2x1_g1_ffma_t1r3s3_aligna4_alignc4_beta0_packed_stride Tactic: 0x3712e3e595645874 Time: 0.424814
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_wngd_f32f32_f32_f32_nchwkcrs_nchw_tilesize8x16x64x8_warpsize8x1x1_wngd2x2 Tactic: 0x0190806602534cfd Time: 0.299008
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP3_TQ7_C8_R3_S3_U1_V1 Tactic: 0xacd7fdab1dbcfb17 Time: 0.526775
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP8_TQ5_C4_R3_S3_U1_V1 Tactic: 0x654c738c7e22e52d Time: 0.86528
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP7_TQ3_C1_R3_S3_U1_V1 Tactic: 0xf40c46e2397ffca2 Time: 0.606208
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec4_4_TP2_TQ7_C2_R3_S3_U1_V1 Tactic: 0x7b24723533bf2b95 Time: 0.913408
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP5_TQ7_C4_R3_S3_U1_V1 Tactic: 0xc5d66905a0dc80da Time: 0.628736
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP5_TQ8_C8_R3_S3_U1_V1 Tactic: 0xfd41b85001aca09a Time: 0.713874
[04/25/2025-09:08:48] [V] [TRT] Fast skip Tactic:0xba9b6b776846f39f which exceed time limit during pre-run
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ4_C1_R3_S3_U1_V1 Tactic: 0xba9b6b776846f39f Time: 1.26054
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP8_TQ5_C8_R3_S3_U1_V1 Tactic: 0x9077cb791a10f1ef Time: 0.737865
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP5_TQ7_C2_R3_S3_U1_V1 Tactic: 0xe7244671c44102b5 Time: 0.894245
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP5_TQ7_C4_R3_S3_U1_V1 Tactic: 0x9db99a0b765808d4 Time: 0.596699
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP7_TQ5_C1_R3_S3_U1_V1 Tactic: 0x02a94cee74fb4175 Time: 0.745179
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP4_TQ8_C4_R3_S3_U1_V1 Tactic: 0xb89ffea7e63be26b Time: 0.600786
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec1_1_TP4_TQ7_C1_R3_S3_U1_V1 Tactic: 0x1ba3392c2d9e8dc2 Time: 0.566126
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xa31d27de74b895ff Time: 0.523995
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP5_TQ7_C1_R3_S3_U1_V1 Tactic: 0x1306ffd94aca88c7 Time: 0.802962
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xbb8c3889c7eacd30 Time: 0.591433
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec1_1_TP6_TQ8_C2_R3_S3_U1_V1 Tactic: 0x61e15c17631a91cd Time: 0.446464
[04/25/2025-09:08:48] [V] [TRT] Conv_60 + Relu_61 (CaskConvolution[0x80000009]) profiling completed in 0.584424 seconds. Fastest Tactic: 0x94119b4c514b211a Time: 0.286135
[04/25/2025-09:08:48] [V] [TRT] --------------- Timing Runner: Conv_60 + Relu_61 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:48] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:48] [V] [TRT] --------------- Timing Runner: Conv_60 + Relu_61 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:48] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:48] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x94119b4c514b211a
[04/25/2025-09:08:48] [V] [TRT] *************** Autotuning format combination: Float(16588800,1,92160,512) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:48] [V] [TRT] --------------- Timing Runner: Conv_60 + Relu_61 (CaskConvolution[0x80000009])
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x3f0c846d6379bc98 Time: 1.26581
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x19b688348f983aa0 Time: 0.611182
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0xf48db81f02eca9ee Time: 0.498542
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x92ed3100c35fc43e Time: 0.727918
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x5953bec563d26434 Time: 0.891026
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x8014228ec08b4d49 Time: 0.355621
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x1da91d865428f237 Time: 0.482743
[04/25/2025-09:08:48] [V] [TRT] Fast skip Tactic:0x4fd3c46622e98342 which exceed time limit during pre-run
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x4fd3c46622e98342 Time: 1.06394
[04/25/2025-09:08:48] [V] [TRT] Fast skip Tactic:0x32059de4888dfdda which exceed time limit during pre-run
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x32059de4888dfdda Time: 1.01683
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x7121ec1db3f80c67 Time: 0.887808
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0xd15dd11d64344e83 Time: 0.851968
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x0a143be7a52f301a Time: 0.905061
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x62835fce994f06dd Time: 0.570825
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xa6448a1e79f1ca6f Time: 0.601673
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x94a7db94ba744c45 Time: 0.56832
[04/25/2025-09:08:48] [V] [TRT] Conv_60 + Relu_61 (CaskConvolution[0x80000009]) profiling completed in 0.124166 seconds. Fastest Tactic: 0x8014228ec08b4d49 Time: 0.355621
[04/25/2025-09:08:48] [V] [TRT] --------------- Timing Runner: Conv_60 + Relu_61 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:48] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:48] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x8014228ec08b4d49
[04/25/2025-09:08:48] [V] [TRT] *************** Autotuning format combination: Float(4147200,1:4,23040,128) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:48] [V] [TRT] --------------- Timing Runner: Conv_60 + Relu_61 (CaskConvolution[0x80000009])
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 0x9787b83bedcff6a2 Time: 0.460654
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_alignc4 Tactic: 0xe8f7b6a5bab325f8 Time: 0.482889
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_alignc4 Tactic: 0x9fd9fe001908ce2e Time: 0.492544
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0xe0a307ffe0ffb6a5 Time: 0.47221
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3_alignc4 Tactic: 0x1323e48791e2f671 Time: 0.451438
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0x3104d85fecdd547c Time: 0.455826
[04/25/2025-09:08:48] [V] [TRT] Conv_60 + Relu_61 (CaskConvolution[0x80000009]) profiling completed in 0.0365319 seconds. Fastest Tactic: 0x1323e48791e2f671 Time: 0.451438
[04/25/2025-09:08:48] [V] [TRT] --------------- Timing Runner: Conv_60 + Relu_61 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:48] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:48] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x1323e48791e2f671
[04/25/2025-09:08:48] [V] [TRT] *************** Autotuning format combination: Float(4147200,1:4,23040,128) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:48] [V] [TRT] --------------- Timing Runner: Conv_60 + Relu_61 (CaskConvolution[0x80000009])
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 0xbdfdef6b84f7ccc9 Time: 0.400667
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0x3e2b881168d9689d Time: 0.416914
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0xf90060ce8193b811 Time: 0.792576
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x7bc32c782b800c48 Time: 0.829294
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0xb443c221fcb1565b Time: 0.458021
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 0x999e005e3b016ea6 Time: 0.471625
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0x65e41d81f093b482 Time: 0.540818
[04/25/2025-09:08:48] [V] [TRT] Conv_60 + Relu_61 (CaskConvolution[0x80000009]) profiling completed in 0.0493985 seconds. Fastest Tactic: 0xbdfdef6b84f7ccc9 Time: 0.400667
[04/25/2025-09:08:48] [V] [TRT] --------------- Timing Runner: Conv_60 + Relu_61 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:48] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:48] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xbdfdef6b84f7ccc9
[04/25/2025-09:08:48] [V] [TRT] *************** Autotuning format combination: Half(16588800,32400,180,1) -> Half(2073600,32400,180,1) ***************
[04/25/2025-09:08:48] [V] [TRT] --------------- Timing Runner: Conv_60 + Relu_61 (CaskConvolution[0x80000009])
[04/25/2025-09:08:48] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:48] [V] [TRT] --------------- Timing Runner: Conv_60 + Relu_61 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:48] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:48] [V] [TRT] --------------- Timing Runner: Conv_60 + Relu_61 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:48] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:48] [V] [TRT] *************** Autotuning format combination: Half(8294400,1:2,46080,256) -> Half(1036800,1:2,5760,32) ***************
[04/25/2025-09:08:48] [V] [TRT] --------------- Timing Runner: Conv_60 + Relu_61 (CaskConvolution[0x80000009])
[04/25/2025-09:08:48] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:48] [V] [TRT] --------------- Timing Runner: Conv_60 + Relu_61 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:48] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:48] [V] [TRT] *************** Autotuning format combination: Half(4147200,1:4,23040,128) -> Half(518400,1:4,2880,16) ***************
[04/25/2025-09:08:48] [V] [TRT] --------------- Timing Runner: Conv_60 + Relu_61 (CaskConvolution[0x80000009])
[04/25/2025-09:08:48] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:48] [V] [TRT] --------------- Timing Runner: Conv_60 + Relu_61 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:48] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:48] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:48] [V] [TRT] --------------- Timing Runner: Conv_60 + Relu_61 (CaskConvolution[0x80000009])
[04/25/2025-09:08:48] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:48] [V] [TRT] --------------- Timing Runner: Conv_60 + Relu_61 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:48] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:48] [V] [TRT] *************** Autotuning format combination: Half(2073600,1:8,11520,64) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:48] [V] [TRT] --------------- Timing Runner: Conv_60 + Relu_61 (CaskConvolution[0x80000009])
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xdce100b9fe609424 Time: 0.14336
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xa9177bbe4e767df8 Time: 0.231278
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x05b6220f243edacd Time: 0.0968411
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 0x60da8c7151d91e47 Time: 0.113737
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xdfa020ef435ef810 Time: 0.115273
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_wngd_f16f16_f16_f16_nhwckrsc_nhwc_tilesize8x16x32x32_warpsize8x1x1_wngd2x2 Tactic: 0xded5318b4a444b84 Time: 0.134583
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x5568fd8a32f4a40f Time: 0.0972069
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xc0a02dc6095497cc Time: 0.117029
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xb4bec086187edcfc Time: 0.0968411
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x57c9a5ff682354a6 Time: 0.116882
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xdb0b80f591d1bb6d Time: 0.158574
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x31d93dc22d2af081 Time: 0.128073
[04/25/2025-09:08:48] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x5820b3dda403c4d0 Time: 0.184032
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 0xb17d53d15dfbfc9e Time: 0.117753
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x21b295c0c8f6c95a Time: 0.0975726
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xe1ff5ad20f5c6bf6 Time: 0.183584
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xbd08239a9317f2fd Time: 0.0961097
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3_aACCESS Tactic: 0x0866ddee325d07a6 Time: 0.072192
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xa570c55d303796ff Time: 0.081408
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x4a81ea1e51436a30 Time: 0.127707
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x0e07ff4f4f7c1ac9 Time: 0.126391
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xc9d24bd069159fa8 Time: 0.096256
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3_aACCESS Tactic: 0x263a38afd75e3a43 Time: 0.0667063
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x60c3421152ef8e10 Time: 0.119077
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: 0xa1a20ea714d420f4 Time: 0.224987
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xf79479a62ea9f901 Time: 0.151406
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xa83b68f30462f971 Time: 0.136631
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0x834e11ecd4ab9454 Time: 0.152137
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_wngd_f16f16_f16_f16_nhwckrsc_nhwc_tilesize16x16x64x16_warpsize8x1x1_wngd2x2 Tactic: 0xe29800439b9d3cf7 Time: 0.139271
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: 0x7005d10718f6c22d Time: 0.230254
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xd1aaad17ca35fbaa Time: 0.0810423
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3_aACCESS Tactic: 0x245530c34bd6090f Time: 0.118711
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x1x2_g1_tensor16x8x16_aACCESS Tactic: 0x841c601dec2a75bc Time: 0.0912091
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3_aACCESS Tactic: 0x30e8a8d7a953e5e9 Time: 0.0915749
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x048d6d0400f33439 Time: 0.11381
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xafd1e8bf6bd3d638 Time: 0.162816
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xf35e0311fa1cc516 Time: 0.128073
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x529f4431bdae94f5 Time: 0.0807497
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xa40cb43c296a36a8 Time: 0.136923
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x3e7eb35b91b9fa63 Time: 0.152283
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage4_warpsize2x1x2_g1_tensor16x8x16 Tactic: 0x7273dde1d0cd3bd5 Time: 0.0950194
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x17ebf0c9f418f10a Time: 0.160329
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xa033e20ae9f412b2 Time: 0.183589
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x866e7a5f6401b67f Time: 0.118345
[04/25/2025-09:08:49] [V] [TRT] Conv_60 + Relu_61 (CaskConvolution[0x80000009]) profiling completed in 0.130229 seconds. Fastest Tactic: 0x263a38afd75e3a43 Time: 0.0667063
[04/25/2025-09:08:49] [V] [TRT] --------------- Timing Runner: Conv_60 + Relu_61 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:49] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:49] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x263a38afd75e3a43
[04/25/2025-09:08:49] [V] [TRT] =============== Computing costs for Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168
[04/25/2025-09:08:49] [V] [TRT] *************** Autotuning format combination: Float(2073600,32400,180,1) -> Float(74649600,32400,180,1) ***************
[04/25/2025-09:08:49] [V] [TRT] --------------- Timing Runner: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (CaskConvolution[0x80000009])
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: 0xf067e6205da31c2e Time: 1.89586
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 0x5deb29b7a8e275f7 Time: 1.88475
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 0x503619c69ae500ff Time: 1.69896
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 0x3f243c490d502deb Time: 1.8982
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize1x4x1_g1_ffma_aligna4_alignc4_beta0_packed_stride Tactic: 0xede36641840ce3d2 Time: 2.40845
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xa9366041633a5135 Time: 3.23716
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize4x1x1_g1_ffma_aligna4_alignc4_beta0_packed_stride Tactic: 0x1673e3594ce11cea Time: 2.20584
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_wngd_f32f32_f32_f32_nchwkcrs_nchw_tilesize8x16x32x8_warpsize8x1x1_wngd2x2 Tactic: 0xe47e164f4a743900 Time: 1.5714
[04/25/2025-09:08:49] [V] [TRT] Fast skip Tactic:0xcb8a43f748d8a338 which exceed time limit during pre-run
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xcb8a43f748d8a338 Time: 3.74477
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x5aa723e0481da855 Time: 1.82287
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4_beta0_packed_stride Tactic: 0x7fc93550f5b9c127 Time: 1.80604
[04/25/2025-09:08:49] [V] [TRT] Fast skip Tactic:0x40a12e3938221818 which exceed time limit during pre-run
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x40a12e3938221818 Time: 5.06982
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x01cf8ce2da913006 Time: 1.7702
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xb0bf940d5e0f9f45 Time: 3.03967
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xd828f024626fa982 Time: 2.37451
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize2x2x1_g1_ffma_aligna4_alignc4_beta0_packed_stride Tactic: 0x31aa67f57c5aea77 Time: 2.17805
[04/25/2025-09:08:49] [V] [TRT] Fast skip Tactic:0x9d9fdb5fd9945f64 which exceed time limit during pre-run
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x9d9fdb5fd9945f64 Time: 3.45395
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x4efce38acc876f5c Time: 1.56965
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x4727434768e46395 Time: 2.00046
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_wngd_f32f32_f32_f32_nchwkcrs_nchw_tilesize8x16x16x8_warpsize8x1x1_wngd2x2 Tactic: 0xe38e9dfd56c33779 Time: 1.5635
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 0x94119b4c514b211a Time: 1.33178
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: 0xa8609adc4e0ceb90 Time: 2.08106
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: 0xf64396b97c889179 Time: 1.97266
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize4x1x1_g1_ffma_t1r3s3_aligna4_alignc4_beta0_packed_stride Tactic: 0xe640ceafd7d34ca9 Time: 1.92219
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x12dbf7d94ee3696d Time: 1.80882
[04/25/2025-09:08:49] [V] [TRT] Fast skip Tactic:0x8ad32616b1424be4 which exceed time limit during pre-run
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x8ad32616b1424be4 Time: 3.10579
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize2x2x1_g1_ffma_t1r3s3_aligna4_alignc4_beta0_packed_stride Tactic: 0x3712e3e595645874 Time: 1.62055
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_wngd_f32f32_f32_f32_nchwkcrs_nchw_tilesize8x16x64x8_warpsize8x1x1_wngd2x2 Tactic: 0x0190806602534cfd Time: 1.1144
[04/25/2025-09:08:49] [V] [TRT] Fast skip Tactic:0xa31d27de74b895ff which exceed time limit during pre-run
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xa31d27de74b895ff Time: 2.82726
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xbb8c3889c7eacd30 Time: 1.658
[04/25/2025-09:08:49] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (CaskConvolution[0x80000009]) profiling completed in 0.731777 seconds. Fastest Tactic: 0x0190806602534cfd Time: 1.1144
[04/25/2025-09:08:49] [V] [TRT] --------------- Timing Runner: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:49] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:49] [V] [TRT] --------------- Timing Runner: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:49] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:49] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x0190806602534cfd
[04/25/2025-09:08:49] [V] [TRT] *************** Autotuning format combination: Float(2073600,1,11520,64) -> Float(74649600,1,414720,2304) ***************
[04/25/2025-09:08:49] [V] [TRT] --------------- Timing Runner: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (CaskConvolution[0x80000009])
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x3f0c846d6379bc98 Time: 1.67687
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x19b688348f983aa0 Time: 2.46038
[04/25/2025-09:08:49] [V] [TRT] Fast skip Tactic:0xcf8ea142095f02d2 which exceed time limit during pre-run
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4_alignc4 Tactic: 0xcf8ea142095f02d2 Time: 3.65261
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0xf48db81f02eca9ee Time: 1.67717
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x92ed3100c35fc43e Time: 3.19386
[04/25/2025-09:08:49] [V] [TRT] Fast skip Tactic:0x5953bec563d26434 which exceed time limit during pre-run
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x5953bec563d26434 Time: 3.83795
[04/25/2025-09:08:49] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x8014228ec08b4d49 Time: 1.46198
[04/25/2025-09:08:50] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x1da91d865428f237 Time: 1.67995
[04/25/2025-09:08:50] [V] [TRT] Fast skip Tactic:0x4fd3c46622e98342 which exceed time limit during pre-run
[04/25/2025-09:08:50] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x4fd3c46622e98342 Time: 5.15072
[04/25/2025-09:08:50] [V] [TRT] Fast skip Tactic:0x32059de4888dfdda which exceed time limit during pre-run
[04/25/2025-09:08:50] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x32059de4888dfdda Time: 5.10464
[04/25/2025-09:08:50] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4_alignc4 Tactic: 0xf231cca3335919a4 Time: 2.59833
[04/25/2025-09:08:50] [V] [TRT] Fast skip Tactic:0x7121ec1db3f80c67 which exceed time limit during pre-run
[04/25/2025-09:08:50] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x7121ec1db3f80c67 Time: 3.76115
[04/25/2025-09:08:50] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0xd15dd11d64344e83 Time: 2.25953
[04/25/2025-09:08:50] [V] [TRT] Fast skip Tactic:0x0a143be7a52f301a which exceed time limit during pre-run
[04/25/2025-09:08:50] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x0a143be7a52f301a Time: 4.18304
[04/25/2025-09:08:50] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x62835fce994f06dd Time: 1.99124
[04/25/2025-09:08:50] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xa6448a1e79f1ca6f Time: 3.0167
[04/25/2025-09:08:50] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x94a7db94ba744c45 Time: 1.8865
[04/25/2025-09:08:50] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (CaskConvolution[0x80000009]) profiling completed in 0.378733 seconds. Fastest Tactic: 0x8014228ec08b4d49 Time: 1.46198
[04/25/2025-09:08:50] [V] [TRT] --------------- Timing Runner: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:50] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:50] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x8014228ec08b4d49
[04/25/2025-09:08:50] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(74649600,32400,180,1) ***************
[04/25/2025-09:08:50] [V] [TRT] --------------- Timing Runner: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (CaskConvolution[0x80000009])
[04/25/2025-09:08:50] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 0x9787b83bedcff6a2 Time: 1.34188
[04/25/2025-09:08:50] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_alignc4 Tactic: 0xe8f7b6a5bab325f8 Time: 1.42073
[04/25/2025-09:08:50] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_alignc4 Tactic: 0x9fd9fe001908ce2e Time: 1.27371
[04/25/2025-09:08:50] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0xe0a307ffe0ffb6a5 Time: 1.15917
[04/25/2025-09:08:50] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3_alignc4 Tactic: 0x1323e48791e2f671 Time: 1.13284
[04/25/2025-09:08:50] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0x3104d85fecdd547c Time: 1.12216
[04/25/2025-09:08:50] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (CaskConvolution[0x80000009]) profiling completed in 0.107037 seconds. Fastest Tactic: 0x3104d85fecdd547c Time: 1.12216
[04/25/2025-09:08:50] [V] [TRT] --------------- Timing Runner: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:50] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:50] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x3104d85fecdd547c
[04/25/2025-09:08:50] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(18662400,1:4,103680,576) ***************
[04/25/2025-09:08:50] [V] [TRT] --------------- Timing Runner: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (CaskConvolution[0x80000009])
[04/25/2025-09:08:50] [V] [TRT] Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 0xbdfdef6b84f7ccc9 Time: 1.80487
[04/25/2025-09:08:50] [V] [TRT] Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0x3e2b881168d9689d Time: 1.96725
[04/25/2025-09:08:50] [V] [TRT] Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0xf90060ce8193b811 Time: 1.79888
[04/25/2025-09:08:50] [V] [TRT] Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x7bc32c782b800c48 Time: 1.66049
[04/25/2025-09:08:50] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc8 Tactic: 0x96467934a22da27d Time: 2.02094
[04/25/2025-09:08:50] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x64_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8 Tactic: 0x9355e195cee05798 Time: 1.59056
[04/25/2025-09:08:50] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x64_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc8 Tactic: 0x3a8712b17741b582 Time: 1.18872
[04/25/2025-09:08:50] [V] [TRT] Fast skip Tactic:0xb3e5ce9d1b1da232 which exceed time limit during pre-run
[04/25/2025-09:08:50] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4 Tactic: 0xb3e5ce9d1b1da232 Time: 3.33517
[04/25/2025-09:08:50] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x64_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc4 Tactic: 0xb6f6563c77d057d7 Time: 1.24796
[04/25/2025-09:08:50] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x64_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8 Tactic: 0xe9e5475c77d60638 Time: 2.13489
[04/25/2025-09:08:50] [V] [TRT] Fast skip Tactic:0x43ffe5cf09cee087 which exceed time limit during pre-run
[04/25/2025-09:08:50] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4_alignc8 Tactic: 0x43ffe5cf09cee087 Time: 3.39149
[04/25/2025-09:08:50] [V] [TRT] Fast skip Tactic:0x4640eb34c8ecc700 which exceed time limit during pre-run
[04/25/2025-09:08:50] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8_alignc8 Tactic: 0x4640eb34c8ecc700 Time: 2.57638
[04/25/2025-09:08:50] [V] [TRT] Fast skip Tactic:0x3f948a101b8c4067 which exceed time limit during pre-run
[04/25/2025-09:08:50] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8 Tactic: 0x3f948a101b8c4067 Time: 2.57638
[04/25/2025-09:08:50] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc4 Tactic: 0xfed494d61b2087ba Time: 1.39162
[04/25/2025-09:08:50] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc8 Tactic: 0x72a5d05b1bb165ef Time: 1.32637
[04/25/2025-09:08:50] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 0x9cb304e2edbc1221 Time: 1.25835
[04/25/2025-09:08:50] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8_alignc4 Tactic: 0xf78ec258f27b3e23 Time: 2.29244
[04/25/2025-09:08:50] [V] [TRT] Fast skip Tactic:0x1acd4f006848c62b which exceed time limit during pre-run
[04/25/2025-09:08:50] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x64_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4_alignc8 Tactic: 0x1acd4f006848c62b Time: 2.64704
[04/25/2025-09:08:50] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0xb443c221fcb1565b Time: 1.11616
[04/25/2025-09:08:50] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x64_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc4 Tactic: 0xcc46f0f5cee60677 Time: 1.40098
[04/25/2025-09:08:50] [V] [TRT] Fast skip Tactic:0x7e40882e33c8fbf1 which exceed time limit during pre-run
[04/25/2025-09:08:50] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4_alignc8 Tactic: 0x7e40882e33c8fbf1 Time: 2.39104
[04/25/2025-09:08:50] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x64_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc8 Tactic: 0x4037b478ce77e422 Time: 1.73422
[04/25/2025-09:08:50] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc4 Tactic: 0x1a373db9a2bc4028 Time: 1.81833
[04/25/2025-09:08:50] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x64_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 0x10383a0781d24dde Time: 1.43082
[04/25/2025-09:08:50] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8_alignc8 Tactic: 0x7bff86d5f2eadc76 Time: 2.12246
[04/25/2025-09:08:50] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x64_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 0xb33296dda7141c64 Time: 1.22266
[04/25/2025-09:08:50] [V] [TRT] Fast skip Tactic:0x570667f2a28165a0 which exceed time limit during pre-run
[04/25/2025-09:08:50] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4 Tactic: 0x570667f2a28165a0 Time: 2.50061
[04/25/2025-09:08:50] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x64_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8_alignc4 Tactic: 0x93030576a9fb03f9 Time: 1.59408
[04/25/2025-09:08:50] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 0x999e005e3b016ea6 Time: 1.09744
[04/25/2025-09:08:50] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0x65e41d81f093b482 Time: 1.15727
[04/25/2025-09:08:50] [V] [TRT] Fast skip Tactic:0x22cadc265a3b2e32 which exceed time limit during pre-run
[04/25/2025-09:08:50] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x64_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4_alignc8 Tactic: 0x22cadc265a3b2e32 Time: 3.70688
[04/25/2025-09:08:50] [V] [TRT] Fast skip Tactic:0xab0496509b88ebe0 which exceed time limit during pre-run
[04/25/2025-09:08:50] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x64_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8_alignc4 Tactic: 0xab0496509b88ebe0 Time: 2.2313
[04/25/2025-09:08:50] [V] [TRT] Fast skip Tactic:0xdb77237fa21087f5 which exceed time limit during pre-run
[04/25/2025-09:08:50] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8 Tactic: 0xdb77237fa21087f5 Time: 2.34291
[04/25/2025-09:08:50] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 0xae48d3ccfe1edfcd Time: 1.6403
[04/25/2025-09:08:50] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (CaskConvolution[0x80000009]) profiling completed in 0.586282 seconds. Fastest Tactic: 0x999e005e3b016ea6 Time: 1.09744
[04/25/2025-09:08:50] [V] [TRT] --------------- Timing Runner: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:50] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:50] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x999e005e3b016ea6
[04/25/2025-09:08:50] [V] [TRT] *************** Autotuning format combination: Half(2073600,32400,180,1) -> Half(74649600,32400,180,1) ***************
[04/25/2025-09:08:50] [V] [TRT] --------------- Timing Runner: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (CaskConvolution[0x80000009])
[04/25/2025-09:08:50] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:50] [V] [TRT] --------------- Timing Runner: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:50] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:50] [V] [TRT] --------------- Timing Runner: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:50] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:50] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:2,5760,32) -> Half(37324800,1:2,207360,1152) ***************
[04/25/2025-09:08:50] [V] [TRT] --------------- Timing Runner: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (CaskConvolution[0x80000009])
[04/25/2025-09:08:50] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:50] [V] [TRT] --------------- Timing Runner: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:50] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:50] [V] [TRT] *************** Autotuning format combination: Half(518400,1:4,2880,16) -> Half(18662400,1:4,103680,576) ***************
[04/25/2025-09:08:51] [V] [TRT] --------------- Timing Runner: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (CaskConvolution[0x80000009])
[04/25/2025-09:08:51] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:51] [V] [TRT] --------------- Timing Runner: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:51] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:51] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Float(74649600,32400,180,1) ***************
[04/25/2025-09:08:51] [V] [TRT] --------------- Timing Runner: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (CaskConvolution[0x80000009])
[04/25/2025-09:08:51] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:51] [V] [TRT] --------------- Timing Runner: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:51] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:51] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Half(9331200,1:8,51840,288) ***************
[04/25/2025-09:08:51] [V] [TRT] --------------- Timing Runner: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (CaskConvolution[0x80000009])
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xdce100b9fe609424 Time: 0.705097
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xa9177bbe4e767df8 Time: 0.313637
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x05b6220f243edacd Time: 0.533211
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 0x60da8c7151d91e47 Time: 0.311735
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xdfa020ef435ef810 Time: 0.338213
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_wngd_f16f16_f16_f16_nhwckrsc_nhwc_tilesize8x16x32x32_warpsize8x1x1_wngd2x2 Tactic: 0xded5318b4a444b84 Time: 0.671451
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x5568fd8a32f4a40f Time: 0.541257
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xc0a02dc6095497cc Time: 0.356645
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xb4bec086187edcfc Time: 0.491666
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x57c9a5ff682354a6 Time: 0.361033
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xdb0b80f591d1bb6d Time: 0.438126
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x31d93dc22d2af081 Time: 0.654043
[04/25/2025-09:08:51] [V] [TRT] Fast skip Tactic:0x5820b3dda403c4d0 which exceed time limit during pre-run
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x5820b3dda403c4d0 Time: 1.20218
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 0xb17d53d15dfbfc9e Time: 0.317147
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x21b295c0c8f6c95a Time: 0.549742
[04/25/2025-09:08:51] [V] [TRT] Fast skip Tactic:0xe1ff5ad20f5c6bf6 which exceed time limit during pre-run
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xe1ff5ad20f5c6bf6 Time: 1.08442
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xbd08239a9317f2fd Time: 0.467675
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3_aACCESS Tactic: 0x0866ddee325d07a6 Time: 0.348014
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xa570c55d303796ff Time: 0.396434
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x4a81ea1e51436a30 Time: 0.634002
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x0e07ff4f4f7c1ac9 Time: 0.355474
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xc9d24bd069159fa8 Time: 0.465193
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3_aACCESS Tactic: 0x263a38afd75e3a43 Time: 0.379305
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x60c3421152ef8e10 Time: 0.344942
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: 0xa1a20ea714d420f4 Time: 0.313929
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xf79479a62ea9f901 Time: 0.776923
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xa83b68f30462f971 Time: 0.736987
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0x834e11ecd4ab9454 Time: 0.77707
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_wngd_f16f16_f16_f16_nhwckrsc_nhwc_tilesize16x16x64x16_warpsize8x1x1_wngd2x2 Tactic: 0xe29800439b9d3cf7 Time: 0.518437
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: 0x7005d10718f6c22d Time: 0.319634
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xd1aaad17ca35fbaa Time: 0.402725
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3_aACCESS Tactic: 0x245530c34bd6090f Time: 0.338651
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x1x2_g1_tensor16x8x16_aACCESS Tactic: 0x841c601dec2a75bc Time: 0.473381
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3_aACCESS Tactic: 0x30e8a8d7a953e5e9 Time: 0.479086
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x048d6d0400f33439 Time: 0.311442
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xafd1e8bf6bd3d638 Time: 0.442514
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xf35e0311fa1cc516 Time: 0.660334
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x529f4431bdae94f5 Time: 0.400384
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xa40cb43c296a36a8 Time: 0.710217
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x3e7eb35b91b9fa63 Time: 0.776192
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage4_warpsize2x1x2_g1_tensor16x8x16 Tactic: 0x7273dde1d0cd3bd5 Time: 0.539794
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x17ebf0c9f418f10a Time: 0.43637
[04/25/2025-09:08:51] [V] [TRT] Fast skip Tactic:0xa033e20ae9f412b2 which exceed time limit during pre-run
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xa033e20ae9f412b2 Time: 1.14995
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x866e7a5f6401b67f Time: 0.351963
[04/25/2025-09:08:51] [V] [TRT] Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (CaskConvolution[0x80000009]) profiling completed in 0.324844 seconds. Fastest Tactic: 0x048d6d0400f33439 Time: 0.311442
[04/25/2025-09:08:51] [V] [TRT] --------------- Timing Runner: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:51] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:51] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x048d6d0400f33439
[04/25/2025-09:08:51] [V] [TRT] =============== Computing costs for Conv_64
[04/25/2025-09:08:51] [V] [TRT] *************** Autotuning format combination: Float(74649600,32400,180,1) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:51] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_64
[04/25/2025-09:08:51] [V] [TRT] --------------- Timing Runner: Conv_64 (CaskConvolution[0x80000009])
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: 0xf067e6205da31c2e Time: 0.0922331
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 0x5deb29b7a8e275f7 Time: 0.054272
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 0x503619c69ae500ff Time: 0.0913577
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 0x3f243c490d502deb Time: 0.055101
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize1x4x1_g1_ffma_aligna4_alignc4_beta0_packed_stride Tactic: 0xede36641840ce3d2 Time: 0.0618301
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xa9366041633a5135 Time: 0.0497371
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP5_TQ5_C1_R3_S3_U1_V1 Tactic: 0x4165f9dd71b6e38a Time: 0.0746857
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP4_TQ7_C4_R3_S3_U1_V1 Tactic: 0x753397072379d6e9 Time: 0.0704107
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize4x1x1_g1_ffma_aligna4_alignc4_beta0_packed_stride Tactic: 0x1673e3594ce11cea Time: 0.0649021
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP7_TQ4_C1_R3_S3_U1_V1 Tactic: 0xe2f49879bec27b91 Time: 0.0716069
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ5_C1_R3_S3_U1_V1 Tactic: 0x5ac6bfe0a27fc97b Time: 0.0507611
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP4_TQ8_C1_R3_S3_U1_V1 Tactic: 0x36209b75daa96278 Time: 0.100206
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xcb8a43f748d8a338 Time: 0.0529554
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP4_TQ7_C2_R3_S3_U1_V1 Tactic: 0x57c1b87347e45486 Time: 0.0424229
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x5aa723e0481da855 Time: 0.0930377
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP5_TQ7_C8_R3_S3_U1_V1 Tactic: 0x688222fe126a1c16 Time: 0.0678278
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4_beta0_packed_stride Tactic: 0x7fc93550f5b9c127 Time: 0.0520777
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec1_1_TP7_TQ8_C8_R3_S3_U1_V1 Tactic: 0x06cd3594e0105153 Time: 0.0300754
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x40a12e3938221818 Time: 0.041472
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x01cf8ce2da913006 Time: 0.0904046
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xb0bf940d5e0f9f45 Time: 0.0396434
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xd828f024626fa982 Time: 0.0681691
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP6_TQ5_C2_R3_S3_U1_V1 Tactic: 0x1e01f84aaf51153a Time: 0.0739474
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize2x2x1_g1_ffma_aligna4_alignc4_beta0_packed_stride Tactic: 0x31aa67f57c5aea77 Time: 0.0606126
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ8_C4_R3_S3_U1_V1 Tactic: 0x4bb6b59660d316a7 Time: 0.0426057
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x9d9fdb5fd9945f64 Time: 0.0285842
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x4efce38acc876f5c Time: 0.079584
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x4727434768e46395 Time: 0.0637318
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec1_1_TP6_TQ8_C8_R3_S3_U1_V1 Tactic: 0xee473898b5318f6e Time: 0.0319753
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP8_TQ7_C4_R3_S3_U1_V1 Tactic: 0x372f7588455e8e60 Time: 0.0373029
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP5_TQ7_C2_R3_S3_U1_V1 Tactic: 0xbf4bb57f12c58abb Time: 0.0496884
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP4_TQ7_C1_R3_S3_U1_V1 Tactic: 0xfb8cf2d51feb56fa Time: 0.0889417
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP4_TQ8_C2_R3_S3_U1_V1 Tactic: 0xc20222dd5422e80a Time: 0.0822126
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP8_TQ5_C2_R3_S3_U1_V1 Tactic: 0x1fd1aff6cc3bef4c Time: 0.0617341
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ7_C2_R3_S3_U1_V1 Tactic: 0xfc87004c17882844 Time: 0.0504183
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 0x94119b4c514b211a Time: 0.0270141
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: 0xa8609adc4e0ceb90 Time: 0.0498834
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ6_C8_R3_S3_U1_V1 Tactic: 0x937cb0540b9a0c03 Time: 0.038656
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: 0xf64396b97c889179 Time: 0.0570027
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ7_C8_R3_S3_U1_V1 Tactic: 0x732164c3c1a336e7 Time: 0.0464823
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize4x1x1_g1_ffma_t1r3s3_aligna4_alignc4_beta0_packed_stride Tactic: 0xe640ceafd7d34ca9 Time: 0.0539794
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ7_C4_R3_S3_U1_V1 Tactic: 0x861adc36a5912225 Time: 0.0465189
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x12dbf7d94ee3696d Time: 0.0511025
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x8ad32616b1424be4 Time: 0.0417646
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize2x2x1_g1_ffma_t1r3s3_aligna4_alignc4_beta0_packed_stride Tactic: 0x3712e3e595645874 Time: 0.0488107
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP3_TQ7_C8_R3_S3_U1_V1 Tactic: 0xacd7fdab1dbcfb17 Time: 0.0603672
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP8_TQ5_C4_R3_S3_U1_V1 Tactic: 0x654c738c7e22e52d Time: 0.0442903
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP7_TQ3_C1_R3_S3_U1_V1 Tactic: 0xf40c46e2397ffca2 Time: 0.0724114
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP5_TQ7_C4_R3_S3_U1_V1 Tactic: 0xc5d66905a0dc80da Time: 0.0370469
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP5_TQ8_C8_R3_S3_U1_V1 Tactic: 0xfd41b85001aca09a Time: 0.0445074
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ4_C1_R3_S3_U1_V1 Tactic: 0xba9b6b776846f39f Time: 0.0486644
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP8_TQ5_C8_R3_S3_U1_V1 Tactic: 0x9077cb791a10f1ef Time: 0.0367177
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP5_TQ7_C2_R3_S3_U1_V1 Tactic: 0xe7244671c44102b5 Time: 0.0759223
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP5_TQ7_C4_R3_S3_U1_V1 Tactic: 0x9db99a0b765808d4 Time: 0.0705112
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP7_TQ5_C1_R3_S3_U1_V1 Tactic: 0x02a94cee74fb4175 Time: 0.0696808
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP4_TQ8_C4_R3_S3_U1_V1 Tactic: 0xb89ffea7e63be26b Time: 0.0582705
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec1_1_TP4_TQ7_C1_R3_S3_U1_V1 Tactic: 0x1ba3392c2d9e8dc2 Time: 0.0369006
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xa31d27de74b895ff Time: 0.0684663
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP5_TQ7_C1_R3_S3_U1_V1 Tactic: 0x1306ffd94aca88c7 Time: 0.0759954
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xbb8c3889c7eacd30 Time: 0.0797257
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec1_1_TP6_TQ8_C2_R3_S3_U1_V1 Tactic: 0x61e15c17631a91cd Time: 0.0294912
[04/25/2025-09:08:51] [V] [TRT] Conv_64 (CaskConvolution[0x80000009]) profiling completed in 0.163339 seconds. Fastest Tactic: 0x94119b4c514b211a Time: 0.0270141
[04/25/2025-09:08:51] [V] [TRT] --------------- Timing Runner: Conv_64 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:51] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:51] [V] [TRT] --------------- Timing Runner: Conv_64 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:51] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:51] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x94119b4c514b211a
[04/25/2025-09:08:51] [V] [TRT] *************** Autotuning format combination: Float(74649600,1,414720,2304) long-strided -> Float(64800,1,360,2) ***************
[04/25/2025-09:08:51] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_64
[04/25/2025-09:08:51] [V] [TRT] --------------- Timing Runner: Conv_64 (CaskConvolution[0x80000009])
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x3f0c846d6379bc98 Time: 0.160037
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x19b688348f983aa0 Time: 0.0600747
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4_alignc4 Tactic: 0xcf8ea142095f02d2 Time: 0.0303982
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0xf48db81f02eca9ee Time: 0.0525653
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x92ed3100c35fc43e Time: 0.0254537
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x5953bec563d26434 Time: 0.0426057
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x8014228ec08b4d49 Time: 0.0469577
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x1da91d865428f237 Time: 0.0528091
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x4fd3c46622e98342 Time: 0.0364983
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x32059de4888dfdda Time: 0.0331483
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4_alignc4 Tactic: 0xf231cca3335919a4 Time: 0.0321829
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x7121ec1db3f80c67 Time: 0.0437394
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0xd15dd11d64344e83 Time: 0.0969874
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x0a143be7a52f301a Time: 0.0480305
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x62835fce994f06dd Time: 0.0560274
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xa6448a1e79f1ca6f Time: 0.041216
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x94a7db94ba744c45 Time: 0.0597333
[04/25/2025-09:08:51] [V] [TRT] Conv_64 (CaskConvolution[0x80000009]) profiling completed in 0.0466519 seconds. Fastest Tactic: 0x92ed3100c35fc43e Time: 0.0254537
[04/25/2025-09:08:51] [V] [TRT] --------------- Timing Runner: Conv_64 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:51] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:51] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x92ed3100c35fc43e
[04/25/2025-09:08:51] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:51] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_64
[04/25/2025-09:08:51] [V] [TRT] --------------- Timing Runner: Conv_64 (CaskConvolution[0x80000009])
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 0x9787b83bedcff6a2 Time: 0.0631954
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_alignc4 Tactic: 0xe8f7b6a5bab325f8 Time: 0.0676328
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_alignc4 Tactic: 0x9fd9fe001908ce2e Time: 0.0650484
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0xe0a307ffe0ffb6a5 Time: 0.0645608
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3_alignc4 Tactic: 0x1323e48791e2f671 Time: 0.0637318
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0x3104d85fecdd547c Time: 0.0628053
[04/25/2025-09:08:51] [V] [TRT] Conv_64 (CaskConvolution[0x80000009]) profiling completed in 0.017078 seconds. Fastest Tactic: 0x3104d85fecdd547c Time: 0.0628053
[04/25/2025-09:08:51] [V] [TRT] --------------- Timing Runner: Conv_64 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:51] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:51] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x3104d85fecdd547c
[04/25/2025-09:08:51] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:51] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_64
[04/25/2025-09:08:51] [V] [TRT] --------------- Timing Runner: Conv_64 (CaskConvolution[0x80000009])
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 0xbdfdef6b84f7ccc9 Time: 0.0543208
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0x3e2b881168d9689d Time: 0.0320658
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0xf90060ce8193b811 Time: 0.0885029
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x7bc32c782b800c48 Time: 0.088208
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc8 Tactic: 0x96467934a22da27d Time: 0.0203703
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x64_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8 Tactic: 0x9355e195cee05798 Time: 0.026429
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x64_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc8 Tactic: 0x3a8712b17741b582 Time: 0.0219847
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4 Tactic: 0xb3e5ce9d1b1da232 Time: 0.0325925
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x64_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc4 Tactic: 0xb6f6563c77d057d7 Time: 0.0219847
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x64_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8 Tactic: 0xe9e5475c77d60638 Time: 0.0289344
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4_alignc8 Tactic: 0x43ffe5cf09cee087 Time: 0.0305737
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8_alignc8 Tactic: 0x4640eb34c8ecc700 Time: 0.0313655
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8 Tactic: 0x3f948a101b8c4067 Time: 0.0304859
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc4 Tactic: 0xfed494d61b2087ba Time: 0.0236134
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc8 Tactic: 0x72a5d05b1bb165ef Time: 0.0233417
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 0x9cb304e2edbc1221 Time: 0.0234057
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8_alignc4 Tactic: 0xf78ec258f27b3e23 Time: 0.0334702
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x64_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4_alignc8 Tactic: 0x1acd4f006848c62b Time: 0.0350793
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0xb443c221fcb1565b Time: 0.0633417
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x64_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc4 Tactic: 0xcc46f0f5cee60677 Time: 0.0151698
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4_alignc8 Tactic: 0x7e40882e33c8fbf1 Time: 0.0310665
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x64_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc8 Tactic: 0x4037b478ce77e422 Time: 0.0188343
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc4 Tactic: 0x1a373db9a2bc4028 Time: 0.0203337
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x64_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 0x10383a0781d24dde Time: 0.015243
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8_alignc8 Tactic: 0x7bff86d5f2eadc76 Time: 0.0334702
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x64_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 0xb33296dda7141c64 Time: 0.0232594
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4 Tactic: 0x570667f2a28165a0 Time: 0.0358034
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x64_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8_alignc4 Tactic: 0x93030576a9fb03f9 Time: 0.026624
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 0x999e005e3b016ea6 Time: 0.062464
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0x65e41d81f093b482 Time: 0.0655848
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x64_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4_alignc8 Tactic: 0x22cadc265a3b2e32 Time: 0.0304274
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x64_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8_alignc4 Tactic: 0xab0496509b88ebe0 Time: 0.0284526
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8 Tactic: 0xdb77237fa21087f5 Time: 0.0330606
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 0xae48d3ccfe1edfcd Time: 0.017343
[04/25/2025-09:08:51] [V] [TRT] Conv_64 (CaskConvolution[0x80000009]) profiling completed in 0.0816531 seconds. Fastest Tactic: 0xcc46f0f5cee60677 Time: 0.0151698
[04/25/2025-09:08:51] [V] [TRT] --------------- Timing Runner: Conv_64 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:51] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:51] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xcc46f0f5cee60677
[04/25/2025-09:08:51] [V] [TRT] *************** Autotuning format combination: Half(74649600,32400,180,1) long-strided -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:51] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_64
[04/25/2025-09:08:51] [V] [TRT] --------------- Timing Runner: Conv_64 (CaskConvolution[0x80000009])
[04/25/2025-09:08:51] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:51] [V] [TRT] --------------- Timing Runner: Conv_64 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:51] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:51] [V] [TRT] --------------- Timing Runner: Conv_64 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:51] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:51] [V] [TRT] *************** Autotuning format combination: Half(37324800,1:2,207360,1152) long-strided -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:51] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_64
[04/25/2025-09:08:51] [V] [TRT] --------------- Timing Runner: Conv_64 (CaskConvolution[0x80000009])
[04/25/2025-09:08:51] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:51] [V] [TRT] --------------- Timing Runner: Conv_64 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:51] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:51] [V] [TRT] *************** Autotuning format combination: Half(18662400,1:4,103680,576) long-strided -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:51] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_64
[04/25/2025-09:08:51] [V] [TRT] --------------- Timing Runner: Conv_64 (CaskConvolution[0x80000009])
[04/25/2025-09:08:51] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:51] [V] [TRT] --------------- Timing Runner: Conv_64 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:51] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:51] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:51] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_64
[04/25/2025-09:08:51] [V] [TRT] --------------- Timing Runner: Conv_64 (CaskConvolution[0x80000009])
[04/25/2025-09:08:51] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:51] [V] [TRT] --------------- Timing Runner: Conv_64 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:51] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:51] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:51] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_64
[04/25/2025-09:08:51] [V] [TRT] --------------- Timing Runner: Conv_64 (CaskConvolution[0x80000009])
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xdce100b9fe609424 Time: 0.0122998
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xa9177bbe4e767df8 Time: 0.0342601
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x05b6220f243edacd Time: 0.0146871
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 0x60da8c7151d91e47 Time: 0.0187063
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xdfa020ef435ef810 Time: 0.020096
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x5568fd8a32f4a40f Time: 0.0151113
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xc0a02dc6095497cc Time: 0.0212336
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xb4bec086187edcfc Time: 0.0143355
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x57c9a5ff682354a6 Time: 0.0211905
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xdb0b80f591d1bb6d Time: 0.0234684
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x31d93dc22d2af081 Time: 0.0168229
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x5820b3dda403c4d0 Time: 0.0170179
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 0xb17d53d15dfbfc9e Time: 0.0190354
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x21b295c0c8f6c95a Time: 0.0145115
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xe1ff5ad20f5c6bf6 Time: 0.016254
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xbd08239a9317f2fd Time: 0.0144677
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3_aACCESS Tactic: 0x0866ddee325d07a6 Time: 0.0123368
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xa570c55d303796ff Time: 0.0128499
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x4a81ea1e51436a30 Time: 0.0165308
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x0e07ff4f4f7c1ac9 Time: 0.0211487
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xc9d24bd069159fa8 Time: 0.0146725
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3_aACCESS Tactic: 0x263a38afd75e3a43 Time: 0.0131391
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x60c3421152ef8e10 Time: 0.0205845
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: 0xa1a20ea714d420f4 Time: 0.0344942
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xf79479a62ea9f901 Time: 0.0124213
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xa83b68f30462f971 Time: 0.0120446
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0x834e11ecd4ab9454 Time: 0.0125322
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: 0x7005d10718f6c22d Time: 0.0347291
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xd1aaad17ca35fbaa Time: 0.0128853
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3_aACCESS Tactic: 0x245530c34bd6090f Time: 0.0206681
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x1x2_g1_tensor16x8x16_aACCESS Tactic: 0x841c601dec2a75bc Time: 0.0147895
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3_aACCESS Tactic: 0x30e8a8d7a953e5e9 Time: 0.0149659
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x048d6d0400f33439 Time: 0.0187069
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xafd1e8bf6bd3d638 Time: 0.0230296
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xf35e0311fa1cc516 Time: 0.0170504
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x529f4431bdae94f5 Time: 0.0126415
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xa40cb43c296a36a8 Time: 0.0122149
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x3e7eb35b91b9fa63 Time: 0.0124099
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage4_warpsize2x1x2_g1_tensor16x8x16 Tactic: 0x7273dde1d0cd3bd5 Time: 0.0159451
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x17ebf0c9f418f10a Time: 0.0230922
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xa033e20ae9f412b2 Time: 0.016449
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x866e7a5f6401b67f Time: 0.0206054
[04/25/2025-09:08:51] [V] [TRT] Conv_64 (CaskConvolution[0x80000009]) profiling completed in 0.0944884 seconds. Fastest Tactic: 0xa83b68f30462f971 Time: 0.0120446
[04/25/2025-09:08:51] [V] [TRT] --------------- Timing Runner: Conv_64 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:51] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:51] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xa83b68f30462f971
[04/25/2025-09:08:51] [V] [TRT] *************** Autotuning format combination: Float(2073600,32400,180,1) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:51] [V] [TRT] --------------- Timing Runner: Conv_64 (CaskConvolution[0x80000009])
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: 0xf067e6205da31c2e Time: 0.09216
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 0x5deb29b7a8e275f7 Time: 0.0543208
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 0x503619c69ae500ff Time: 0.0914286
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 0x3f243c490d502deb Time: 0.0550522
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize1x4x1_g1_ffma_aligna4_alignc4_beta0_packed_stride Tactic: 0xede36641840ce3d2 Time: 0.0619764
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xa9366041633a5135 Time: 0.0497859
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP5_TQ5_C1_R3_S3_U1_V1 Tactic: 0x4165f9dd71b6e38a Time: 0.0749714
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP4_TQ7_C4_R3_S3_U1_V1 Tactic: 0x753397072379d6e9 Time: 0.0705097
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize4x1x1_g1_ffma_aligna4_alignc4_beta0_packed_stride Tactic: 0x1673e3594ce11cea Time: 0.0650484
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_wngd_f32f32_f32_f32_nchwkcrs_nchw_tilesize8x16x32x8_warpsize8x1x1_wngd2x2 Tactic: 0xe47e164f4a743900 Time: 0.0288475
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP7_TQ4_C1_R3_S3_U1_V1 Tactic: 0xe2f49879bec27b91 Time: 0.07168
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ5_C1_R3_S3_U1_V1 Tactic: 0x5ac6bfe0a27fc97b Time: 0.0507611
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP4_TQ8_C1_R3_S3_U1_V1 Tactic: 0x36209b75daa96278 Time: 0.100133
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xcb8a43f748d8a338 Time: 0.0531992
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP4_TQ7_C2_R3_S3_U1_V1 Tactic: 0x57c1b87347e45486 Time: 0.0424606
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x5aa723e0481da855 Time: 0.0918674
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP5_TQ7_C8_R3_S3_U1_V1 Tactic: 0x688222fe126a1c16 Time: 0.0679741
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4_beta0_packed_stride Tactic: 0x7fc93550f5b9c127 Time: 0.0521265
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec1_1_TP7_TQ8_C8_R3_S3_U1_V1 Tactic: 0x06cd3594e0105153 Time: 0.0300763
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x40a12e3938221818 Time: 0.0415086
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x01cf8ce2da913006 Time: 0.0904046
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xb0bf940d5e0f9f45 Time: 0.03968
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xd828f024626fa982 Time: 0.0681691
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP6_TQ5_C2_R3_S3_U1_V1 Tactic: 0x1e01f84aaf51153a Time: 0.0738743
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize2x2x1_g1_ffma_aligna4_alignc4_beta0_packed_stride Tactic: 0x31aa67f57c5aea77 Time: 0.0606598
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ8_C4_R3_S3_U1_V1 Tactic: 0x4bb6b59660d316a7 Time: 0.0426423
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x9d9fdb5fd9945f64 Time: 0.028672
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x4efce38acc876f5c Time: 0.0797257
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x4727434768e46395 Time: 0.0631954
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec1_1_TP6_TQ8_C8_R3_S3_U1_V1 Tactic: 0xee473898b5318f6e Time: 0.0319781
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_wngd_f32f32_f32_f32_nchwkcrs_nchw_tilesize8x16x16x8_warpsize8x1x1_wngd2x2 Tactic: 0xe38e9dfd56c33779 Time: 0.0202411
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP8_TQ7_C4_R3_S3_U1_V1 Tactic: 0x372f7588455e8e60 Time: 0.037376
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP5_TQ7_C2_R3_S3_U1_V1 Tactic: 0xbf4bb57f12c58abb Time: 0.0498347
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP4_TQ7_C1_R3_S3_U1_V1 Tactic: 0xfb8cf2d51feb56fa Time: 0.0888686
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP4_TQ8_C2_R3_S3_U1_V1 Tactic: 0xc20222dd5422e80a Time: 0.0822857
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP8_TQ5_C2_R3_S3_U1_V1 Tactic: 0x1fd1aff6cc3bef4c Time: 0.0618773
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ7_C2_R3_S3_U1_V1 Tactic: 0xfc87004c17882844 Time: 0.0503223
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 0x94119b4c514b211a Time: 0.0270408
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: 0xa8609adc4e0ceb90 Time: 0.0498347
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ6_C8_R3_S3_U1_V1 Tactic: 0x937cb0540b9a0c03 Time: 0.0385486
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: 0xf64396b97c889179 Time: 0.0570514
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ7_C8_R3_S3_U1_V1 Tactic: 0x732164c3c1a336e7 Time: 0.0464091
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize4x1x1_g1_ffma_t1r3s3_aligna4_alignc4_beta0_packed_stride Tactic: 0xe640ceafd7d34ca9 Time: 0.0537844
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ7_C4_R3_S3_U1_V1 Tactic: 0x861adc36a5912225 Time: 0.046336
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x12dbf7d94ee3696d Time: 0.051005
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x8ad32616b1424be4 Time: 0.0396434
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize2x2x1_g1_ffma_t1r3s3_aligna4_alignc4_beta0_packed_stride Tactic: 0x3712e3e595645874 Time: 0.0484693
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm80_xmma_fprop_wngd_f32f32_f32_f32_nchwkcrs_nchw_tilesize8x16x64x8_warpsize8x1x1_wngd2x2 Tactic: 0x0190806602534cfd Time: 0.0404846
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP3_TQ7_C8_R3_S3_U1_V1 Tactic: 0xacd7fdab1dbcfb17 Time: 0.0604114
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP8_TQ5_C4_R3_S3_U1_V1 Tactic: 0x654c738c7e22e52d Time: 0.0442891
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP7_TQ3_C1_R3_S3_U1_V1 Tactic: 0xf40c46e2397ffca2 Time: 0.0724114
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP5_TQ7_C4_R3_S3_U1_V1 Tactic: 0xc5d66905a0dc80da Time: 0.0369349
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP5_TQ8_C8_R3_S3_U1_V1 Tactic: 0xfd41b85001aca09a Time: 0.044544
[04/25/2025-09:08:51] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ4_C1_R3_S3_U1_V1 Tactic: 0xba9b6b776846f39f Time: 0.0487147
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP8_TQ5_C8_R3_S3_U1_V1 Tactic: 0x9077cb791a10f1ef Time: 0.0366446
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP5_TQ7_C2_R3_S3_U1_V1 Tactic: 0xe7244671c44102b5 Time: 0.0758491
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP5_TQ7_C4_R3_S3_U1_V1 Tactic: 0x9db99a0b765808d4 Time: 0.0705585
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP7_TQ5_C1_R3_S3_U1_V1 Tactic: 0x02a94cee74fb4175 Time: 0.069632
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP4_TQ8_C4_R3_S3_U1_V1 Tactic: 0xb89ffea7e63be26b Time: 0.0582217
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec1_1_TP4_TQ7_C1_R3_S3_U1_V1 Tactic: 0x1ba3392c2d9e8dc2 Time: 0.036864
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xa31d27de74b895ff Time: 0.0690956
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec2_2_TP5_TQ7_C1_R3_S3_U1_V1 Tactic: 0x1306ffd94aca88c7 Time: 0.0760686
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xbb8c3889c7eacd30 Time: 0.0800183
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec1_1_TP6_TQ8_C2_R3_S3_U1_V1 Tactic: 0x61e15c17631a91cd Time: 0.029696
[04/25/2025-09:08:52] [V] [TRT] Conv_64 (CaskConvolution[0x80000009]) profiling completed in 0.158738 seconds. Fastest Tactic: 0xe38e9dfd56c33779 Time: 0.0202411
[04/25/2025-09:08:52] [V] [TRT] --------------- Timing Runner: Conv_64 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:52] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:52] [V] [TRT] --------------- Timing Runner: Conv_64 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:52] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:52] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xe38e9dfd56c33779
[04/25/2025-09:08:52] [V] [TRT] *************** Autotuning format combination: Float(2073600,1,11520,64) -> Float(64800,1,360,2) ***************
[04/25/2025-09:08:52] [V] [TRT] --------------- Timing Runner: Conv_64 (CaskConvolution[0x80000009])
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x3f0c846d6379bc98 Time: 0.163401
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x19b688348f983aa0 Time: 0.0598309
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4_alignc4 Tactic: 0xcf8ea142095f02d2 Time: 0.029813
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0xf48db81f02eca9ee Time: 0.0505173
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x92ed3100c35fc43e Time: 0.0253318
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x5953bec563d26434 Time: 0.0421303
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x8014228ec08b4d49 Time: 0.0464823
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x1da91d865428f237 Time: 0.052029
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x4fd3c46622e98342 Time: 0.0342601
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x32059de4888dfdda Time: 0.0304859
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4_alignc4 Tactic: 0xf231cca3335919a4 Time: 0.0306615
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x7121ec1db3f80c67 Time: 0.042496
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0xd15dd11d64344e83 Time: 0.0941349
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x0a143be7a52f301a Time: 0.0477867
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x62835fce994f06dd Time: 0.0555398
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xa6448a1e79f1ca6f Time: 0.0380354
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x94a7db94ba744c45 Time: 0.0583192
[04/25/2025-09:08:52] [V] [TRT] Conv_64 (CaskConvolution[0x80000009]) profiling completed in 0.0412091 seconds. Fastest Tactic: 0x92ed3100c35fc43e Time: 0.0253318
[04/25/2025-09:08:52] [V] [TRT] --------------- Timing Runner: Conv_64 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:52] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:52] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x92ed3100c35fc43e
[04/25/2025-09:08:52] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:52] [V] [TRT] --------------- Timing Runner: Conv_64 (CaskConvolution[0x80000009])
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 0x9787b83bedcff6a2 Time: 0.0631467
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_alignc4 Tactic: 0xe8f7b6a5bab325f8 Time: 0.067584
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_alignc4 Tactic: 0x9fd9fe001908ce2e Time: 0.0650484
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0xe0a307ffe0ffb6a5 Time: 0.064512
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3_alignc4 Tactic: 0x1323e48791e2f671 Time: 0.0637806
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0x3104d85fecdd547c Time: 0.0627566
[04/25/2025-09:08:52] [V] [TRT] Conv_64 (CaskConvolution[0x80000009]) profiling completed in 0.0197063 seconds. Fastest Tactic: 0x3104d85fecdd547c Time: 0.0627566
[04/25/2025-09:08:52] [V] [TRT] --------------- Timing Runner: Conv_64 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:52] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:52] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x3104d85fecdd547c
[04/25/2025-09:08:52] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:52] [V] [TRT] --------------- Timing Runner: Conv_64 (CaskConvolution[0x80000009])
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 0xbdfdef6b84f7ccc9 Time: 0.0543695
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0x3e2b881168d9689d Time: 0.0315977
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0xf90060ce8193b811 Time: 0.0883566
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x7bc32c782b800c48 Time: 0.0882103
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc8 Tactic: 0x96467934a22da27d Time: 0.0205629
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x64_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8 Tactic: 0x9355e195cee05798 Time: 0.0260389
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x64_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc8 Tactic: 0x3a8712b17741b582 Time: 0.0218593
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4 Tactic: 0xb3e5ce9d1b1da232 Time: 0.0323291
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x64_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc4 Tactic: 0xb6f6563c77d057d7 Time: 0.0219011
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x64_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8 Tactic: 0xe9e5475c77d60638 Time: 0.0288201
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4_alignc8 Tactic: 0x43ffe5cf09cee087 Time: 0.0303982
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8_alignc8 Tactic: 0x4640eb34c8ecc700 Time: 0.0311881
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8 Tactic: 0x3f948a101b8c4067 Time: 0.0303122
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc4 Tactic: 0xfed494d61b2087ba Time: 0.0236578
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc8 Tactic: 0x72a5d05b1bb165ef Time: 0.0236147
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 0x9cb304e2edbc1221 Time: 0.0238446
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8_alignc4 Tactic: 0xf78ec258f27b3e23 Time: 0.0334117
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x64_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4_alignc8 Tactic: 0x1acd4f006848c62b Time: 0.0346697
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0xb443c221fcb1565b Time: 0.0633905
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x64_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc4 Tactic: 0xcc46f0f5cee60677 Time: 0.0151259
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4_alignc8 Tactic: 0x7e40882e33c8fbf1 Time: 0.0309248
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x64_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc8 Tactic: 0x4037b478ce77e422 Time: 0.0189263
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc4 Tactic: 0x1a373db9a2bc4028 Time: 0.0208771
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x64_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 0x10383a0781d24dde Time: 0.0161402
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8_alignc8 Tactic: 0x7bff86d5f2eadc76 Time: 0.0334994
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x64_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 0xb33296dda7141c64 Time: 0.0236356
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4 Tactic: 0x570667f2a28165a0 Time: 0.0360594
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x64_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8_alignc4 Tactic: 0x93030576a9fb03f9 Time: 0.0269166
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 0x999e005e3b016ea6 Time: 0.0632442
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0x65e41d81f093b482 Time: 0.0661211
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x64_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4_alignc8 Tactic: 0x22cadc265a3b2e32 Time: 0.0308663
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x64_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8_alignc4 Tactic: 0xab0496509b88ebe0 Time: 0.0290816
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8 Tactic: 0xdb77237fa21087f5 Time: 0.0332654
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 0xae48d3ccfe1edfcd Time: 0.01792
[04/25/2025-09:08:52] [V] [TRT] Conv_64 (CaskConvolution[0x80000009]) profiling completed in 0.0720104 seconds. Fastest Tactic: 0xcc46f0f5cee60677 Time: 0.0151259
[04/25/2025-09:08:52] [V] [TRT] --------------- Timing Runner: Conv_64 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:52] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:52] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xcc46f0f5cee60677
[04/25/2025-09:08:52] [V] [TRT] *************** Autotuning format combination: Half(2073600,32400,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:52] [V] [TRT] --------------- Timing Runner: Conv_64 (CaskConvolution[0x80000009])
[04/25/2025-09:08:52] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:52] [V] [TRT] --------------- Timing Runner: Conv_64 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:52] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:52] [V] [TRT] --------------- Timing Runner: Conv_64 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:52] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:52] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:2,5760,32) -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:52] [V] [TRT] --------------- Timing Runner: Conv_64 (CaskConvolution[0x80000009])
[04/25/2025-09:08:52] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:52] [V] [TRT] --------------- Timing Runner: Conv_64 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:52] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:52] [V] [TRT] *************** Autotuning format combination: Half(518400,1:4,2880,16) -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:52] [V] [TRT] --------------- Timing Runner: Conv_64 (CaskConvolution[0x80000009])
[04/25/2025-09:08:52] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:52] [V] [TRT] --------------- Timing Runner: Conv_64 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:52] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:52] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:52] [V] [TRT] --------------- Timing Runner: Conv_64 (CaskConvolution[0x80000009])
[04/25/2025-09:08:52] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:52] [V] [TRT] --------------- Timing Runner: Conv_64 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:52] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:52] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:52] [V] [TRT] --------------- Timing Runner: Conv_64 (CaskConvolution[0x80000009])
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xdce100b9fe609424 Time: 0.0121044
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xa9177bbe4e767df8 Time: 0.034315
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x05b6220f243edacd Time: 0.0149079
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 0x60da8c7151d91e47 Time: 0.0187246
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xdfa020ef435ef810 Time: 0.0202971
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_wngd_f16f16_f16_f16_nhwckrsc_nhwc_tilesize8x16x32x32_warpsize8x1x1_wngd2x2 Tactic: 0xded5318b4a444b84 Time: 0.0137642
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x5568fd8a32f4a40f Time: 0.0152722
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xc0a02dc6095497cc Time: 0.0215876
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xb4bec086187edcfc Time: 0.0144384
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x57c9a5ff682354a6 Time: 0.0214413
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xdb0b80f591d1bb6d Time: 0.0229251
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x31d93dc22d2af081 Time: 0.0171642
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x5820b3dda403c4d0 Time: 0.0170992
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 0xb17d53d15dfbfc9e Time: 0.0190171
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x21b295c0c8f6c95a Time: 0.0146286
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xe1ff5ad20f5c6bf6 Time: 0.0164003
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xbd08239a9317f2fd Time: 0.0145993
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3_aACCESS Tactic: 0x0866ddee325d07a6 Time: 0.0117929
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xa570c55d303796ff Time: 0.012947
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x4a81ea1e51436a30 Time: 0.0167578
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x0e07ff4f4f7c1ac9 Time: 0.0212741
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xc9d24bd069159fa8 Time: 0.0145262
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3_aACCESS Tactic: 0x263a38afd75e3a43 Time: 0.0128971
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x60c3421152ef8e10 Time: 0.0205211
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: 0xa1a20ea714d420f4 Time: 0.0345234
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xf79479a62ea9f901 Time: 0.0125196
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xa83b68f30462f971 Time: 0.0121783
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0x834e11ecd4ab9454 Time: 0.0125798
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_wngd_f16f16_f16_f16_nhwckrsc_nhwc_tilesize16x16x64x16_warpsize8x1x1_wngd2x2 Tactic: 0xe29800439b9d3cf7 Time: 0.0192549
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: 0x7005d10718f6c22d Time: 0.0347575
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xd1aaad17ca35fbaa Time: 0.013046
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3_aACCESS Tactic: 0x245530c34bd6090f Time: 0.0206054
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x1x2_g1_tensor16x8x16_aACCESS Tactic: 0x841c601dec2a75bc Time: 0.0148763
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3_aACCESS Tactic: 0x30e8a8d7a953e5e9 Time: 0.0150382
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x048d6d0400f33439 Time: 0.0187611
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xafd1e8bf6bd3d638 Time: 0.0224862
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xf35e0311fa1cc516 Time: 0.0173105
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x529f4431bdae94f5 Time: 0.0128122
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xa40cb43c296a36a8 Time: 0.0122027
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x3e7eb35b91b9fa63 Time: 0.0124465
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage4_warpsize2x1x2_g1_tensor16x8x16 Tactic: 0x7273dde1d0cd3bd5 Time: 0.0163352
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x17ebf0c9f418f10a Time: 0.0225489
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xa033e20ae9f412b2 Time: 0.0165465
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x866e7a5f6401b67f Time: 0.021086
[04/25/2025-09:08:52] [V] [TRT] Conv_64 (CaskConvolution[0x80000009]) profiling completed in 0.100991 seconds. Fastest Tactic: 0x0866ddee325d07a6 Time: 0.0117929
[04/25/2025-09:08:52] [V] [TRT] --------------- Timing Runner: Conv_64 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:52] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:52] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x0866ddee325d07a6
[04/25/2025-09:08:52] [V] [TRT] =============== Computing costs for Conv_67
[04/25/2025-09:08:52] [V] [TRT] *************** Autotuning format combination: Float(74649600,32400,180,1) long-strided -> Float(32400,32400,180,1) ***************
[04/25/2025-09:08:52] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_67
[04/25/2025-09:08:52] [V] [TRT] --------------- Timing Runner: Conv_67 (CaskConvolution[0x80000009])
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: 0xf067e6205da31c2e Time: 0.0922331
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 0x5deb29b7a8e275f7 Time: 0.0543695
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 0x503619c69ae500ff Time: 0.0913554
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 0x3f243c490d502deb Time: 0.0551497
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize1x4x1_g1_ffma_aligna4_alignc4_beta0_packed_stride Tactic: 0xede36641840ce3d2 Time: 0.0617813
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xa9366041633a5135 Time: 0.0498316
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize4x1x1_g1_ffma_aligna4_alignc4_beta0_packed_stride Tactic: 0x1673e3594ce11cea Time: 0.0649021
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ5_C1_R3_S3_U1_V1 Tactic: 0x5ac6bfe0a27fc97b Time: 0.0507611
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xcb8a43f748d8a338 Time: 0.0530042
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP4_TQ7_C2_R3_S3_U1_V1 Tactic: 0x57c1b87347e45486 Time: 0.0431909
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x5aa723e0481da855 Time: 0.0918674
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4_beta0_packed_stride Tactic: 0x7fc93550f5b9c127 Time: 0.0520777
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec1_1_TP7_TQ8_C8_R3_S3_U1_V1 Tactic: 0x06cd3594e0105153 Time: 0.0300471
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x40a12e3938221818 Time: 0.0414354
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x01cf8ce2da913006 Time: 0.0903314
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xb0bf940d5e0f9f45 Time: 0.0394606
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xd828f024626fa982 Time: 0.0681691
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize2x2x1_g1_ffma_aligna4_alignc4_beta0_packed_stride Tactic: 0x31aa67f57c5aea77 Time: 0.0606126
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ8_C4_R3_S3_U1_V1 Tactic: 0x4bb6b59660d316a7 Time: 0.0428251
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x9d9fdb5fd9945f64 Time: 0.028672
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x4efce38acc876f5c Time: 0.0796526
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x4727434768e46395 Time: 0.0628053
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec1_1_TP6_TQ8_C8_R3_S3_U1_V1 Tactic: 0xee473898b5318f6e Time: 0.0319488
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP8_TQ7_C4_R3_S3_U1_V1 Tactic: 0x372f7588455e8e60 Time: 0.0374126
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP5_TQ7_C2_R3_S3_U1_V1 Tactic: 0xbf4bb57f12c58abb Time: 0.0500785
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP8_TQ5_C2_R3_S3_U1_V1 Tactic: 0x1fd1aff6cc3bef4c Time: 0.0554423
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ7_C2_R3_S3_U1_V1 Tactic: 0xfc87004c17882844 Time: 0.0503223
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 0x94119b4c514b211a Time: 0.0270385
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: 0xa8609adc4e0ceb90 Time: 0.0497417
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ6_C8_R3_S3_U1_V1 Tactic: 0x937cb0540b9a0c03 Time: 0.0385097
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: 0xf64396b97c889179 Time: 0.0570514
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ7_C8_R3_S3_U1_V1 Tactic: 0x732164c3c1a336e7 Time: 0.0463726
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize4x1x1_g1_ffma_t1r3s3_aligna4_alignc4_beta0_packed_stride Tactic: 0xe640ceafd7d34ca9 Time: 0.0537844
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ7_C4_R3_S3_U1_V1 Tactic: 0x861adc36a5912225 Time: 0.0463383
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x12dbf7d94ee3696d Time: 0.0510537
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x8ad32616b1424be4 Time: 0.0406674
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize2x2x1_g1_ffma_t1r3s3_aligna4_alignc4_beta0_packed_stride Tactic: 0x3712e3e595645874 Time: 0.0485669
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP8_TQ5_C4_R3_S3_U1_V1 Tactic: 0x654c738c7e22e52d Time: 0.0428251
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP5_TQ7_C4_R3_S3_U1_V1 Tactic: 0xc5d66905a0dc80da Time: 0.0369737
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP5_TQ8_C8_R3_S3_U1_V1 Tactic: 0xfd41b85001aca09a Time: 0.0447269
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ4_C1_R3_S3_U1_V1 Tactic: 0xba9b6b776846f39f Time: 0.043776
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP8_TQ5_C8_R3_S3_U1_V1 Tactic: 0x9077cb791a10f1ef Time: 0.0364617
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec1_1_TP4_TQ7_C1_R3_S3_U1_V1 Tactic: 0x1ba3392c2d9e8dc2 Time: 0.0367543
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xa31d27de74b895ff Time: 0.068608
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xbb8c3889c7eacd30 Time: 0.0797989
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec1_1_TP6_TQ8_C2_R3_S3_U1_V1 Tactic: 0x61e15c17631a91cd Time: 0.029696
[04/25/2025-09:08:52] [V] [TRT] Conv_67 (CaskConvolution[0x80000009]) profiling completed in 0.12467 seconds. Fastest Tactic: 0x94119b4c514b211a Time: 0.0270385
[04/25/2025-09:08:52] [V] [TRT] --------------- Timing Runner: Conv_67 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:52] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:52] [V] [TRT] --------------- Timing Runner: Conv_67 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:52] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:52] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x94119b4c514b211a
[04/25/2025-09:08:52] [V] [TRT] *************** Autotuning format combination: Float(74649600,1,414720,2304) long-strided -> Float(32400,1,180,1) ***************
[04/25/2025-09:08:52] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_67
[04/25/2025-09:08:52] [V] [TRT] --------------- Timing Runner: Conv_67 (CaskConvolution[0x80000009])
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x3f0c846d6379bc98 Time: 0.159598
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x19b688348f983aa0 Time: 0.0590507
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4_alignc4 Tactic: 0xcf8ea142095f02d2 Time: 0.0297838
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0xf48db81f02eca9ee Time: 0.0509074
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x92ed3100c35fc43e Time: 0.0251124
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x5953bec563d26434 Time: 0.0422766
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x8014228ec08b4d49 Time: 0.0469577
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x1da91d865428f237 Time: 0.0518827
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x4fd3c46622e98342 Time: 0.0353445
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x32059de4888dfdda Time: 0.0313637
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4_alignc4 Tactic: 0xf231cca3335919a4 Time: 0.0306322
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x7121ec1db3f80c67 Time: 0.0426423
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0xd15dd11d64344e83 Time: 0.0915749
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x0a143be7a52f301a Time: 0.047936
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x62835fce994f06dd Time: 0.059197
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xa6448a1e79f1ca6f Time: 0.0410697
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x94a7db94ba744c45 Time: 0.0570514
[04/25/2025-09:08:52] [V] [TRT] Conv_67 (CaskConvolution[0x80000009]) profiling completed in 0.0448806 seconds. Fastest Tactic: 0x92ed3100c35fc43e Time: 0.0251124
[04/25/2025-09:08:52] [V] [TRT] --------------- Timing Runner: Conv_67 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:52] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:52] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x92ed3100c35fc43e
[04/25/2025-09:08:52] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(32400,32400,180,1) ***************
[04/25/2025-09:08:52] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_67
[04/25/2025-09:08:52] [V] [TRT] --------------- Timing Runner: Conv_67 (CaskConvolution[0x80000009])
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 0x9787b83bedcff6a2 Time: 0.063293
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_alignc4 Tactic: 0xe8f7b6a5bab325f8 Time: 0.0678278
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_alignc4 Tactic: 0x9fd9fe001908ce2e Time: 0.0651947
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0xe0a307ffe0ffb6a5 Time: 0.0645623
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3_alignc4 Tactic: 0x1323e48791e2f671 Time: 0.0640244
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0x3104d85fecdd547c Time: 0.0627566
[04/25/2025-09:08:52] [V] [TRT] Conv_67 (CaskConvolution[0x80000009]) profiling completed in 0.0173926 seconds. Fastest Tactic: 0x3104d85fecdd547c Time: 0.0627566
[04/25/2025-09:08:52] [V] [TRT] --------------- Timing Runner: Conv_67 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:52] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:52] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x3104d85fecdd547c
[04/25/2025-09:08:52] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:52] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_67
[04/25/2025-09:08:52] [V] [TRT] --------------- Timing Runner: Conv_67 (CaskConvolution[0x80000009])
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 0xbdfdef6b84f7ccc9 Time: 0.0545158
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0x3e2b881168d9689d Time: 0.0321536
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0xf90060ce8193b811 Time: 0.0885029
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x7bc32c782b800c48 Time: 0.0882103
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc8 Tactic: 0x96467934a22da27d Time: 0.0204591
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x64_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8 Tactic: 0x9355e195cee05798 Time: 0.026528
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x64_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc8 Tactic: 0x3a8712b17741b582 Time: 0.0225907
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4 Tactic: 0xb3e5ce9d1b1da232 Time: 0.0326528
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x64_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc4 Tactic: 0xb6f6563c77d057d7 Time: 0.0221309
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x64_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8 Tactic: 0xe9e5475c77d60638 Time: 0.0290231
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4_alignc8 Tactic: 0x43ffe5cf09cee087 Time: 0.0307493
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8_alignc8 Tactic: 0x4640eb34c8ecc700 Time: 0.0314807
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8 Tactic: 0x3f948a101b8c4067 Time: 0.0307493
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc4 Tactic: 0xfed494d61b2087ba Time: 0.0234684
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc8 Tactic: 0x72a5d05b1bb165ef Time: 0.0235311
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 0x9cb304e2edbc1221 Time: 0.0236147
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8_alignc4 Tactic: 0xf78ec258f27b3e23 Time: 0.0338213
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x64_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4_alignc8 Tactic: 0x1acd4f006848c62b Time: 0.0352549
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0xb443c221fcb1565b Time: 0.0636343
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x64_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc4 Tactic: 0xcc46f0f5cee60677 Time: 0.0151991
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4_alignc8 Tactic: 0x7e40882e33c8fbf1 Time: 0.0312174
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x64_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc8 Tactic: 0x4037b478ce77e422 Time: 0.0188343
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc4 Tactic: 0x1a373db9a2bc4028 Time: 0.0204591
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x64_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 0x10383a0781d24dde Time: 0.0154478
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8_alignc8 Tactic: 0x7bff86d5f2eadc76 Time: 0.0337627
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x64_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 0xb33296dda7141c64 Time: 0.0236565
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4 Tactic: 0x570667f2a28165a0 Time: 0.0359863
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x64_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8_alignc4 Tactic: 0x93030576a9fb03f9 Time: 0.026819
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 0x999e005e3b016ea6 Time: 0.0623665
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0x65e41d81f093b482 Time: 0.065536
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x64_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4_alignc8 Tactic: 0x22cadc265a3b2e32 Time: 0.0304859
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x64_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8_alignc4 Tactic: 0xab0496509b88ebe0 Time: 0.0283307
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8 Tactic: 0xdb77237fa21087f5 Time: 0.0329435
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 0xae48d3ccfe1edfcd Time: 0.0174395
[04/25/2025-09:08:52] [V] [TRT] Conv_67 (CaskConvolution[0x80000009]) profiling completed in 0.0822694 seconds. Fastest Tactic: 0xcc46f0f5cee60677 Time: 0.0151991
[04/25/2025-09:08:52] [V] [TRT] --------------- Timing Runner: Conv_67 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:52] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:52] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xcc46f0f5cee60677
[04/25/2025-09:08:52] [V] [TRT] *************** Autotuning format combination: Half(74649600,32400,180,1) long-strided -> Half(32400,32400,180,1) ***************
[04/25/2025-09:08:52] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_67
[04/25/2025-09:08:52] [V] [TRT] --------------- Timing Runner: Conv_67 (CaskConvolution[0x80000009])
[04/25/2025-09:08:52] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:52] [V] [TRT] --------------- Timing Runner: Conv_67 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:52] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:52] [V] [TRT] --------------- Timing Runner: Conv_67 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:52] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:52] [V] [TRT] *************** Autotuning format combination: Half(37324800,1:2,207360,1152) long-strided -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:52] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_67
[04/25/2025-09:08:52] [V] [TRT] --------------- Timing Runner: Conv_67 (CaskConvolution[0x80000009])
[04/25/2025-09:08:52] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:52] [V] [TRT] --------------- Timing Runner: Conv_67 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:52] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:52] [V] [TRT] *************** Autotuning format combination: Half(18662400,1:4,103680,576) long-strided -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:52] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_67
[04/25/2025-09:08:52] [V] [TRT] --------------- Timing Runner: Conv_67 (CaskConvolution[0x80000009])
[04/25/2025-09:08:52] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:52] [V] [TRT] --------------- Timing Runner: Conv_67 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:52] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:52] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Float(32400,32400,180,1) ***************
[04/25/2025-09:08:52] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_67
[04/25/2025-09:08:52] [V] [TRT] --------------- Timing Runner: Conv_67 (CaskConvolution[0x80000009])
[04/25/2025-09:08:52] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:52] [V] [TRT] --------------- Timing Runner: Conv_67 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:52] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:52] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:52] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_67
[04/25/2025-09:08:52] [V] [TRT] --------------- Timing Runner: Conv_67 (CaskConvolution[0x80000009])
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xdce100b9fe609424 Time: 0.0124952
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xa9177bbe4e767df8 Time: 0.034699
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x05b6220f243edacd Time: 0.0149669
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 0x60da8c7151d91e47 Time: 0.0188709
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xdfa020ef435ef810 Time: 0.020224
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x5568fd8a32f4a40f Time: 0.0152722
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xc0a02dc6095497cc Time: 0.0211696
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xb4bec086187edcfc Time: 0.0144091
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x57c9a5ff682354a6 Time: 0.0212532
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xdb0b80f591d1bb6d Time: 0.0237401
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x31d93dc22d2af081 Time: 0.0170017
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x5820b3dda403c4d0 Time: 0.0171154
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 0xb17d53d15dfbfc9e Time: 0.0192
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x21b295c0c8f6c95a Time: 0.0149211
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xe1ff5ad20f5c6bf6 Time: 0.0166928
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xbd08239a9317f2fd Time: 0.0147602
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3_aACCESS Tactic: 0x0866ddee325d07a6 Time: 0.0125928
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xa570c55d303796ff Time: 0.0130061
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x4a81ea1e51436a30 Time: 0.0166613
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x0e07ff4f4f7c1ac9 Time: 0.0213995
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xc9d24bd069159fa8 Time: 0.0146286
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3_aACCESS Tactic: 0x263a38afd75e3a43 Time: 0.0131258
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x60c3421152ef8e10 Time: 0.0206054
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: 0xa1a20ea714d420f4 Time: 0.0345527
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xf79479a62ea9f901 Time: 0.0124587
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xa83b68f30462f971 Time: 0.0120686
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0x834e11ecd4ab9454 Time: 0.012605
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: 0x7005d10718f6c22d Time: 0.0347867
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xd1aaad17ca35fbaa Time: 0.0128979
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3_aACCESS Tactic: 0x245530c34bd6090f Time: 0.0206256
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x1x2_g1_tensor16x8x16_aACCESS Tactic: 0x841c601dec2a75bc Time: 0.014848
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3_aACCESS Tactic: 0x30e8a8d7a953e5e9 Time: 0.0149797
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x048d6d0400f33439 Time: 0.0186149
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xafd1e8bf6bd3d638 Time: 0.023134
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xf35e0311fa1cc516 Time: 0.0170484
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x529f4431bdae94f5 Time: 0.0127021
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xa40cb43c296a36a8 Time: 0.0119954
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x3e7eb35b91b9fa63 Time: 0.0123611
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage4_warpsize2x1x2_g1_tensor16x8x16 Tactic: 0x7273dde1d0cd3bd5 Time: 0.0158574
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x17ebf0c9f418f10a Time: 0.023134
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xa033e20ae9f412b2 Time: 0.0163845
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x866e7a5f6401b67f Time: 0.0206034
[04/25/2025-09:08:52] [V] [TRT] Conv_67 (CaskConvolution[0x80000009]) profiling completed in 0.100207 seconds. Fastest Tactic: 0xa40cb43c296a36a8 Time: 0.0119954
[04/25/2025-09:08:52] [V] [TRT] --------------- Timing Runner: Conv_67 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:52] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:52] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xa40cb43c296a36a8
[04/25/2025-09:08:52] [V] [TRT] *************** Autotuning format combination: Float(2073600,32400,180,1) -> Float(32400,32400,180,1) ***************
[04/25/2025-09:08:52] [V] [TRT] --------------- Timing Runner: Conv_67 (CaskConvolution[0x80000009])
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: 0xf067e6205da31c2e Time: 0.0922331
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 0x5deb29b7a8e275f7 Time: 0.0542781
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 0x503619c69ae500ff Time: 0.0915017
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 0x3f243c490d502deb Time: 0.0550034
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize1x4x1_g1_ffma_aligna4_alignc4_beta0_packed_stride Tactic: 0xede36641840ce3d2 Time: 0.0616838
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xa9366041633a5135 Time: 0.0496884
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize4x1x1_g1_ffma_aligna4_alignc4_beta0_packed_stride Tactic: 0x1673e3594ce11cea Time: 0.0649509
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_wngd_f32f32_f32_f32_nchwkcrs_nchw_tilesize8x16x32x8_warpsize8x1x1_wngd2x2 Tactic: 0xe47e164f4a743900 Time: 0.0289061
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ5_C1_R3_S3_U1_V1 Tactic: 0x5ac6bfe0a27fc97b Time: 0.0506636
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xcb8a43f748d8a338 Time: 0.0530042
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP4_TQ7_C2_R3_S3_U1_V1 Tactic: 0x57c1b87347e45486 Time: 0.042496
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x5aa723e0481da855 Time: 0.0920137
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4_beta0_packed_stride Tactic: 0x7fc93550f5b9c127 Time: 0.0521265
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec1_1_TP7_TQ8_C8_R3_S3_U1_V1 Tactic: 0x06cd3594e0105153 Time: 0.0300178
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x40a12e3938221818 Time: 0.0413989
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x01cf8ce2da913006 Time: 0.0904777
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xb0bf940d5e0f9f45 Time: 0.0396069
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xd828f024626fa982 Time: 0.0680229
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize2x2x1_g1_ffma_aligna4_alignc4_beta0_packed_stride Tactic: 0x31aa67f57c5aea77 Time: 0.0606111
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ8_C4_R3_S3_U1_V1 Tactic: 0x4bb6b59660d316a7 Time: 0.04264
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x9d9fdb5fd9945f64 Time: 0.0286135
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x4efce38acc876f5c Time: 0.0796457
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x4727434768e46395 Time: 0.0622202
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec1_1_TP6_TQ8_C8_R3_S3_U1_V1 Tactic: 0xee473898b5318f6e Time: 0.0318318
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_wngd_f32f32_f32_f32_nchwkcrs_nchw_tilesize8x16x16x8_warpsize8x1x1_wngd2x2 Tactic: 0xe38e9dfd56c33779 Time: 0.0203703
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP8_TQ7_C4_R3_S3_U1_V1 Tactic: 0x372f7588455e8e60 Time: 0.0372663
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP5_TQ7_C2_R3_S3_U1_V1 Tactic: 0xbf4bb57f12c58abb Time: 0.0497859
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP8_TQ5_C2_R3_S3_U1_V1 Tactic: 0x1fd1aff6cc3bef4c Time: 0.0549547
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ7_C2_R3_S3_U1_V1 Tactic: 0xfc87004c17882844 Time: 0.050371
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 0x94119b4c514b211a Time: 0.0270385
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: 0xa8609adc4e0ceb90 Time: 0.0497859
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ6_C8_R3_S3_U1_V1 Tactic: 0x937cb0540b9a0c03 Time: 0.0384731
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: 0xf64396b97c889179 Time: 0.0570514
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ7_C8_R3_S3_U1_V1 Tactic: 0x732164c3c1a336e7 Time: 0.0464823
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize4x1x1_g1_ffma_t1r3s3_aligna4_alignc4_beta0_packed_stride Tactic: 0xe640ceafd7d34ca9 Time: 0.0536869
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ7_C4_R3_S3_U1_V1 Tactic: 0x861adc36a5912225 Time: 0.0462629
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x12dbf7d94ee3696d Time: 0.0509562
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x8ad32616b1424be4 Time: 0.0395337
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize2x2x1_g1_ffma_t1r3s3_aligna4_alignc4_beta0_packed_stride Tactic: 0x3712e3e595645874 Time: 0.0484175
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_wngd_f32f32_f32_f32_nchwkcrs_nchw_tilesize8x16x64x8_warpsize8x1x1_wngd2x2 Tactic: 0x0190806602534cfd Time: 0.0403749
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP8_TQ5_C4_R3_S3_U1_V1 Tactic: 0x654c738c7e22e52d Time: 0.0427886
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP5_TQ7_C4_R3_S3_U1_V1 Tactic: 0xc5d66905a0dc80da Time: 0.0370103
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP5_TQ8_C8_R3_S3_U1_V1 Tactic: 0xfd41b85001aca09a Time: 0.0445806
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ4_C1_R3_S3_U1_V1 Tactic: 0xba9b6b776846f39f Time: 0.0437429
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP8_TQ5_C8_R3_S3_U1_V1 Tactic: 0x9077cb791a10f1ef Time: 0.0363154
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec1_1_TP4_TQ7_C1_R3_S3_U1_V1 Tactic: 0x1ba3392c2d9e8dc2 Time: 0.0367177
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xa31d27de74b895ff Time: 0.0690956
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xbb8c3889c7eacd30 Time: 0.0796526
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec1_1_TP6_TQ8_C2_R3_S3_U1_V1 Tactic: 0x61e15c17631a91cd Time: 0.0296073
[04/25/2025-09:08:52] [V] [TRT] Conv_67 (CaskConvolution[0x80000009]) profiling completed in 0.115865 seconds. Fastest Tactic: 0xe38e9dfd56c33779 Time: 0.0203703
[04/25/2025-09:08:52] [V] [TRT] --------------- Timing Runner: Conv_67 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:52] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:52] [V] [TRT] --------------- Timing Runner: Conv_67 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:52] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:52] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xe38e9dfd56c33779
[04/25/2025-09:08:52] [V] [TRT] *************** Autotuning format combination: Float(2073600,1,11520,64) -> Float(32400,1,180,1) ***************
[04/25/2025-09:08:52] [V] [TRT] --------------- Timing Runner: Conv_67 (CaskConvolution[0x80000009])
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x3f0c846d6379bc98 Time: 0.158427
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x19b688348f983aa0 Time: 0.0592457
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4_alignc4 Tactic: 0xcf8ea142095f02d2 Time: 0.0305417
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0xf48db81f02eca9ee Time: 0.0523703
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x92ed3100c35fc43e Time: 0.0250149
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x5953bec563d26434 Time: 0.0433737
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x8014228ec08b4d49 Time: 0.0473966
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x1da91d865428f237 Time: 0.0527604
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x4fd3c46622e98342 Time: 0.0344357
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x32059de4888dfdda Time: 0.0306615
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4_alignc4 Tactic: 0xf231cca3335919a4 Time: 0.0313344
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x7121ec1db3f80c67 Time: 0.042752
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0xd15dd11d64344e83 Time: 0.0904046
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x0a143be7a52f301a Time: 0.0480305
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x62835fce994f06dd Time: 0.0564175
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xa6448a1e79f1ca6f Time: 0.0385463
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x94a7db94ba744c45 Time: 0.055491
[04/25/2025-09:08:52] [V] [TRT] Conv_67 (CaskConvolution[0x80000009]) profiling completed in 0.0404356 seconds. Fastest Tactic: 0x92ed3100c35fc43e Time: 0.0250149
[04/25/2025-09:08:52] [V] [TRT] --------------- Timing Runner: Conv_67 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:52] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:52] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x92ed3100c35fc43e
[04/25/2025-09:08:52] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(32400,32400,180,1) ***************
[04/25/2025-09:08:52] [V] [TRT] --------------- Timing Runner: Conv_67 (CaskConvolution[0x80000009])
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 0x9787b83bedcff6a2 Time: 0.0630491
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_alignc4 Tactic: 0xe8f7b6a5bab325f8 Time: 0.067584
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_alignc4 Tactic: 0x9fd9fe001908ce2e Time: 0.0651459
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0xe0a307ffe0ffb6a5 Time: 0.0644145
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3_alignc4 Tactic: 0x1323e48791e2f671 Time: 0.0638248
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0x3104d85fecdd547c Time: 0.0627566
[04/25/2025-09:08:52] [V] [TRT] Conv_67 (CaskConvolution[0x80000009]) profiling completed in 0.0157929 seconds. Fastest Tactic: 0x3104d85fecdd547c Time: 0.0627566
[04/25/2025-09:08:52] [V] [TRT] --------------- Timing Runner: Conv_67 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:52] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:52] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x3104d85fecdd547c
[04/25/2025-09:08:52] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:52] [V] [TRT] --------------- Timing Runner: Conv_67 (CaskConvolution[0x80000009])
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 0xbdfdef6b84f7ccc9 Time: 0.0544183
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0x3e2b881168d9689d Time: 0.0315685
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0xf90060ce8193b811 Time: 0.0884297
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x7bc32c782b800c48 Time: 0.088064
[04/25/2025-09:08:52] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc8 Tactic: 0x96467934a22da27d Time: 0.0206263
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x64_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8 Tactic: 0x9355e195cee05798 Time: 0.0260389
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x64_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc8 Tactic: 0x3a8712b17741b582 Time: 0.0218815
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4 Tactic: 0xb3e5ce9d1b1da232 Time: 0.0322679
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x64_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc4 Tactic: 0xb6f6563c77d057d7 Time: 0.0218802
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x64_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8 Tactic: 0xe9e5475c77d60638 Time: 0.0288475
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4_alignc8 Tactic: 0x43ffe5cf09cee087 Time: 0.0304567
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8_alignc8 Tactic: 0x4640eb34c8ecc700 Time: 0.0311296
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8 Tactic: 0x3f948a101b8c4067 Time: 0.0303689
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc4 Tactic: 0xfed494d61b2087ba Time: 0.0236356
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc8 Tactic: 0x72a5d05b1bb165ef Time: 0.0236369
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 0x9cb304e2edbc1221 Time: 0.0237819
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8_alignc4 Tactic: 0xf78ec258f27b3e23 Time: 0.0333797
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x64_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4_alignc8 Tactic: 0x1acd4f006848c62b Time: 0.0347867
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0xb443c221fcb1565b Time: 0.0633417
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x64_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc4 Tactic: 0xcc46f0f5cee60677 Time: 0.0150967
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4_alignc8 Tactic: 0x7e40882e33c8fbf1 Time: 0.0309833
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x64_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc8 Tactic: 0x4037b478ce77e422 Time: 0.0191086
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc4 Tactic: 0x1a373db9a2bc4028 Time: 0.0206054
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x64_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 0x10383a0781d24dde Time: 0.0150821
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8_alignc8 Tactic: 0x7bff86d5f2eadc76 Time: 0.0333257
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x64_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 0xb33296dda7141c64 Time: 0.0231758
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4 Tactic: 0x570667f2a28165a0 Time: 0.0357669
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x64_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8_alignc4 Tactic: 0x93030576a9fb03f9 Time: 0.026307
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 0x999e005e3b016ea6 Time: 0.0624152
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0x65e41d81f093b482 Time: 0.0653897
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x64_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4_alignc8 Tactic: 0x22cadc265a3b2e32 Time: 0.0302519
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x64_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8_alignc4 Tactic: 0xab0496509b88ebe0 Time: 0.0282819
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8 Tactic: 0xdb77237fa21087f5 Time: 0.0328841
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 0xae48d3ccfe1edfcd Time: 0.0175705
[04/25/2025-09:08:53] [V] [TRT] Conv_67 (CaskConvolution[0x80000009]) profiling completed in 0.0704424 seconds. Fastest Tactic: 0x10383a0781d24dde Time: 0.0150821
[04/25/2025-09:08:53] [V] [TRT] --------------- Timing Runner: Conv_67 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:53] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:53] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x10383a0781d24dde
[04/25/2025-09:08:53] [V] [TRT] *************** Autotuning format combination: Half(2073600,32400,180,1) -> Half(32400,32400,180,1) ***************
[04/25/2025-09:08:53] [V] [TRT] --------------- Timing Runner: Conv_67 (CaskConvolution[0x80000009])
[04/25/2025-09:08:53] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:53] [V] [TRT] --------------- Timing Runner: Conv_67 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:53] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:53] [V] [TRT] --------------- Timing Runner: Conv_67 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:53] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:53] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:2,5760,32) -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:53] [V] [TRT] --------------- Timing Runner: Conv_67 (CaskConvolution[0x80000009])
[04/25/2025-09:08:53] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:53] [V] [TRT] --------------- Timing Runner: Conv_67 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:53] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:53] [V] [TRT] *************** Autotuning format combination: Half(518400,1:4,2880,16) -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:53] [V] [TRT] --------------- Timing Runner: Conv_67 (CaskConvolution[0x80000009])
[04/25/2025-09:08:53] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:53] [V] [TRT] --------------- Timing Runner: Conv_67 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:53] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:53] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Float(32400,32400,180,1) ***************
[04/25/2025-09:08:53] [V] [TRT] --------------- Timing Runner: Conv_67 (CaskConvolution[0x80000009])
[04/25/2025-09:08:53] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:53] [V] [TRT] --------------- Timing Runner: Conv_67 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:53] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:53] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:53] [V] [TRT] --------------- Timing Runner: Conv_67 (CaskConvolution[0x80000009])
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xdce100b9fe609424 Time: 0.0120564
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xa9177bbe4e767df8 Time: 0.0342912
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x05b6220f243edacd Time: 0.0148773
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 0x60da8c7151d91e47 Time: 0.0186526
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xdfa020ef435ef810 Time: 0.0202606
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_wngd_f16f16_f16_f16_nhwckrsc_nhwc_tilesize8x16x32x32_warpsize8x1x1_wngd2x2 Tactic: 0xded5318b4a444b84 Time: 0.0138705
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x5568fd8a32f4a40f Time: 0.0152869
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xc0a02dc6095497cc Time: 0.0211905
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xb4bec086187edcfc Time: 0.0143918
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x57c9a5ff682354a6 Time: 0.0214413
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xdb0b80f591d1bb6d Time: 0.0228206
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x31d93dc22d2af081 Time: 0.0173755
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x5820b3dda403c4d0 Time: 0.0170667
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 0xb17d53d15dfbfc9e Time: 0.019072
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x21b295c0c8f6c95a Time: 0.0146875
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xe1ff5ad20f5c6bf6 Time: 0.016416
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xbd08239a9317f2fd Time: 0.0146578
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3_aACCESS Tactic: 0x0866ddee325d07a6 Time: 0.011971
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xa570c55d303796ff Time: 0.0128731
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x4a81ea1e51436a30 Time: 0.0168229
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x0e07ff4f4f7c1ac9 Time: 0.0212741
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xc9d24bd069159fa8 Time: 0.0145408
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3_aACCESS Tactic: 0x263a38afd75e3a43 Time: 0.0129821
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x60c3421152ef8e10 Time: 0.0207099
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: 0xa1a20ea714d420f4 Time: 0.0345234
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xf79479a62ea9f901 Time: 0.0125074
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xa83b68f30462f971 Time: 0.0121417
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0x834e11ecd4ab9454 Time: 0.0125928
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_wngd_f16f16_f16_f16_nhwckrsc_nhwc_tilesize16x16x64x16_warpsize8x1x1_wngd2x2 Tactic: 0xe29800439b9d3cf7 Time: 0.0200594
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: 0x7005d10718f6c22d Time: 0.0348453
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xd1aaad17ca35fbaa Time: 0.0130859
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3_aACCESS Tactic: 0x245530c34bd6090f Time: 0.0206472
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x1x2_g1_tensor16x8x16_aACCESS Tactic: 0x841c601dec2a75bc Time: 0.0148334
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3_aACCESS Tactic: 0x30e8a8d7a953e5e9 Time: 0.0149801
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x048d6d0400f33439 Time: 0.0186886
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xafd1e8bf6bd3d638 Time: 0.022528
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xf35e0311fa1cc516 Time: 0.0173272
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x529f4431bdae94f5 Time: 0.012861
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xa40cb43c296a36a8 Time: 0.0121051
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x3e7eb35b91b9fa63 Time: 0.012397
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage4_warpsize2x1x2_g1_tensor16x8x16 Tactic: 0x7273dde1d0cd3bd5 Time: 0.0160574
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x17ebf0c9f418f10a Time: 0.0224862
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xa033e20ae9f412b2 Time: 0.016449
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x866e7a5f6401b67f Time: 0.0208144
[04/25/2025-09:08:53] [V] [TRT] Conv_67 (CaskConvolution[0x80000009]) profiling completed in 0.101929 seconds. Fastest Tactic: 0x0866ddee325d07a6 Time: 0.011971
[04/25/2025-09:08:53] [V] [TRT] --------------- Timing Runner: Conv_67 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:53] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:53] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x0866ddee325d07a6
[04/25/2025-09:08:53] [V] [TRT] =============== Computing costs for Conv_70
[04/25/2025-09:08:53] [V] [TRT] *************** Autotuning format combination: Float(74649600,32400,180,1) long-strided -> Float(97200,32400,180,1) ***************
[04/25/2025-09:08:53] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_70
[04/25/2025-09:08:53] [V] [TRT] --------------- Timing Runner: Conv_70 (CaskConvolution[0x80000009])
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: 0xf067e6205da31c2e Time: 0.0922331
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 0x5deb29b7a8e275f7 Time: 0.0544168
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 0x503619c69ae500ff Time: 0.0913554
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 0x3f243c490d502deb Time: 0.0550507
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize1x4x1_g1_ffma_aligna4_alignc4_beta0_packed_stride Tactic: 0xede36641840ce3d2 Time: 0.0618301
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xa9366041633a5135 Time: 0.0497859
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize4x1x1_g1_ffma_aligna4_alignc4_beta0_packed_stride Tactic: 0x1673e3594ce11cea Time: 0.0649509
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ5_C1_R3_S3_U1_V1 Tactic: 0x5ac6bfe0a27fc97b Time: 0.0517364
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xcb8a43f748d8a338 Time: 0.053152
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP4_TQ7_C2_R3_S3_U1_V1 Tactic: 0x57c1b87347e45486 Time: 0.0426069
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x5aa723e0481da855 Time: 0.0920869
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4_beta0_packed_stride Tactic: 0x7fc93550f5b9c127 Time: 0.0521295
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec1_1_TP7_TQ8_C8_R3_S3_U1_V1 Tactic: 0x06cd3594e0105153 Time: 0.0302226
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x40a12e3938221818 Time: 0.0415817
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x01cf8ce2da913006 Time: 0.0904777
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xb0bf940d5e0f9f45 Time: 0.0398263
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xd828f024626fa982 Time: 0.0682682
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize2x2x1_g1_ffma_aligna4_alignc4_beta0_packed_stride Tactic: 0x31aa67f57c5aea77 Time: 0.0607086
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ8_C4_R3_S3_U1_V1 Tactic: 0x4bb6b59660d316a7 Time: 0.0425326
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x9d9fdb5fd9945f64 Time: 0.0286135
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x4efce38acc876f5c Time: 0.0795794
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x4727434768e46395 Time: 0.0623665
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec1_1_TP6_TQ8_C8_R3_S3_U1_V1 Tactic: 0xee473898b5318f6e Time: 0.0319195
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP8_TQ7_C4_R3_S3_U1_V1 Tactic: 0x372f7588455e8e60 Time: 0.0374491
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP5_TQ7_C2_R3_S3_U1_V1 Tactic: 0xbf4bb57f12c58abb Time: 0.0498377
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP8_TQ5_C2_R3_S3_U1_V1 Tactic: 0x1fd1aff6cc3bef4c Time: 0.064707
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ7_C2_R3_S3_U1_V1 Tactic: 0xfc87004c17882844 Time: 0.051005
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 0x94119b4c514b211a Time: 0.027085
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: 0xa8609adc4e0ceb90 Time: 0.0499322
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ6_C8_R3_S3_U1_V1 Tactic: 0x937cb0540b9a0c03 Time: 0.0390251
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: 0xf64396b97c889179 Time: 0.0570042
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ7_C8_R3_S3_U1_V1 Tactic: 0x732164c3c1a336e7 Time: 0.046592
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize4x1x1_g1_ffma_t1r3s3_aligna4_alignc4_beta0_packed_stride Tactic: 0xe640ceafd7d34ca9 Time: 0.0558811
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ7_C4_R3_S3_U1_V1 Tactic: 0x861adc36a5912225 Time: 0.0465189
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x12dbf7d94ee3696d Time: 0.051005
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x8ad32616b1424be4 Time: 0.0418377
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize2x2x1_g1_ffma_t1r3s3_aligna4_alignc4_beta0_packed_stride Tactic: 0x3712e3e595645874 Time: 0.0484709
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP8_TQ5_C4_R3_S3_U1_V1 Tactic: 0x654c738c7e22e52d Time: 0.0446869
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP5_TQ7_C4_R3_S3_U1_V1 Tactic: 0xc5d66905a0dc80da Time: 0.0371189
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP5_TQ8_C8_R3_S3_U1_V1 Tactic: 0xfd41b85001aca09a Time: 0.0448366
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ4_C1_R3_S3_U1_V1 Tactic: 0xba9b6b776846f39f Time: 0.0547109
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP8_TQ5_C8_R3_S3_U1_V1 Tactic: 0x9077cb791a10f1ef Time: 0.036864
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec1_1_TP4_TQ7_C1_R3_S3_U1_V1 Tactic: 0x1ba3392c2d9e8dc2 Time: 0.0370834
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xa31d27de74b895ff Time: 0.0679741
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xbb8c3889c7eacd30 Time: 0.079648
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec1_1_TP6_TQ8_C2_R3_S3_U1_V1 Tactic: 0x61e15c17631a91cd Time: 0.0294354
[04/25/2025-09:08:53] [V] [TRT] Conv_70 (CaskConvolution[0x80000009]) profiling completed in 0.122993 seconds. Fastest Tactic: 0x94119b4c514b211a Time: 0.027085
[04/25/2025-09:08:53] [V] [TRT] --------------- Timing Runner: Conv_70 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:53] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:53] [V] [TRT] --------------- Timing Runner: Conv_70 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:53] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:53] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x94119b4c514b211a
[04/25/2025-09:08:53] [V] [TRT] *************** Autotuning format combination: Float(74649600,1,414720,2304) long-strided -> Float(97200,1,540,3) ***************
[04/25/2025-09:08:53] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_70
[04/25/2025-09:08:53] [V] [TRT] --------------- Timing Runner: Conv_70 (CaskConvolution[0x80000009])
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x3f0c846d6379bc98 Time: 0.159451
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x19b688348f983aa0 Time: 0.0589044
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4_alignc4 Tactic: 0xcf8ea142095f02d2 Time: 0.0305765
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0xf48db81f02eca9ee Time: 0.0522728
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x92ed3100c35fc43e Time: 0.0249417
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x5953bec563d26434 Time: 0.0424594
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x8014228ec08b4d49 Time: 0.0464091
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x1da91d865428f237 Time: 0.0540282
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x4fd3c46622e98342 Time: 0.03584
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x32059de4888dfdda Time: 0.0328265
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4_alignc4 Tactic: 0xf231cca3335919a4 Time: 0.0311259
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x7121ec1db3f80c67 Time: 0.0426789
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0xd15dd11d64344e83 Time: 0.0956709
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x0a143be7a52f301a Time: 0.0479299
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x62835fce994f06dd Time: 0.0580754
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xa6448a1e79f1ca6f Time: 0.0406686
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x94a7db94ba744c45 Time: 0.0613912
[04/25/2025-09:08:53] [V] [TRT] Conv_70 (CaskConvolution[0x80000009]) profiling completed in 0.0434215 seconds. Fastest Tactic: 0x92ed3100c35fc43e Time: 0.0249417
[04/25/2025-09:08:53] [V] [TRT] --------------- Timing Runner: Conv_70 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:53] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:53] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x92ed3100c35fc43e
[04/25/2025-09:08:53] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(97200,32400,180,1) ***************
[04/25/2025-09:08:53] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_70
[04/25/2025-09:08:53] [V] [TRT] --------------- Timing Runner: Conv_70 (CaskConvolution[0x80000009])
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 0x9787b83bedcff6a2 Time: 0.0632442
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_alignc4 Tactic: 0xe8f7b6a5bab325f8 Time: 0.067584
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_alignc4 Tactic: 0x9fd9fe001908ce2e Time: 0.0649996
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0xe0a307ffe0ffb6a5 Time: 0.064512
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3_alignc4 Tactic: 0x1323e48791e2f671 Time: 0.0637806
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0x3104d85fecdd547c Time: 0.0628541
[04/25/2025-09:08:53] [V] [TRT] Conv_70 (CaskConvolution[0x80000009]) profiling completed in 0.0166074 seconds. Fastest Tactic: 0x3104d85fecdd547c Time: 0.0628541
[04/25/2025-09:08:53] [V] [TRT] --------------- Timing Runner: Conv_70 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:53] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:53] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x3104d85fecdd547c
[04/25/2025-09:08:53] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:53] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_70
[04/25/2025-09:08:53] [V] [TRT] --------------- Timing Runner: Conv_70 (CaskConvolution[0x80000009])
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 0xbdfdef6b84f7ccc9 Time: 0.0543208
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0x3e2b881168d9689d Time: 0.0320631
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0xf90060ce8193b811 Time: 0.0885029
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x7bc32c782b800c48 Time: 0.0882103
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc8 Tactic: 0x96467934a22da27d Time: 0.0202577
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x64_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8 Tactic: 0x9355e195cee05798 Time: 0.0264046
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x64_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc8 Tactic: 0x3a8712b17741b582 Time: 0.0219847
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4 Tactic: 0xb3e5ce9d1b1da232 Time: 0.0324782
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x64_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc4 Tactic: 0xb6f6563c77d057d7 Time: 0.0219429
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x64_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8 Tactic: 0xe9e5475c77d60638 Time: 0.0289938
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4_alignc8 Tactic: 0x43ffe5cf09cee087 Time: 0.0307493
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8_alignc8 Tactic: 0x4640eb34c8ecc700 Time: 0.0314807
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8 Tactic: 0x3f948a101b8c4067 Time: 0.0306615
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc4 Tactic: 0xfed494d61b2087ba Time: 0.0233221
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc8 Tactic: 0x72a5d05b1bb165ef Time: 0.0232594
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 0x9cb304e2edbc1221 Time: 0.0234266
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8_alignc4 Tactic: 0xf78ec258f27b3e23 Time: 0.0335305
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x64_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4_alignc8 Tactic: 0x1acd4f006848c62b Time: 0.0349623
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0xb443c221fcb1565b Time: 0.0633417
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x64_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc4 Tactic: 0xcc46f0f5cee60677 Time: 0.0151552
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4_alignc8 Tactic: 0x7e40882e33c8fbf1 Time: 0.0311296
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x64_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc8 Tactic: 0x4037b478ce77e422 Time: 0.0187817
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc4 Tactic: 0x1a373db9a2bc4028 Time: 0.020352
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x64_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 0x10383a0781d24dde Time: 0.0151113
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8_alignc8 Tactic: 0x7bff86d5f2eadc76 Time: 0.0335031
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x64_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 0xb33296dda7141c64 Time: 0.0232594
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4 Tactic: 0x570667f2a28165a0 Time: 0.0357669
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x64_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8_alignc4 Tactic: 0x93030576a9fb03f9 Time: 0.0267977
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 0x999e005e3b016ea6 Time: 0.0623665
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0x65e41d81f093b482 Time: 0.0654872
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x64_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4_alignc8 Tactic: 0x22cadc265a3b2e32 Time: 0.0305125
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x64_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8_alignc4 Tactic: 0xab0496509b88ebe0 Time: 0.0283794
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8 Tactic: 0xdb77237fa21087f5 Time: 0.0330898
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 0xae48d3ccfe1edfcd Time: 0.0173917
[04/25/2025-09:08:53] [V] [TRT] Conv_70 (CaskConvolution[0x80000009]) profiling completed in 0.0800963 seconds. Fastest Tactic: 0x10383a0781d24dde Time: 0.0151113
[04/25/2025-09:08:53] [V] [TRT] --------------- Timing Runner: Conv_70 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:53] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:53] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x10383a0781d24dde
[04/25/2025-09:08:53] [V] [TRT] *************** Autotuning format combination: Half(74649600,32400,180,1) long-strided -> Half(97200,32400,180,1) ***************
[04/25/2025-09:08:53] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_70
[04/25/2025-09:08:53] [V] [TRT] --------------- Timing Runner: Conv_70 (CaskConvolution[0x80000009])
[04/25/2025-09:08:53] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:53] [V] [TRT] --------------- Timing Runner: Conv_70 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:53] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:53] [V] [TRT] --------------- Timing Runner: Conv_70 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:53] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:53] [V] [TRT] *************** Autotuning format combination: Half(37324800,1:2,207360,1152) long-strided -> Half(64800,1:2,360,2) ***************
[04/25/2025-09:08:53] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_70
[04/25/2025-09:08:53] [V] [TRT] --------------- Timing Runner: Conv_70 (CaskConvolution[0x80000009])
[04/25/2025-09:08:53] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:53] [V] [TRT] --------------- Timing Runner: Conv_70 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:53] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:53] [V] [TRT] *************** Autotuning format combination: Half(18662400,1:4,103680,576) long-strided -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:53] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_70
[04/25/2025-09:08:53] [V] [TRT] --------------- Timing Runner: Conv_70 (CaskConvolution[0x80000009])
[04/25/2025-09:08:53] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:53] [V] [TRT] --------------- Timing Runner: Conv_70 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:53] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:53] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Float(97200,32400,180,1) ***************
[04/25/2025-09:08:53] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_70
[04/25/2025-09:08:53] [V] [TRT] --------------- Timing Runner: Conv_70 (CaskConvolution[0x80000009])
[04/25/2025-09:08:53] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:53] [V] [TRT] --------------- Timing Runner: Conv_70 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:53] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:53] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:53] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_70
[04/25/2025-09:08:53] [V] [TRT] --------------- Timing Runner: Conv_70 (CaskConvolution[0x80000009])
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xdce100b9fe609424 Time: 0.012019
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xa9177bbe4e767df8 Time: 0.0342016
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x05b6220f243edacd Time: 0.0149198
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 0x60da8c7151d91e47 Time: 0.0185966
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xdfa020ef435ef810 Time: 0.02004
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x5568fd8a32f4a40f Time: 0.0152421
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xc0a02dc6095497cc Time: 0.0211487
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xb4bec086187edcfc Time: 0.0144686
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x57c9a5ff682354a6 Time: 0.0212323
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xdb0b80f591d1bb6d Time: 0.0232993
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x31d93dc22d2af081 Time: 0.0170179
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x5820b3dda403c4d0 Time: 0.0172292
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 0xb17d53d15dfbfc9e Time: 0.018944
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x21b295c0c8f6c95a Time: 0.0147305
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xe1ff5ad20f5c6bf6 Time: 0.0164333
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xbd08239a9317f2fd Time: 0.0146871
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3_aACCESS Tactic: 0x0866ddee325d07a6 Time: 0.0123368
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xa570c55d303796ff Time: 0.0131125
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x4a81ea1e51436a30 Time: 0.0165633
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x0e07ff4f4f7c1ac9 Time: 0.0211696
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xc9d24bd069159fa8 Time: 0.0146734
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3_aACCESS Tactic: 0x263a38afd75e3a43 Time: 0.0131013
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x60c3421152ef8e10 Time: 0.0205427
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: 0xa1a20ea714d420f4 Time: 0.0344357
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xf79479a62ea9f901 Time: 0.0125425
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xa83b68f30462f971 Time: 0.0121535
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0x834e11ecd4ab9454 Time: 0.0128
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: 0x7005d10718f6c22d Time: 0.0347575
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xd1aaad17ca35fbaa Time: 0.0129219
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3_aACCESS Tactic: 0x245530c34bd6090f Time: 0.0206472
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x1x2_g1_tensor16x8x16_aACCESS Tactic: 0x841c601dec2a75bc Time: 0.0148507
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3_aACCESS Tactic: 0x30e8a8d7a953e5e9 Time: 0.0149806
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x048d6d0400f33439 Time: 0.0185966
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xafd1e8bf6bd3d638 Time: 0.0229473
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xf35e0311fa1cc516 Time: 0.0176036
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x529f4431bdae94f5 Time: 0.0129097
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xa40cb43c296a36a8 Time: 0.0123855
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x3e7eb35b91b9fa63 Time: 0.0128
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage4_warpsize2x1x2_g1_tensor16x8x16 Tactic: 0x7273dde1d0cd3bd5 Time: 0.0167416
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x17ebf0c9f418f10a Time: 0.0240152
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xa033e20ae9f412b2 Time: 0.017278
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x866e7a5f6401b67f Time: 0.0214622
[04/25/2025-09:08:53] [V] [TRT] Conv_70 (CaskConvolution[0x80000009]) profiling completed in 0.0946748 seconds. Fastest Tactic: 0xdce100b9fe609424 Time: 0.012019
[04/25/2025-09:08:53] [V] [TRT] --------------- Timing Runner: Conv_70 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:53] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:53] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xdce100b9fe609424
[04/25/2025-09:08:53] [V] [TRT] *************** Autotuning format combination: Float(2073600,32400,180,1) -> Float(97200,32400,180,1) ***************
[04/25/2025-09:08:53] [V] [TRT] --------------- Timing Runner: Conv_70 (CaskConvolution[0x80000009])
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: ampere_scudnn_128x128_relu_medium_nn_v1 Tactic: 0xf067e6205da31c2e Time: 0.0931109
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: ampere_scudnn_128x64_relu_xregs_large_nn_v1 Tactic: 0x5deb29b7a8e275f7 Time: 0.0543695
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: ampere_scudnn_128x128_relu_small_nn_v1 Tactic: 0x503619c69ae500ff Time: 0.0915017
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: ampere_scudnn_128x64_relu_small_nn_v1 Tactic: 0x3f243c490d502deb Time: 0.055296
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize1x4x1_g1_ffma_aligna4_alignc4_beta0_packed_stride Tactic: 0xede36641840ce3d2 Time: 0.0617844
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xa9366041633a5135 Time: 0.049981
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize4x1x1_g1_ffma_aligna4_alignc4_beta0_packed_stride Tactic: 0x1673e3594ce11cea Time: 0.0649996
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_wngd_f32f32_f32_f32_nchwkcrs_nchw_tilesize8x16x32x8_warpsize8x1x1_wngd2x2 Tactic: 0xe47e164f4a743900 Time: 0.0287305
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ5_C1_R3_S3_U1_V1 Tactic: 0x5ac6bfe0a27fc97b Time: 0.0516876
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xcb8a43f748d8a338 Time: 0.0531017
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP4_TQ7_C2_R3_S3_U1_V1 Tactic: 0x57c1b87347e45486 Time: 0.0425337
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x5aa723e0481da855 Time: 0.0918674
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4_beta0_packed_stride Tactic: 0x7fc93550f5b9c127 Time: 0.0521752
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec1_1_TP7_TQ8_C8_R3_S3_U1_V1 Tactic: 0x06cd3594e0105153 Time: 0.0301641
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x40a12e3938221818 Time: 0.041472
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x01cf8ce2da913006 Time: 0.0904046
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xb0bf940d5e0f9f45 Time: 0.0397897
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xd828f024626fa982 Time: 0.0682179
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize2x2x1_g1_ffma_aligna4_alignc4_beta0_packed_stride Tactic: 0x31aa67f57c5aea77 Time: 0.0606598
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ8_C4_R3_S3_U1_V1 Tactic: 0x4bb6b59660d316a7 Time: 0.0426389
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x9d9fdb5fd9945f64 Time: 0.0287305
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x4efce38acc876f5c Time: 0.0795794
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x4727434768e46395 Time: 0.0635368
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec1_1_TP6_TQ8_C8_R3_S3_U1_V1 Tactic: 0xee473898b5318f6e Time: 0.0318903
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_wngd_f32f32_f32_f32_nchwkcrs_nchw_tilesize8x16x16x8_warpsize8x1x1_wngd2x2 Tactic: 0xe38e9dfd56c33779 Time: 0.0203709
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP8_TQ7_C4_R3_S3_U1_V1 Tactic: 0x372f7588455e8e60 Time: 0.0374126
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP5_TQ7_C2_R3_S3_U1_V1 Tactic: 0xbf4bb57f12c58abb Time: 0.0498789
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP8_TQ5_C2_R3_S3_U1_V1 Tactic: 0x1fd1aff6cc3bef4c Time: 0.0646583
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ7_C2_R3_S3_U1_V1 Tactic: 0xfc87004c17882844 Time: 0.0506636
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: ampere_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 0x94119b4c514b211a Time: 0.0270141
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: ampere_scudnn_128x32_relu_small_nn_v1 Tactic: 0xa8609adc4e0ceb90 Time: 0.0497387
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ6_C8_R3_S3_U1_V1 Tactic: 0x937cb0540b9a0c03 Time: 0.038912
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: ampere_scudnn_128x64_relu_medium_nn_v1 Tactic: 0xf64396b97c889179 Time: 0.0570027
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ7_C8_R3_S3_U1_V1 Tactic: 0x732164c3c1a336e7 Time: 0.046592
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize4x1x1_g1_ffma_t1r3s3_aligna4_alignc4_beta0_packed_stride Tactic: 0xe640ceafd7d34ca9 Time: 0.0538331
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ7_C4_R3_S3_U1_V1 Tactic: 0x861adc36a5912225 Time: 0.0463726
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x12dbf7d94ee3696d Time: 0.051005
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x8ad32616b1424be4 Time: 0.0400811
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize128x64x8_stage2_warpsize2x2x1_g1_ffma_t1r3s3_aligna4_alignc4_beta0_packed_stride Tactic: 0x3712e3e595645874 Time: 0.0484693
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_wngd_f32f32_f32_f32_nchwkcrs_nchw_tilesize8x16x64x8_warpsize8x1x1_wngd2x2 Tactic: 0x0190806602534cfd Time: 0.040448
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP8_TQ5_C4_R3_S3_U1_V1 Tactic: 0x654c738c7e22e52d Time: 0.0446171
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP5_TQ7_C4_R3_S3_U1_V1 Tactic: 0xc5d66905a0dc80da Time: 0.0370446
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP5_TQ8_C8_R3_S3_U1_V1 Tactic: 0xfd41b85001aca09a Time: 0.0448
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP7_TQ4_C1_R3_S3_U1_V1 Tactic: 0xba9b6b776846f39f Time: 0.0547109
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec1_fltVec1_1_TP8_TQ5_C8_R3_S3_U1_V1 Tactic: 0x9077cb791a10f1ef Time: 0.0369371
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec1_1_TP4_TQ7_C1_R3_S3_U1_V1 Tactic: 0x1ba3392c2d9e8dc2 Time: 0.0370069
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0xa31d27de74b895ff Time: 0.068608
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nchwkcrs_nchw_tilesize256x128x8_stage3_warpsize4x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xbb8c3889c7eacd30 Time: 0.0797989
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm50_xmma_conv_fprop_fused_conv_act_fp32_NCHW_fp32_NCHW_KCRS_fp32_fp32_fp32_Accfloat_1_1_cC1_dC1_srcVec2_fltVec1_1_TP6_TQ8_C2_R3_S3_U1_V1 Tactic: 0x61e15c17631a91cd Time: 0.0295205
[04/25/2025-09:08:53] [V] [TRT] Conv_70 (CaskConvolution[0x80000009]) profiling completed in 0.119662 seconds. Fastest Tactic: 0xe38e9dfd56c33779 Time: 0.0203709
[04/25/2025-09:08:53] [V] [TRT] --------------- Timing Runner: Conv_70 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:53] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:53] [V] [TRT] --------------- Timing Runner: Conv_70 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:53] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:53] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xe38e9dfd56c33779
[04/25/2025-09:08:53] [V] [TRT] *************** Autotuning format combination: Float(2073600,1,11520,64) -> Float(97200,1,540,3) ***************
[04/25/2025-09:08:53] [V] [TRT] --------------- Timing Runner: Conv_70 (CaskConvolution[0x80000009])
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x256x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x3f0c846d6379bc98 Time: 0.158574
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x19b688348f983aa0 Time: 0.0599771
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4_alignc4 Tactic: 0xcf8ea142095f02d2 Time: 0.0300763
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0xf48db81f02eca9ee Time: 0.0511497
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x92ed3100c35fc43e Time: 0.0247947
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x5953bec563d26434 Time: 0.0424229
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize256x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x8014228ec08b4d49 Time: 0.0464091
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x64x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x1da91d865428f237 Time: 0.0517851
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_aligna4_alignc4 Tactic: 0x4fd3c46622e98342 Time: 0.0343479
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x16x8_stage3_warpsize4x1x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x32059de4888dfdda Time: 0.0313344
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4_alignc4 Tactic: 0xf231cca3335919a4 Time: 0.0307767
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x7121ec1db3f80c67 Time: 0.0427154
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x128x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0xd15dd11d64344e83 Time: 0.0927451
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize32x32x8_stage3_warpsize1x2x1_g1_ffma_aligna4_alignc4 Tactic: 0x0a143be7a52f301a Time: 0.0480731
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_aligna4_alignc4 Tactic: 0x62835fce994f06dd Time: 0.0563657
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize128x32x8_stage3_warpsize2x2x1_g1_ffma_aligna4_alignc4 Tactic: 0xa6448a1e79f1ca6f Time: 0.0392411
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_f32f32_f32_nhwckrsc_nhwc_tilesize64x64x8_stage3_warpsize1x4x1_g1_ffma_t1r3s3_aligna4_alignc4 Tactic: 0x94a7db94ba744c45 Time: 0.0599284
[04/25/2025-09:08:53] [V] [TRT] Conv_70 (CaskConvolution[0x80000009]) profiling completed in 0.0390948 seconds. Fastest Tactic: 0x92ed3100c35fc43e Time: 0.0247947
[04/25/2025-09:08:53] [V] [TRT] --------------- Timing Runner: Conv_70 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:53] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:53] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x92ed3100c35fc43e
[04/25/2025-09:08:53] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(97200,32400,180,1) ***************
[04/25/2025-09:08:53] [V] [TRT] --------------- Timing Runner: Conv_70 (CaskConvolution[0x80000009])
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 0x9787b83bedcff6a2 Time: 0.0632442
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_alignc4 Tactic: 0xe8f7b6a5bab325f8 Time: 0.0674865
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_alignc4 Tactic: 0x9fd9fe001908ce2e Time: 0.0651413
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0xe0a307ffe0ffb6a5 Time: 0.0645608
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3_alignc4 Tactic: 0x1323e48791e2f671 Time: 0.0637806
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nchw_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0x3104d85fecdd547c Time: 0.0628053
[04/25/2025-09:08:53] [V] [TRT] Conv_70 (CaskConvolution[0x80000009]) profiling completed in 0.0149782 seconds. Fastest Tactic: 0x3104d85fecdd547c Time: 0.0628053
[04/25/2025-09:08:53] [V] [TRT] --------------- Timing Runner: Conv_70 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:53] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:53] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x3104d85fecdd547c
[04/25/2025-09:08:53] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:53] [V] [TRT] --------------- Timing Runner: Conv_70 (CaskConvolution[0x80000009])
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: ampere_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1 Tactic: 0xbdfdef6b84f7ccc9 Time: 0.0543695
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: ampere_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0x3e2b881168d9689d Time: 0.0314807
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: 0xf90060ce8193b811 Time: 0.0883611
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: ampere_scudnn_128x128_ldg4_relu_exp_medium_nhwc_tn_v1 Tactic: 0x7bc32c782b800c48 Time: 0.0882103
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc8 Tactic: 0x96467934a22da27d Time: 0.0209162
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x64_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8 Tactic: 0x9355e195cee05798 Time: 0.0260389
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x64_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc8 Tactic: 0x3a8712b17741b582 Time: 0.0218397
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4 Tactic: 0xb3e5ce9d1b1da232 Time: 0.0322706
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x64_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc4 Tactic: 0xb6f6563c77d057d7 Time: 0.0219011
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x64_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8 Tactic: 0xe9e5475c77d60638 Time: 0.0288768
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4_alignc8 Tactic: 0x43ffe5cf09cee087 Time: 0.0304283
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8_alignc8 Tactic: 0x4640eb34c8ecc700 Time: 0.0311881
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8 Tactic: 0x3f948a101b8c4067 Time: 0.0303397
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc4 Tactic: 0xfed494d61b2087ba Time: 0.0235729
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc8 Tactic: 0x72a5d05b1bb165ef Time: 0.0235938
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 0x9cb304e2edbc1221 Time: 0.0238202
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8_alignc4 Tactic: 0xf78ec258f27b3e23 Time: 0.0333833
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x64_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4_alignc8 Tactic: 0x1acd4f006848c62b Time: 0.034699
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0xb443c221fcb1565b Time: 0.0633417
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x64_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc4 Tactic: 0xcc46f0f5cee60677 Time: 0.0150528
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4_alignc8 Tactic: 0x7e40882e33c8fbf1 Time: 0.0308635
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x64_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc8 Tactic: 0x4037b478ce77e422 Time: 0.0188874
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8_alignc4 Tactic: 0x1a373db9a2bc4028 Time: 0.0205427
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x64_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 0x10383a0781d24dde Time: 0.0151259
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8_alignc8 Tactic: 0x7bff86d5f2eadc76 Time: 0.0333513
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x64_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 0xb33296dda7141c64 Time: 0.0231549
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4 Tactic: 0x570667f2a28165a0 Time: 0.0357669
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x64_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8_alignc4 Tactic: 0x93030576a9fb03f9 Time: 0.0262095
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_t1r3s3 Tactic: 0x999e005e3b016ea6 Time: 0.0623665
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8 Tactic: 0x65e41d81f093b482 Time: 0.065341
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x64_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna4_alignc8 Tactic: 0x22cadc265a3b2e32 Time: 0.0302226
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x64_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8_alignc4 Tactic: 0xab0496509b88ebe0 Time: 0.0282598
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x8_aligna8 Tactic: 0xdb77237fa21087f5 Time: 0.0328558
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x8 Tactic: 0xae48d3ccfe1edfcd Time: 0.0174568
[04/25/2025-09:08:53] [V] [TRT] Conv_70 (CaskConvolution[0x80000009]) profiling completed in 0.0692027 seconds. Fastest Tactic: 0xcc46f0f5cee60677 Time: 0.0150528
[04/25/2025-09:08:53] [V] [TRT] --------------- Timing Runner: Conv_70 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:53] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:53] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0xcc46f0f5cee60677
[04/25/2025-09:08:53] [V] [TRT] *************** Autotuning format combination: Half(2073600,32400,180,1) -> Half(97200,32400,180,1) ***************
[04/25/2025-09:08:53] [V] [TRT] --------------- Timing Runner: Conv_70 (CaskConvolution[0x80000009])
[04/25/2025-09:08:53] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:53] [V] [TRT] --------------- Timing Runner: Conv_70 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:53] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:53] [V] [TRT] --------------- Timing Runner: Conv_70 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:53] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:53] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:2,5760,32) -> Half(64800,1:2,360,2) ***************
[04/25/2025-09:08:53] [V] [TRT] --------------- Timing Runner: Conv_70 (CaskConvolution[0x80000009])
[04/25/2025-09:08:53] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:53] [V] [TRT] --------------- Timing Runner: Conv_70 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:53] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:53] [V] [TRT] *************** Autotuning format combination: Half(518400,1:4,2880,16) -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:53] [V] [TRT] --------------- Timing Runner: Conv_70 (CaskConvolution[0x80000009])
[04/25/2025-09:08:53] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:53] [V] [TRT] --------------- Timing Runner: Conv_70 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:53] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:53] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Float(97200,32400,180,1) ***************
[04/25/2025-09:08:53] [V] [TRT] --------------- Timing Runner: Conv_70 (CaskConvolution[0x80000009])
[04/25/2025-09:08:53] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:53] [V] [TRT] --------------- Timing Runner: Conv_70 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:53] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:53] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:53] [V] [TRT] --------------- Timing Runner: Conv_70 (CaskConvolution[0x80000009])
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xdce100b9fe609424 Time: 0.012021
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xa9177bbe4e767df8 Time: 0.0342309
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x05b6220f243edacd Time: 0.0149211
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 0x60da8c7151d91e47 Time: 0.0186149
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xdfa020ef435ef810 Time: 0.0202423
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_wngd_f16f16_f16_f16_nhwckrsc_nhwc_tilesize8x16x32x32_warpsize8x1x1_wngd2x2 Tactic: 0xded5318b4a444b84 Time: 0.0137642
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x5568fd8a32f4a40f Time: 0.0152274
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xc0a02dc6095497cc Time: 0.021169
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xb4bec086187edcfc Time: 0.0143067
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x57c9a5ff682354a6 Time: 0.0213577
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xdb0b80f591d1bb6d Time: 0.0228624
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x31d93dc22d2af081 Time: 0.0171002
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x5820b3dda403c4d0 Time: 0.0170504
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16 Tactic: 0xb17d53d15dfbfc9e Time: 0.0190029
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x21b295c0c8f6c95a Time: 0.0146144
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xe1ff5ad20f5c6bf6 Time: 0.0165953
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xbd08239a9317f2fd Time: 0.0145536
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3_aACCESS Tactic: 0x0866ddee325d07a6 Time: 0.0117479
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xa570c55d303796ff Time: 0.0128126
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x4a81ea1e51436a30 Time: 0.0167578
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x0e07ff4f4f7c1ac9 Time: 0.021231
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xc9d24bd069159fa8 Time: 0.014453
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3_aACCESS Tactic: 0x263a38afd75e3a43 Time: 0.0128865
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x60c3421152ef8e10 Time: 0.020606
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: 0xa1a20ea714d420f4 Time: 0.0344357
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xf79479a62ea9f901 Time: 0.0124465
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xa83b68f30462f971 Time: 0.012117
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0x834e11ecd4ab9454 Time: 0.0125196
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_wngd_f16f16_f16_f16_nhwckrsc_nhwc_tilesize16x16x64x16_warpsize8x1x1_wngd2x2 Tactic: 0xe29800439b9d3cf7 Time: 0.0191817
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x256x32_stage3_warpsize2x4x1_g1_tensor16x8x16 Tactic: 0x7005d10718f6c22d Time: 0.0347867
[04/25/2025-09:08:53] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16 Tactic: 0xd1aaad17ca35fbaa Time: 0.0129836
[04/25/2025-09:08:54] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3_aACCESS Tactic: 0x245530c34bd6090f Time: 0.0206054
[04/25/2025-09:08:54] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x1x2_g1_tensor16x8x16_aACCESS Tactic: 0x841c601dec2a75bc Time: 0.0147895
[04/25/2025-09:08:54] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3_aACCESS Tactic: 0x30e8a8d7a953e5e9 Time: 0.0149943
[04/25/2025-09:08:54] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x048d6d0400f33439 Time: 0.0191451
[04/25/2025-09:08:54] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xafd1e8bf6bd3d638 Time: 0.0226325
[04/25/2025-09:08:54] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0xf35e0311fa1cc516 Time: 0.0172434
[04/25/2025-09:08:54] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x529f4431bdae94f5 Time: 0.0127512
[04/25/2025-09:08:54] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xa40cb43c296a36a8 Time: 0.0121291
[04/25/2025-09:08:54] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x3e7eb35b91b9fa63 Time: 0.0124099
[04/25/2025-09:08:54] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage4_warpsize2x1x2_g1_tensor16x8x16 Tactic: 0x7273dde1d0cd3bd5 Time: 0.0160589
[04/25/2025-09:08:54] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0x17ebf0c9f418f10a Time: 0.0226723
[04/25/2025-09:08:54] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3 Tactic: 0xa033e20ae9f412b2 Time: 0.0167416
[04/25/2025-09:08:54] [V] [TRT] Tactic Name: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x64_stage3_warpsize2x2x1_g1_tensor16x8x16 Tactic: 0x866e7a5f6401b67f Time: 0.0211069
[04/25/2025-09:08:54] [V] [TRT] Conv_70 (CaskConvolution[0x80000009]) profiling completed in 0.0923396 seconds. Fastest Tactic: 0x0866ddee325d07a6 Time: 0.0117479
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_70 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 0x0866ddee325d07a6
[04/25/2025-09:08:54] [V] [TRT] =============== Computing costs for Conv_73
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,32400,180,1) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,1,414720,2304) long-strided -> Float(64800,1,360,2) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(74649600,32400,180,1) long-strided -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_73
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_73 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_73 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_73 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(37324800,1:2,207360,1152) long-strided -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_73
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_73 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_73 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(18662400,1:4,103680,576) long-strided -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_73
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_73 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_73 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_73
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_73 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_73 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,32400,180,1) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,1,11520,64) -> Float(64800,1,360,2) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(2073600,32400,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_73 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_73 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_73 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:2,5760,32) -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_73 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_73 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(518400,1:4,2880,16) -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_73 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_73 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_73 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_73 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] =============== Computing costs for Conv_76
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,32400,180,1) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,1,414720,2304) long-strided -> Float(64800,1,360,2) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(74649600,32400,180,1) long-strided -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_76
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_76 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_76 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_76 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(37324800,1:2,207360,1152) long-strided -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_76
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_76 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_76 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(18662400,1:4,103680,576) long-strided -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_76
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_76 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_76 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_76
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_76 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_76 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,32400,180,1) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,1,11520,64) -> Float(64800,1,360,2) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(2073600,32400,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_76 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_76 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_76 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:2,5760,32) -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_76 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_76 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(518400,1:4,2880,16) -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_76 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_76 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_76 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_76 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] =============== Computing costs for Conv_79
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,32400,180,1) long-strided -> Float(32400,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,1,414720,2304) long-strided -> Float(32400,1,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(32400,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(74649600,32400,180,1) long-strided -> Half(32400,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_79
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_79 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_79 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_79 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(37324800,1:2,207360,1152) long-strided -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_79
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_79 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_79 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(18662400,1:4,103680,576) long-strided -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_79
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_79 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_79 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Float(32400,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_79
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_79 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_79 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,32400,180,1) -> Float(32400,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,1,11520,64) -> Float(32400,1,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(32400,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(2073600,32400,180,1) -> Half(32400,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_79 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_79 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_79 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:2,5760,32) -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_79 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_79 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(518400,1:4,2880,16) -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_79 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_79 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Float(32400,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_79 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_79 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] =============== Computing costs for Conv_82
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,32400,180,1) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,1,414720,2304) long-strided -> Float(64800,1,360,2) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(74649600,32400,180,1) long-strided -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_82
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_82 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_82 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_82 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(37324800,1:2,207360,1152) long-strided -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_82
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_82 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_82 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(18662400,1:4,103680,576) long-strided -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_82
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_82 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_82 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_82
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_82 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_82 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,32400,180,1) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,1,11520,64) -> Float(64800,1,360,2) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(2073600,32400,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_82 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_82 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_82 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:2,5760,32) -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_82 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_82 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(518400,1:4,2880,16) -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_82 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_82 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_82 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_82 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] =============== Computing costs for Conv_85
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,32400,180,1) long-strided -> Float(32400,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,1,414720,2304) long-strided -> Float(32400,1,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(32400,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(74649600,32400,180,1) long-strided -> Half(32400,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_85
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_85 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_85 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_85 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(37324800,1:2,207360,1152) long-strided -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_85
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_85 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_85 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(18662400,1:4,103680,576) long-strided -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_85
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_85 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_85 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Float(32400,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_85
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_85 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_85 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,32400,180,1) -> Float(32400,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,1,11520,64) -> Float(32400,1,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(32400,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(2073600,32400,180,1) -> Half(32400,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_85 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_85 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_85 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:2,5760,32) -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_85 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_85 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(518400,1:4,2880,16) -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_85 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_85 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Float(32400,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_85 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_85 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] =============== Computing costs for Conv_88
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,32400,180,1) long-strided -> Float(97200,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,1,414720,2304) long-strided -> Float(97200,1,540,3) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(97200,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(74649600,32400,180,1) long-strided -> Half(97200,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_88
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_88 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_88 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_88 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(37324800,1:2,207360,1152) long-strided -> Half(64800,1:2,360,2) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_88
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_88 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_88 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(18662400,1:4,103680,576) long-strided -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_88
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_88 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_88 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Float(97200,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_88
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_88 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_88 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,32400,180,1) -> Float(97200,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,1,11520,64) -> Float(97200,1,540,3) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(97200,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(2073600,32400,180,1) -> Half(97200,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_88 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_88 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_88 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:2,5760,32) -> Half(64800,1:2,360,2) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_88 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_88 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(518400,1:4,2880,16) -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_88 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_88 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Float(97200,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_88 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_88 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] =============== Computing costs for Conv_91
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,32400,180,1) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,1,414720,2304) long-strided -> Float(64800,1,360,2) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(74649600,32400,180,1) long-strided -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_91
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_91 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_91 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_91 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(37324800,1:2,207360,1152) long-strided -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_91
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_91 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_91 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(18662400,1:4,103680,576) long-strided -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_91
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_91 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_91 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_91
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_91 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_91 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,32400,180,1) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,1,11520,64) -> Float(64800,1,360,2) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(2073600,32400,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_91 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_91 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_91 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:2,5760,32) -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_91 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_91 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(518400,1:4,2880,16) -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_91 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_91 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_91 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_91 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] =============== Computing costs for Conv_94
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,32400,180,1) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,1,414720,2304) long-strided -> Float(64800,1,360,2) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(74649600,32400,180,1) long-strided -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_94
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_94 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_94 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_94 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(37324800,1:2,207360,1152) long-strided -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_94
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_94 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_94 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(18662400,1:4,103680,576) long-strided -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_94
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_94 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_94 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_94
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_94 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_94 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,32400,180,1) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,1,11520,64) -> Float(64800,1,360,2) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(2073600,32400,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_94 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_94 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_94 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:2,5760,32) -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_94 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_94 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(518400,1:4,2880,16) -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_94 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_94 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_94 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_94 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] =============== Computing costs for Conv_97
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,32400,180,1) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,1,414720,2304) long-strided -> Float(64800,1,360,2) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(74649600,32400,180,1) long-strided -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_97
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_97 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_97 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_97 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(37324800,1:2,207360,1152) long-strided -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_97
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_97 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_97 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(18662400,1:4,103680,576) long-strided -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_97
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_97 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_97 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_97
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_97 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_97 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,32400,180,1) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,1,11520,64) -> Float(64800,1,360,2) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(2073600,32400,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_97 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_97 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_97 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:2,5760,32) -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_97 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_97 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(518400,1:4,2880,16) -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_97 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_97 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_97 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_97 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] =============== Computing costs for Conv_100
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,32400,180,1) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,1,414720,2304) long-strided -> Float(64800,1,360,2) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(74649600,32400,180,1) long-strided -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_100
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_100 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_100 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_100 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(37324800,1:2,207360,1152) long-strided -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_100
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_100 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_100 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(18662400,1:4,103680,576) long-strided -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_100
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_100 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_100 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_100
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_100 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_100 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,32400,180,1) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,1,11520,64) -> Float(64800,1,360,2) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(2073600,32400,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_100 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_100 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_100 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:2,5760,32) -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_100 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_100 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(518400,1:4,2880,16) -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_100 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_100 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_100 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_100 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] =============== Computing costs for Conv_103
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,32400,180,1) long-strided -> Float(32400,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,1,414720,2304) long-strided -> Float(32400,1,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(32400,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(74649600,32400,180,1) long-strided -> Half(32400,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_103
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_103 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_103 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_103 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(37324800,1:2,207360,1152) long-strided -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_103
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_103 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_103 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(18662400,1:4,103680,576) long-strided -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_103
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_103 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_103 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Float(32400,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_103
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_103 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_103 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,32400,180,1) -> Float(32400,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,1,11520,64) -> Float(32400,1,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(32400,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(2073600,32400,180,1) -> Half(32400,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_103 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_103 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_103 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:2,5760,32) -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_103 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_103 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(518400,1:4,2880,16) -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_103 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_103 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Float(32400,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_103 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_103 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] =============== Computing costs for Conv_106
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,32400,180,1) long-strided -> Float(97200,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,1,414720,2304) long-strided -> Float(97200,1,540,3) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(97200,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(74649600,32400,180,1) long-strided -> Half(97200,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_106
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_106 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_106 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_106 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(37324800,1:2,207360,1152) long-strided -> Half(64800,1:2,360,2) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_106
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_106 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_106 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(18662400,1:4,103680,576) long-strided -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_106
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_106 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_106 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Float(97200,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_106
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_106 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_106 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,32400,180,1) -> Float(97200,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,1,11520,64) -> Float(97200,1,540,3) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(97200,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(2073600,32400,180,1) -> Half(97200,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_106 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_106 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_106 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:2,5760,32) -> Half(64800,1:2,360,2) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_106 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_106 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(518400,1:4,2880,16) -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_106 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_106 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Float(97200,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_106 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_106 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] =============== Computing costs for Conv_109
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,32400,180,1) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,1,414720,2304) long-strided -> Float(64800,1,360,2) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(74649600,32400,180,1) long-strided -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_109
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_109 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_109 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_109 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(37324800,1:2,207360,1152) long-strided -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_109
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_109 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_109 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(18662400,1:4,103680,576) long-strided -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_109
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_109 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_109 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_109
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_109 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_109 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,32400,180,1) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,1,11520,64) -> Float(64800,1,360,2) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(2073600,32400,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_109 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_109 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_109 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:2,5760,32) -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_109 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_109 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(518400,1:4,2880,16) -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_109 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_109 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_109 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_109 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] =============== Computing costs for Conv_112
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,32400,180,1) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,1,414720,2304) long-strided -> Float(64800,1,360,2) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(74649600,32400,180,1) long-strided -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_112
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_112 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_112 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_112 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(37324800,1:2,207360,1152) long-strided -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_112
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_112 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_112 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(18662400,1:4,103680,576) long-strided -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_112
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_112 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_112 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_112
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_112 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_112 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,32400,180,1) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,1,11520,64) -> Float(64800,1,360,2) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(2073600,32400,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_112 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_112 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_112 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:2,5760,32) -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_112 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_112 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(518400,1:4,2880,16) -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_112 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_112 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_112 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_112 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] =============== Computing costs for Conv_115
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,32400,180,1) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,1,414720,2304) long-strided -> Float(64800,1,360,2) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(74649600,32400,180,1) long-strided -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_115
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_115 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_115 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_115 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(37324800,1:2,207360,1152) long-strided -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_115
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_115 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_115 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(18662400,1:4,103680,576) long-strided -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_115
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_115 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_115 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_115
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_115 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_115 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,32400,180,1) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,1,11520,64) -> Float(64800,1,360,2) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(2073600,32400,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_115 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_115 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_115 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:2,5760,32) -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_115 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_115 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(518400,1:4,2880,16) -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_115 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_115 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_115 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_115 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] =============== Computing costs for Conv_118
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,32400,180,1) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,1,414720,2304) long-strided -> Float(64800,1,360,2) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(74649600,32400,180,1) long-strided -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_118
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_118 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_118 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_118 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(37324800,1:2,207360,1152) long-strided -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_118
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_118 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_118 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(18662400,1:4,103680,576) long-strided -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_118
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_118 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_118 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_118
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_118 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_118 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,32400,180,1) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,1,11520,64) -> Float(64800,1,360,2) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(2073600,32400,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_118 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_118 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_118 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:2,5760,32) -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_118 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_118 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(518400,1:4,2880,16) -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_118 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_118 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_118 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_118 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] =============== Computing costs for Conv_121
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,32400,180,1) long-strided -> Float(32400,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,1,414720,2304) long-strided -> Float(32400,1,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(32400,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(74649600,32400,180,1) long-strided -> Half(32400,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_121
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_121 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_121 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_121 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(37324800,1:2,207360,1152) long-strided -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_121
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_121 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_121 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(18662400,1:4,103680,576) long-strided -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_121
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_121 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_121 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Float(32400,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_121
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_121 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_121 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,32400,180,1) -> Float(32400,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,1,11520,64) -> Float(32400,1,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(32400,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(2073600,32400,180,1) -> Half(32400,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_121 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_121 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_121 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:2,5760,32) -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_121 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_121 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(518400,1:4,2880,16) -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_121 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_121 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Float(32400,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_121 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_121 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] =============== Computing costs for Conv_124
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,32400,180,1) long-strided -> Float(97200,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,1,414720,2304) long-strided -> Float(97200,1,540,3) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(97200,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(74649600,32400,180,1) long-strided -> Half(97200,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_124
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_124 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_124 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_124 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(37324800,1:2,207360,1152) long-strided -> Half(64800,1:2,360,2) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_124
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_124 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_124 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(18662400,1:4,103680,576) long-strided -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_124
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_124 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_124 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Float(97200,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_124
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_124 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_124 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,32400,180,1) -> Float(97200,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,1,11520,64) -> Float(97200,1,540,3) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(97200,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(2073600,32400,180,1) -> Half(97200,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_124 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_124 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_124 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:2,5760,32) -> Half(64800,1:2,360,2) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_124 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_124 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(518400,1:4,2880,16) -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_124 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_124 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Float(97200,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_124 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_124 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] =============== Computing costs for Conv_127
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,32400,180,1) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,1,414720,2304) long-strided -> Float(64800,1,360,2) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(74649600,32400,180,1) long-strided -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_127
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_127 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_127 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_127 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(37324800,1:2,207360,1152) long-strided -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_127
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_127 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_127 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(18662400,1:4,103680,576) long-strided -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_127
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_127 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_127 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_127
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_127 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_127 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,32400,180,1) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,1,11520,64) -> Float(64800,1,360,2) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(2073600,32400,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_127 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_127 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_127 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:2,5760,32) -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_127 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_127 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(518400,1:4,2880,16) -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_127 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_127 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_127 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_127 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] =============== Computing costs for Conv_130
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,32400,180,1) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,1,414720,2304) long-strided -> Float(64800,1,360,2) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(74649600,32400,180,1) long-strided -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_130
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_130 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_130 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_130 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(37324800,1:2,207360,1152) long-strided -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_130
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_130 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_130 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(18662400,1:4,103680,576) long-strided -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_130
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_130 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_130 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_130
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_130 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_130 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,32400,180,1) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,1,11520,64) -> Float(64800,1,360,2) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(2073600,32400,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_130 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_130 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_130 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:2,5760,32) -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_130 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_130 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(518400,1:4,2880,16) -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_130 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_130 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_130 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_130 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] =============== Computing costs for Conv_133
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,32400,180,1) long-strided -> Float(32400,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,1,414720,2304) long-strided -> Float(32400,1,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(32400,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(74649600,32400,180,1) long-strided -> Half(32400,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_133
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_133 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_133 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_133 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(37324800,1:2,207360,1152) long-strided -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_133
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_133 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_133 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(18662400,1:4,103680,576) long-strided -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_133
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_133 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_133 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Float(32400,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_133
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_133 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_133 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,32400,180,1) -> Float(32400,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,1,11520,64) -> Float(32400,1,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(32400,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(2073600,32400,180,1) -> Half(32400,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_133 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_133 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_133 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:2,5760,32) -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_133 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_133 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(518400,1:4,2880,16) -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_133 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_133 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Float(32400,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_133 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_133 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] =============== Computing costs for Conv_136
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,32400,180,1) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,1,414720,2304) long-strided -> Float(64800,1,360,2) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(74649600,32400,180,1) long-strided -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_136
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_136 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_136 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_136 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(37324800,1:2,207360,1152) long-strided -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_136
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_136 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_136 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(18662400,1:4,103680,576) long-strided -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_136
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_136 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_136 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_136
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_136 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_136 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,32400,180,1) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,1,11520,64) -> Float(64800,1,360,2) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(2073600,32400,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_136 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_136 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_136 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:2,5760,32) -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_136 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_136 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(518400,1:4,2880,16) -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_136 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_136 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_136 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_136 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] =============== Computing costs for Conv_139
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,32400,180,1) long-strided -> Float(32400,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,1,414720,2304) long-strided -> Float(32400,1,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(32400,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(74649600,32400,180,1) long-strided -> Half(32400,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_139
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_139 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_139 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_139 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(37324800,1:2,207360,1152) long-strided -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_139
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_139 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_139 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(18662400,1:4,103680,576) long-strided -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_139
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_139 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_139 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Float(32400,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_139
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_139 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_139 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,32400,180,1) -> Float(32400,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,1,11520,64) -> Float(32400,1,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(32400,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(2073600,32400,180,1) -> Half(32400,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_139 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_139 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_139 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:2,5760,32) -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_139 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_139 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(518400,1:4,2880,16) -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_139 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_139 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Float(32400,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_139 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_139 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] =============== Computing costs for Conv_142
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,32400,180,1) long-strided -> Float(97200,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,1,414720,2304) long-strided -> Float(97200,1,540,3) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(97200,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(74649600,32400,180,1) long-strided -> Half(97200,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_142
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_142 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_142 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_142 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(37324800,1:2,207360,1152) long-strided -> Half(64800,1:2,360,2) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_142
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_142 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_142 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(18662400,1:4,103680,576) long-strided -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_142
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_142 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_142 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Float(97200,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_142
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_142 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_142 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,32400,180,1) -> Float(97200,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,1,11520,64) -> Float(97200,1,540,3) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(97200,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(2073600,32400,180,1) -> Half(97200,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_142 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_142 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_142 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:2,5760,32) -> Half(64800,1:2,360,2) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_142 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_142 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(518400,1:4,2880,16) -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_142 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_142 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Float(97200,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_142 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_142 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] =============== Computing costs for Conv_145
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,32400,180,1) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,1,414720,2304) long-strided -> Float(64800,1,360,2) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(74649600,32400,180,1) long-strided -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_145
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_145 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_145 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_145 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(37324800,1:2,207360,1152) long-strided -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_145
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_145 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_145 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(18662400,1:4,103680,576) long-strided -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_145
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_145 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_145 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_145
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_145 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_145 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,32400,180,1) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,1,11520,64) -> Float(64800,1,360,2) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(2073600,32400,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_145 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_145 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_145 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:2,5760,32) -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_145 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_145 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(518400,1:4,2880,16) -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_145 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_145 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_145 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_145 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] =============== Computing costs for Conv_148
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,32400,180,1) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,1,414720,2304) long-strided -> Float(64800,1,360,2) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(74649600,32400,180,1) long-strided -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_148
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_148 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_148 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_148 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(37324800,1:2,207360,1152) long-strided -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_148
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_148 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_148 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(18662400,1:4,103680,576) long-strided -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_148
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_148 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_148 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_148
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_148 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_148 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,32400,180,1) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,1,11520,64) -> Float(64800,1,360,2) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(2073600,32400,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_148 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_148 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_148 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:2,5760,32) -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_148 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_148 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(518400,1:4,2880,16) -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_148 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_148 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_148 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_148 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] =============== Computing costs for Conv_151
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,32400,180,1) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,1,414720,2304) long-strided -> Float(64800,1,360,2) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(74649600,32400,180,1) long-strided -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_151
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_151 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_151 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_151 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(37324800,1:2,207360,1152) long-strided -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_151
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_151 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_151 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(18662400,1:4,103680,576) long-strided -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_151
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_151 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_151 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_151
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_151 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_151 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,32400,180,1) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,1,11520,64) -> Float(64800,1,360,2) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(2073600,32400,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_151 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_151 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_151 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:2,5760,32) -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_151 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_151 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(518400,1:4,2880,16) -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_151 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_151 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_151 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_151 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] =============== Computing costs for Conv_154
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,32400,180,1) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,1,414720,2304) long-strided -> Float(64800,1,360,2) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(74649600,32400,180,1) long-strided -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_154
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_154 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_154 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_154 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(37324800,1:2,207360,1152) long-strided -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_154
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_154 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_154 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(18662400,1:4,103680,576) long-strided -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_154
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_154 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_154 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_154
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_154 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_154 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,32400,180,1) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,1,11520,64) -> Float(64800,1,360,2) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(2073600,32400,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_154 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_154 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_154 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:2,5760,32) -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_154 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_154 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(518400,1:4,2880,16) -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_154 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_154 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_154 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_154 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] =============== Computing costs for Conv_157
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,32400,180,1) long-strided -> Float(32400,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,1,414720,2304) long-strided -> Float(32400,1,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(32400,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(74649600,32400,180,1) long-strided -> Half(32400,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_157
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_157 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_157 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_157 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(37324800,1:2,207360,1152) long-strided -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_157
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_157 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_157 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(18662400,1:4,103680,576) long-strided -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_157
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_157 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_157 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Float(32400,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_157
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_157 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_157 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,32400,180,1) -> Float(32400,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,1,11520,64) -> Float(32400,1,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(32400,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(2073600,32400,180,1) -> Half(32400,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_157 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_157 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_157 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:2,5760,32) -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_157 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_157 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(518400,1:4,2880,16) -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_157 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_157 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Float(32400,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_157 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_157 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] =============== Computing costs for Conv_160
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,32400,180,1) long-strided -> Float(97200,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,1,414720,2304) long-strided -> Float(97200,1,540,3) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(97200,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(74649600,32400,180,1) long-strided -> Half(97200,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_160
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_160 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_160 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_160 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(37324800,1:2,207360,1152) long-strided -> Half(64800,1:2,360,2) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_160
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_160 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_160 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(18662400,1:4,103680,576) long-strided -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_160
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_160 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_160 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Float(97200,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_160
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_160 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_160 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,32400,180,1) -> Float(97200,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,1,11520,64) -> Float(97200,1,540,3) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(97200,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(2073600,32400,180,1) -> Half(97200,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_160 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_160 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_160 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:2,5760,32) -> Half(64800,1:2,360,2) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_160 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_160 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(518400,1:4,2880,16) -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_160 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_160 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Float(97200,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_160 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_160 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] =============== Computing costs for Conv_163
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,32400,180,1) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,1,414720,2304) long-strided -> Float(64800,1,360,2) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(74649600,32400,180,1) long-strided -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_163
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_163 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_163 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_163 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(37324800,1:2,207360,1152) long-strided -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_163
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_163 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_163 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(18662400,1:4,103680,576) long-strided -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_163
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_163 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_163 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_163
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_163 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_163 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,32400,180,1) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(2073600,1,11520,64) -> Float(64800,1,360,2) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(2073600,32400,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_163 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_163 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_163 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:2,5760,32) -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_163 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_163 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(518400,1:4,2880,16) -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_163 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_163 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_163 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_163 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] =============== Computing costs for Conv_166
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,32400,180,1) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(74649600,1,414720,2304) long-strided -> Float(64800,1,360,2) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(74649600,32400,180,1) long-strided -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_166
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_166 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_166 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_166 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(37324800,1:2,207360,1152) long-strided -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_166
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_166 (CaskConvolution[0x80000009])
[04/25/2025-09:08:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] --------------- Timing Runner: Conv_166 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:54] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:54] [V] [TRT] *************** Autotuning format combination: Half(18662400,1:4,103680,576) long-strided -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:54] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_166
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Conv_166 (CaskConvolution[0x80000009])
[04/25/2025-09:08:55] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Conv_166 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:55] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_166
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Conv_166 (CaskConvolution[0x80000009])
[04/25/2025-09:08:55] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Conv_166 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:55] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning format combination: Float(2073600,32400,180,1) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning format combination: Float(2073600,1,11520,64) -> Float(64800,1,360,2) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning format combination: Half(2073600,32400,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Conv_166 (CaskConvolution[0x80000009])
[04/25/2025-09:08:55] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Conv_166 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:55] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Conv_166 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:55] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:2,5760,32) -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Conv_166 (CaskConvolution[0x80000009])
[04/25/2025-09:08:55] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Conv_166 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:55] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning format combination: Half(518400,1:4,2880,16) -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Conv_166 (CaskConvolution[0x80000009])
[04/25/2025-09:08:55] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Conv_166 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:55] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Conv_166 (CaskConvolution[0x80000009])
[04/25/2025-09:08:55] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Conv_166 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:55] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] =============== Computing costs for Conv_169
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning format combination: Float(74649600,32400,180,1) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning format combination: Float(74649600,1,414720,2304) long-strided -> Float(64800,1,360,2) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning format combination: Float(18662400,1:4,103680,576) long-strided -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning format combination: Half(74649600,32400,180,1) long-strided -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_169
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Conv_169 (CaskConvolution[0x80000009])
[04/25/2025-09:08:55] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Conv_169 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:55] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Conv_169 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:55] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning format combination: Half(37324800,1:2,207360,1152) long-strided -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_169
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Conv_169 (CaskConvolution[0x80000009])
[04/25/2025-09:08:55] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Conv_169 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:55] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning format combination: Half(18662400,1:4,103680,576) long-strided -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_169
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Conv_169 (CaskConvolution[0x80000009])
[04/25/2025-09:08:55] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Conv_169 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:55] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] RunnerBuilder of layer implementation CaskJitConv cannot handle striding for node Conv_169
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Conv_169 (CaskConvolution[0x80000009])
[04/25/2025-09:08:55] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Conv_169 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:55] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning format combination: Half(9331200,1:8,51840,288) long-strided -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning format combination: Float(2073600,32400,180,1) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning format combination: Float(2073600,1,11520,64) -> Float(64800,1,360,2) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning format combination: Float(518400,1:4,2880,16) -> Float(32400,1:4,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning format combination: Half(2073600,32400,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Conv_169 (CaskConvolution[0x80000009])
[04/25/2025-09:08:55] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Conv_169 (CudnnConvolution[0x80000000])
[04/25/2025-09:08:55] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Conv_169 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:55] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning format combination: Half(1036800,1:2,5760,32) -> Half(32400,1:2,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Conv_169 (CaskConvolution[0x80000009])
[04/25/2025-09:08:55] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Conv_169 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:55] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning format combination: Half(518400,1:4,2880,16) -> Half(32400,1:4,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Conv_169 (CaskConvolution[0x80000009])
[04/25/2025-09:08:55] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Conv_169 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:55] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Float(64800,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Conv_169 (CaskConvolution[0x80000009])
[04/25/2025-09:08:55] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Conv_169 (CaskFlattenConvolution[0x80000036])
[04/25/2025-09:08:55] [V] [TRT] CaskFlattenConvolution has no valid tactics for this config, skipping
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning format combination: Half(259200,1:8,1440,8) -> Half(32400,1:8,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:55] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Float(8294400,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0168066
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0159279
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0652434
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(input -> <out>) (Reformat[0x80000006]) profiling completed in 0.0217197 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0159279
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Float(8294400,1,46080,256) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0975726
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0181383
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0975726
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(input -> <out>) (Reformat[0x80000006]) profiling completed in 0.011469 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0181383
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Float(2073600,1:4,11520,64) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0985166
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0181577
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0983771
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(input -> <out>) (Reformat[0x80000006]) profiling completed in 0.00544304 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0181577
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Half(1036800,1:8,5760,32) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0955246
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0120556
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0171322
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(input -> <out>) (Reformat[0x80000006]) profiling completed in 0.0191604 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0120556
[04/25/2025-09:08:55] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:55] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Float(4147200,1,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.12 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0456777
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0124221
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00993615
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(input.12 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00678731 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00993615
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Float(1036800,1:4,5760,32) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.12 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0458971
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0120571
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00993676
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(input.12 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00534141 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00993676
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Half(518400,1:8,2880,16) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.12 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.045312
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0121535
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0104281
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(input.12 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00515984 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0104281
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Float(4147200,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.12 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0529067
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.012288
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00955733
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(input.12 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00518438 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00955733
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Float(1036800,1:4,5760,32) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.12 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.017278
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0118266
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0173267
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(input.12 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00532751 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0118266
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Half(518400,1:8,2880,16) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.12 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0173592
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00952869
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0172942
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(input.12 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00533313 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.00952869
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Float(4147200,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.12 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0529067
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116353
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00957653
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(input.12 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00512606 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00957653
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Float(4147200,1,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.12 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0172617
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0117816
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0174243
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(input.12 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00535293 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0117816
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Half(518400,1:8,2880,16) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.12 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.019584
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00808635
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0195291
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(input.12 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00517492 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.00808635
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Float(4147200,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.12 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0529554
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00987916
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00980114
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(input.12 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00514435 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00980114
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Float(4147200,1,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.12 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0173592
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00991817
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.017343
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(input.12 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00526331 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.00991817
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Float(1036800,1:4,5760,32) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.12 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0199297
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00986941
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0199131
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(input.12 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00519294 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.00986941
[04/25/2025-09:08:55] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:55] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Float(4147200,1,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Float(1036800,1:4,5760,32) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Half(518400,1:8,2880,16) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Float(4147200,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Float(1036800,1:4,5760,32) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Half(518400,1:8,2880,16) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Float(4147200,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Float(4147200,1,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Half(518400,1:8,2880,16) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Float(4147200,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Float(4147200,1,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Float(1036800,1:4,5760,32) ***************
[04/25/2025-09:08:55] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:55] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Float(4147200,1,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Float(1036800,1:4,5760,32) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Half(518400,1:8,2880,16) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Float(4147200,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Float(1036800,1:4,5760,32) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Half(518400,1:8,2880,16) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Float(4147200,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Float(4147200,1,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Half(518400,1:8,2880,16) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Float(4147200,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Float(4147200,1,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Float(1036800,1:4,5760,32) ***************
[04/25/2025-09:08:55] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:55] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Float(4147200,1,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Float(1036800,1:4,5760,32) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Half(518400,1:8,2880,16) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Float(4147200,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Float(1036800,1:4,5760,32) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Half(518400,1:8,2880,16) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Float(4147200,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Float(4147200,1,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Half(518400,1:8,2880,16) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Float(4147200,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Float(4147200,1,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Float(1036800,1:4,5760,32) ***************
[04/25/2025-09:08:55] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:55] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Float(4147200,1,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Float(1036800,1:4,5760,32) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Half(518400,1:8,2880,16) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Float(4147200,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Float(1036800,1:4,5760,32) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Half(518400,1:8,2880,16) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Float(4147200,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Float(4147200,1,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Half(518400,1:8,2880,16) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Float(4147200,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Float(4147200,1,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Float(1036800,1:4,5760,32) ***************
[04/25/2025-09:08:55] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:55] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Float(4147200,1,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0456411
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0121417
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0100062
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006]) profiling completed in 0.00527503 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0100062
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Float(1036800,1:4,5760,32) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0460069
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0120686
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00995718
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006]) profiling completed in 0.00525896 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00995718
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Half(4147200,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.009308
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00809448
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0354011
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006]) profiling completed in 0.00542086 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.00809448
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Half(2073600,32400:2,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0176681
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0273798
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0168716
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006]) profiling completed in 0.00523953 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0168716
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Half(2073600,1:2,11520,64) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0453497
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0157989
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.045312
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006]) profiling completed in 0.00526098 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0157989
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Half(1036800,1:4,5760,32) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0453886
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0081026
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0454217
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006]) profiling completed in 0.00530588 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0081026
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Half(518400,1:8,2880,16) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0453851
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00795657
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0104062
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006]) profiling completed in 0.00530177 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.00795657
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Half(259200,1:16,1440,8) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0453851
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00793023
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.045312
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006]) profiling completed in 0.0053932 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.00793023
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Float(4147200,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0529036
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0117029
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00964541
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006]) profiling completed in 0.00545314 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00964541
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Float(1036800,1:4,5760,32) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.017343
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0118491
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0173105
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006]) profiling completed in 0.00527977 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0118491
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Half(4147200,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0526629
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00793023
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0528091
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006]) profiling completed in 0.0050593 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.00793023
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Half(2073600,32400:2,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0536869
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0267459
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0536869
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006]) profiling completed in 0.00476624 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0267459
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Half(2073600,1:2,11520,64) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0173587
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0150235
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0172764
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006]) profiling completed in 0.00503848 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0150235
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Half(1036800,1:4,5760,32) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0172942
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00833829
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0173257
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006]) profiling completed in 0.00505478 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.00833829
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Half(518400,1:8,2880,16) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0173095
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00807822
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.017278
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006]) profiling completed in 0.00495308 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.00807822
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Half(259200,1:16,1440,8) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0173105
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00815949
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0172617
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006]) profiling completed in 0.00493544 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.00815949
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Float(4147200,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.053053
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116234
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00958598
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006]) profiling completed in 0.00502655 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00958598
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Float(4147200,1,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0172942
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0118604
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0174568
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006]) profiling completed in 0.0055136 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0118604
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Half(4147200,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0528091
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.020224
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0527604
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006]) profiling completed in 0.00525444 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.020224
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Half(2073600,32400:2,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0540282
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0268678
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0537356
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006]) profiling completed in 0.00534317 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0268678
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Half(2073600,1:2,11520,64) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.019584
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0150821
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0195829
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006]) profiling completed in 0.0052501 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0150821
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Half(1036800,1:4,5760,32) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0195863
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0129097
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0195474
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006]) profiling completed in 0.00512545 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0129097
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Half(518400,1:8,2880,16) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0195657
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0126903
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0195657
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006]) profiling completed in 0.00510413 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0126903
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Half(259200,1:16,1440,8) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0195657
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.010543
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.019584
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006]) profiling completed in 0.00503259 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.010543
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Float(4147200,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0527604
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113206
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00973288
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006]) profiling completed in 0.00505107 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00973288
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Float(4147200,1,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0173755
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0127878
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0173735
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006]) profiling completed in 0.00517017 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0127878
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Float(1036800,1:4,5760,32) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0199863
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0101522
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0201143
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006]) profiling completed in 0.00550341 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0101522
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Half(4147200,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0526629
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0101525
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00732228
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006]) profiling completed in 0.00579824 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00732228
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Half(2073600,32400:2,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0534903
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.026941
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00678857
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006]) profiling completed in 0.00545202 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00678857
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Half(2073600,1:2,11520,64) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.018432
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0144969
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0184503
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006]) profiling completed in 0.00494497 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0144969
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Half(1036800,1:4,5760,32) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.018432
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0110502
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0184674
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006]) profiling completed in 0.00478578 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0110502
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Half(259200,1:16,1440,8) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0184514
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0101522
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0185051
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> input.72) (Reformat[0x80000006]) profiling completed in 0.00482498 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0101522
[04/25/2025-09:08:55] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:55] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Float(4147200,1,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Float(1036800,1:4,5760,32) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Half(518400,1:8,2880,16) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Float(4147200,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Float(1036800,1:4,5760,32) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Half(518400,1:8,2880,16) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Float(4147200,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Float(4147200,1,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Half(518400,1:8,2880,16) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Float(4147200,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.72 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00932571
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0107416
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0335579
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(input.72 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00529841 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.00932571
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Float(4147200,1,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.72 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0434469
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0106475
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0434777
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(input.72 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00526185 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0106475
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Float(1036800,1:4,5760,32) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.72 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0439223
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0108571
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.044032
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(input.72 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00560098 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0108571
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Half(518400,1:8,2880,16) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.72 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0428251
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115116
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.009472
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(input.72 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00511717 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.009472
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Float(4147200,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.72 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0173592
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0118038
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0168066
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(input.72 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00536916 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0118038
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Float(4147200,1,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.72 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0204173
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115003
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0203886
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(input.72 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00502316 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0115003
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Float(1036800,1:4,5760,32) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.72 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0213995
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114335
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0214204
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(input.72 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00495284 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0114335
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Half(518400,1:8,2880,16) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.72 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0191086
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0109087
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00759146
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(input.72 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00529845 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00759146
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:2,11520,64) -> Float(4147200,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.72 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0529067
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0103445
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0529067
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(input.72 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00487954 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0103445
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:2,11520,64) -> Float(4147200,1,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.72 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0174243
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0106266
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0174258
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(input.72 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0051395 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0106266
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:2,11520,64) -> Float(1036800,1:4,5760,32) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.72 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0203337
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.010752
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0202057
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(input.72 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00543072 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.010752
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:2,11520,64) -> Half(518400,1:8,2880,16) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.72 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0186697
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0167253
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0185966
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(input.72 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0052778 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0167253
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:4,5760,32) -> Float(4147200,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.72 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.053053
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0122503
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0529554
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(input.72 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00477545 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0122503
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:4,5760,32) -> Float(4147200,1,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.72 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0173105
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114666
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0173745
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(input.72 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00520745 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0114666
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:4,5760,32) -> Float(1036800,1:4,5760,32) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.72 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0198583
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114891
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.019968
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(input.72 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00517144 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0114891
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:4,5760,32) -> Half(518400,1:8,2880,16) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.72 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0184869
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00993768
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0184674
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(input.72 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00482727 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.00993768
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Float(4147200,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Float(4147200,1,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Float(1036800,1:4,5760,32) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Float(4147200,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.72 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0528091
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00979139
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0528091
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(input.72 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00500628 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.00979139
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Float(4147200,1,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.72 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.017343
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0105535
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0176681
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(input.72 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00559493 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0105535
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Float(1036800,1:4,5760,32) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.72 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.019952
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0218802
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0199651
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(input.72 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00561794 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.019952
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Half(518400,1:8,2880,16) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.72 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0185046
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00904229
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0184469
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(input.72 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00508478 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.00904229
[04/25/2025-09:08:55] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:55] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) long-strided -> Float(16588800,1,92160,512) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0986697
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0227997
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0197103
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00559825 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0197103
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) long-strided -> Float(4147200,1:4,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0994011
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0228395
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0198229
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00566528 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0198229
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) long-strided -> Half(16588800,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0168391
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115341
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0168391
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.0109504 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0115341
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) long-strided -> Half(8294400,32400:2,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0322706
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0520777
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0323584
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00502578 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.0322706
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) long-strided -> Half(8294400,1:2,46080,256) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0979383
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0291401
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0980114
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00561151 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0291401
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) long-strided -> Half(4147200,1:4,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0978651
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.016514
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0980846
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.0058 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.016514
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) long-strided -> Half(2073600,1:8,11520,64) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0980114
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0138705
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0980114
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00589867 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0138705
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) long-strided -> Half(1036800,1:16,5760,32) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0980114
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0137775
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0979383
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00591728 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0137775
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) long-strided -> Float(16588800,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.104082
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0211063
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0185229
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00569076 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0185229
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) long-strided -> Float(4147200,1:4,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0340846
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0230922
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0340553
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00561505 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0230922
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) long-strided -> Half(16588800,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.10357
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0143365
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.103497
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00593932 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0143365
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) long-strided -> Half(8294400,32400:2,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.105618
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.052419
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.105765
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00639108 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.052419
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) long-strided -> Half(8294400,1:2,46080,256) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0322734
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0272579
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0322999
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00559613 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0272579
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) long-strided -> Half(4147200,1:4,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0323291
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0171647
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0322706
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00537438 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0171647
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) long-strided -> Half(2073600,1:8,11520,64) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0321829
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0126903
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0323291
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00531988 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0126903
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) long-strided -> Half(1036800,1:16,5760,32) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0322999
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0127627
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0322706
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00541676 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0127627
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) long-strided -> Float(16588800,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.104155
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0211069
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0185234
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00565549 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0185234
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) long-strided -> Float(16588800,1,92160,512) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0340261
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.023134
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0339675
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00560044 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.023134
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) long-strided -> Half(16588800,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.103643
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0150967
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.103643
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.0060856 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0150967
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) long-strided -> Half(8294400,32400:2,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.105545
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0510537
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.105618
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00580513 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0510537
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) long-strided -> Half(8294400,1:2,46080,256) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0367909
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0272579
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0367543
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00498063 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0272579
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) long-strided -> Half(4147200,1:4,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0367177
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0143067
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0368286
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00499476 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0143067
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) long-strided -> Half(2073600,1:8,11520,64) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0367909
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0139636
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0369006
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00498569 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0139636
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) long-strided -> Half(1036800,1:16,5760,32) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0367177
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0126903
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0367909
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00505428 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0126903
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) long-strided -> Float(16588800,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.10379
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0181394
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.103863
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00586528 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0181394
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) long-strided -> Float(16588800,1,92160,512) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0323584
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0178631
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0330606
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00573712 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0178631
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) long-strided -> Float(4147200,1:4,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0375223
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0178834
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0375954
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00500701 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0178834
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) long-strided -> Half(16588800,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.103424
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0171794
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.103424
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00594679 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0171794
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) long-strided -> Half(8294400,32400:2,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.105253
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.051005
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0116128
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00572195 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0116128
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) long-strided -> Half(8294400,1:2,46080,256) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0346405
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.026429
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.034933
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00545906 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.026429
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) long-strided -> Half(4147200,1:4,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0348453
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0129097
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0350208
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00553738 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0129097
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) long-strided -> Half(1036800,1:16,5760,32) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0349038
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0123124
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0348462
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00550184 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0123124
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Float(16588800,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0170829
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0175055
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0170667
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00584693 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0170667
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Float(16588800,1,92160,512) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.098816
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0228624
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0195291
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00551985 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0195291
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0993303
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0229251
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0196206
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00558922 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0196206
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Half(16588800,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0168066
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0130593
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0168066
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00501897 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0130593
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0322139
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0521265
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0318025
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00492963 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0318025
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Half(8294400,1:2,46080,256) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0979383
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0287598
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0980046
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00532894 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0287598
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Half(4147200,1:4,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0979383
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0159614
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0979383
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00543329 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0159614
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0980114
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0156517
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0183589
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00546466 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0156517
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0980114
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0184851
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0981577
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.0059129 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0184851
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(8294400,1,46080,256) -> Float(16588800,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.103424
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0194749
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0173445
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00582748 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0173445
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(8294400,1,46080,256) -> Float(16588800,1,92160,512) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0324462
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.019712
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0324462
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00530382 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.019712
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(8294400,1,46080,256) -> Float(4147200,1:4,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0330606
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0217561
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0330606
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00531306 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0217561
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(8294400,1,46080,256) -> Half(16588800,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.103058
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0130682
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.103058
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00591024 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0130682
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(8294400,1,46080,256) -> Half(8294400,32400:2,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.104887
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0512
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.104887
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00567969 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0512
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(8294400,1,46080,256) -> Half(8294400,1:2,46080,256) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0322414
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0271848
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0323584
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00524623 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0271848
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(8294400,1,46080,256) -> Half(4147200,1:4,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0322999
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0166278
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0325029
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00514036 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0166278
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(8294400,1,46080,256) -> Half(2073600,1:8,11520,64) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0322999
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.012739
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0323291
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00527077 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.012739
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(8294400,1,46080,256) -> Half(1036800,1:16,5760,32) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0322706
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0127269
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0323291
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00522241 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0127269
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1:4,11520,64) -> Float(16588800,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.10357
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0194011
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0173603
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.0056172 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0173603
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1:4,11520,64) -> Float(16588800,1,92160,512) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0329143
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0218593
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0329435
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00534042 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0218593
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1:4,11520,64) -> Float(4147200,1:4,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0374857
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0217966
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0374491
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00503415 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0217966
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1:4,11520,64) -> Half(16588800,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.103058
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0127634
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.103131
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00589222 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0127634
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1:4,11520,64) -> Half(8294400,32400:2,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.104887
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0512
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.104814
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.0056761 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0512
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1:4,11520,64) -> Half(8294400,1:2,46080,256) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0370103
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0272335
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0367909
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00509281 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0272335
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1:4,11520,64) -> Half(4147200,1:4,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0367909
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0146002
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.036864
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00475254 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0146002
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1:4,11520,64) -> Half(2073600,1:8,11520,64) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0367543
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0206263
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.036864
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00481341 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0206263
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1:4,11520,64) -> Half(1036800,1:16,5760,32) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0368663
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0216294
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0368274
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00491213 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0216294
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:8,5760,32) -> Float(16588800,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.103863
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0171957
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.103863
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00593223 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0171957
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:8,5760,32) -> Float(16588800,1,92160,512) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0323877
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0174405
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0324754
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00521367 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0174405
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:8,5760,32) -> Float(4147200,1:4,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0375589
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0175705
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0376686
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00506948 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0175705
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:8,5760,32) -> Half(16588800,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.103424
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0128366
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.10379
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00574404 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0128366
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:8,5760,32) -> Half(8294400,32400:2,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.105326
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0504686
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0115903
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00537463 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0115903
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:8,5760,32) -> Half(8294400,1:2,46080,256) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0345527
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0258187
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0347282
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00517372 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0258187
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:8,5760,32) -> Half(4147200,1:4,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0346697
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0127288
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0346679
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00515202 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0127288
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:8,5760,32) -> Half(2073600,1:8,11520,64) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0345829
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0122888
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0346697
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00510735 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0122888
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:8,5760,32) -> Half(1036800,1:16,5760,32) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0346405
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116466
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.034699
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_602) (Reformat[0x80000006]) profiling completed in 0.00533442 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0116466
[04/25/2025-09:08:55] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:55] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Float(4147200,1,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Float(1036800,1:4,5760,32) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,32400,180,1) -> Half(518400,1:8,2880,16) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Float(4147200,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Float(1036800,1:4,5760,32) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1,23040,128) -> Half(518400,1:8,2880,16) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Float(4147200,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Float(4147200,1,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(1036800,1:4,5760,32) -> Half(518400,1:8,2880,16) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Float(4147200,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Float(4147200,1,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Float(1036800,1:4,5760,32) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(4147200,32400,180,1) -> Half(518400,1:8,2880,16) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Float(4147200,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Float(4147200,1,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Float(1036800,1:4,5760,32) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(2073600,32400:2,180,1) -> Half(518400,1:8,2880,16) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:2,11520,64) -> Float(4147200,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:2,11520,64) -> Float(4147200,1,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:2,11520,64) -> Float(1036800,1:4,5760,32) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:2,11520,64) -> Half(518400,1:8,2880,16) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:4,5760,32) -> Float(4147200,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:4,5760,32) -> Float(4147200,1,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:4,5760,32) -> Float(1036800,1:4,5760,32) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:4,5760,32) -> Half(518400,1:8,2880,16) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Float(4147200,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Float(4147200,1,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(518400,1:8,2880,16) -> Float(1036800,1:4,5760,32) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Float(4147200,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Float(4147200,1,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Float(1036800,1:4,5760,32) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:16,1440,8) -> Half(518400,1:8,2880,16) ***************
[04/25/2025-09:08:55] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:55] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(2073600,8100,90,1) -> Float(2073600,1,23040,256) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.96 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0266971
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0105541
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00604076
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(input.96 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00526584 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00604076
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(2073600,8100,90,1) -> Float(518400,1:4,5760,64) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.96 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0267215
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0106893
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00603429
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(input.96 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00537083 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00603429
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(2073600,8100,90,1) -> Half(259200,1:8,2880,32) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.96 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0265249
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.009362
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00621416
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(input.96 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00536506 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00621416
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,23040,256) -> Float(2073600,8100,90,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.96 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0273821
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00959634
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00702172
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(input.96 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00516343 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00702172
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,23040,256) -> Float(518400,1:4,5760,64) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.96 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0098499
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0104385
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00999619
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(input.96 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00529673 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.0098499
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,23040,256) -> Half(259200,1:8,2880,32) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.96 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00996693
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00992792
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0102504
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(input.96 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00534772 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.00992792
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,5760,64) -> Float(2073600,8100,90,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.96 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0281112
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00984991
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00748251
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(input.96 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00571436 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00748251
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,5760,64) -> Float(2073600,1,23040,256) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.96 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0105012
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0102818
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0111627
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(input.96 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00537827 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0102818
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,5760,64) -> Half(259200,1:8,2880,32) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.96 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0124709
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0110389
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0120686
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(input.96 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00555005 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0110389
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,2880,32) -> Float(2073600,8100,90,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.96 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0282088
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0103549
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00714606
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(input.96 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00557403 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00714606
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,2880,32) -> Float(2073600,1,23040,256) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.96 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0100254
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0120564
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00987916
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(input.96 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00545371 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00987916
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,2880,32) -> Float(518400,1:4,5760,64) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.96 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0111852
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0109812
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.011084
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(input.96 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0051923 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0109812
[04/25/2025-09:08:55] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:55] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(2073600,8100,90,1) -> Float(2073600,1,23040,256) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(2073600,8100,90,1) -> Float(518400,1:4,5760,64) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(2073600,8100,90,1) -> Half(259200,1:8,2880,32) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,23040,256) -> Float(2073600,8100,90,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,23040,256) -> Float(518400,1:4,5760,64) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,23040,256) -> Half(259200,1:8,2880,32) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,5760,64) -> Float(2073600,8100,90,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,5760,64) -> Float(2073600,1,23040,256) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,5760,64) -> Half(259200,1:8,2880,32) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,2880,32) -> Float(2073600,8100,90,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,2880,32) -> Float(2073600,1,23040,256) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,2880,32) -> Float(518400,1:4,5760,64) ***************
[04/25/2025-09:08:55] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:55] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(2073600,8100,90,1) -> Float(2073600,1,23040,256) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(2073600,8100,90,1) -> Float(518400,1:4,5760,64) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(2073600,8100,90,1) -> Half(259200,1:8,2880,32) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,23040,256) -> Float(2073600,8100,90,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,23040,256) -> Float(518400,1:4,5760,64) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,23040,256) -> Half(259200,1:8,2880,32) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,5760,64) -> Float(2073600,8100,90,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,5760,64) -> Float(2073600,1,23040,256) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,5760,64) -> Half(259200,1:8,2880,32) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,2880,32) -> Float(2073600,8100,90,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,2880,32) -> Float(2073600,1,23040,256) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,2880,32) -> Float(518400,1:4,5760,64) ***************
[04/25/2025-09:08:55] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:55] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(2073600,8100,90,1) -> Float(2073600,1,23040,256) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(2073600,8100,90,1) -> Float(518400,1:4,5760,64) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(2073600,8100,90,1) -> Half(259200,1:8,2880,32) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,23040,256) -> Float(2073600,8100,90,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,23040,256) -> Float(518400,1:4,5760,64) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,23040,256) -> Half(259200,1:8,2880,32) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,5760,64) -> Float(2073600,8100,90,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,5760,64) -> Float(2073600,1,23040,256) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,5760,64) -> Half(259200,1:8,2880,32) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,2880,32) -> Float(2073600,8100,90,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,2880,32) -> Float(2073600,1,23040,256) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,2880,32) -> Float(518400,1:4,5760,64) ***************
[04/25/2025-09:08:55] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:55] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(2073600,8100,90,1) -> Float(2073600,1,23040,256) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(2073600,8100,90,1) -> Float(518400,1:4,5760,64) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(2073600,8100,90,1) -> Half(259200,1:8,2880,32) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,23040,256) -> Float(2073600,8100,90,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,23040,256) -> Float(518400,1:4,5760,64) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,23040,256) -> Half(259200,1:8,2880,32) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,5760,64) -> Float(2073600,8100,90,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,5760,64) -> Float(2073600,1,23040,256) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,5760,64) -> Half(259200,1:8,2880,32) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,2880,32) -> Float(2073600,8100,90,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,2880,32) -> Float(2073600,1,23040,256) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,2880,32) -> Float(518400,1:4,5760,64) ***************
[04/25/2025-09:08:55] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:55] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(2073600,8100,90,1) -> Float(2073600,1,23040,256) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(2073600,8100,90,1) -> Float(518400,1:4,5760,64) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(2073600,8100,90,1) -> Half(2073600,8100,90,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::ConvTranspose_644 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00557574
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0107729
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0190171
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(onnx::ConvTranspose_644 -> <out>) (Reformat[0x80000006]) profiling completed in 0.005318 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.00557574
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(2073600,8100,90,1) -> Half(259200,1:8,2880,32) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,23040,256) -> Float(2073600,8100,90,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,23040,256) -> Float(518400,1:4,5760,64) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,23040,256) -> Half(2073600,8100,90,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::ConvTranspose_644 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0274042
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00895171
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0273554
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(onnx::ConvTranspose_644 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00488582 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.00895171
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,23040,256) -> Half(259200,1:8,2880,32) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,5760,64) -> Float(2073600,8100,90,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,5760,64) -> Float(2073600,1,23040,256) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,5760,64) -> Half(2073600,8100,90,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::ConvTranspose_644 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0273798
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0121173
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0274042
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(onnx::ConvTranspose_644 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00496376 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0121173
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,5760,64) -> Half(259200,1:8,2880,32) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,2880,32) -> Float(2073600,8100,90,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,2880,32) -> Float(2073600,1,23040,256) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,2880,32) -> Float(518400,1:4,5760,64) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,2880,32) -> Half(2073600,8100,90,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::ConvTranspose_644 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0273798
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0398629
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00589842
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(onnx::ConvTranspose_644 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00513456 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00589842
[04/25/2025-09:08:55] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:55] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) long-strided -> Float(16588800,1,92160,512) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) long-strided -> Float(4147200,1:4,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) long-strided -> Half(16588800,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) long-strided -> Half(8294400,32400:2,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) long-strided -> Half(8294400,1:2,46080,256) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) long-strided -> Half(4147200,1:4,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) long-strided -> Half(2073600,1:8,11520,64) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) long-strided -> Half(1036800,1:16,5760,32) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) long-strided -> Float(16588800,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) long-strided -> Float(4147200,1:4,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) long-strided -> Half(16588800,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) long-strided -> Half(8294400,32400:2,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) long-strided -> Half(8294400,1:2,46080,256) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) long-strided -> Half(4147200,1:4,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) long-strided -> Half(2073600,1:8,11520,64) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) long-strided -> Half(1036800,1:16,5760,32) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) long-strided -> Float(16588800,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) long-strided -> Float(16588800,1,92160,512) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) long-strided -> Half(16588800,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) long-strided -> Half(8294400,32400:2,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) long-strided -> Half(8294400,1:2,46080,256) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) long-strided -> Half(4147200,1:4,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) long-strided -> Half(2073600,1:8,11520,64) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) long-strided -> Half(1036800,1:16,5760,32) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) long-strided -> Float(16588800,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_647) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0167909
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0159126
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0167578
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_647) (Reformat[0x80000006]) profiling completed in 0.00522829 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0159126
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) long-strided -> Float(16588800,1,92160,512) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_647) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.097792
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0182497
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0984503
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_647) (Reformat[0x80000006]) profiling completed in 0.00569814 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0182497
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) long-strided -> Float(4147200,1:4,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_647) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0986697
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0183229
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0985966
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_647) (Reformat[0x80000006]) profiling completed in 0.00569791 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0183229
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) long-strided -> Half(8294400,32400:2,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_647) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0321243
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0194189
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0321536
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_647) (Reformat[0x80000006]) profiling completed in 0.00520888 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0194189
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) long-strided -> Half(8294400,1:2,46080,256) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_647) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0955909
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.104887
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0956709
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_647) (Reformat[0x80000006]) profiling completed in 0.00589777 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.0955909
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) long-strided -> Half(4147200,1:4,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_647) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0955977
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.10496
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0956709
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_647) (Reformat[0x80000006]) profiling completed in 0.00594621 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.0955977
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) long-strided -> Half(2073600,1:8,11520,64) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_647) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0955977
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0187429
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0956709
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_647) (Reformat[0x80000006]) profiling completed in 0.0055053 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0187429
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) long-strided -> Half(1036800,1:16,5760,32) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_647) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0956709
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0131661
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0955977
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_647) (Reformat[0x80000006]) profiling completed in 0.00538931 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0131661
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) long-strided -> Float(16588800,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) long-strided -> Float(16588800,1,92160,512) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) long-strided -> Float(4147200,1:4,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) long-strided -> Half(16588800,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) long-strided -> Half(8294400,32400:2,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) long-strided -> Half(8294400,1:2,46080,256) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) long-strided -> Half(4147200,1:4,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) long-strided -> Half(1036800,1:16,5760,32) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Float(16588800,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Float(16588800,1,92160,512) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Half(16588800,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Half(8294400,1:2,46080,256) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Half(4147200,1:4,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(8294400,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(8294400,1,46080,256) -> Float(16588800,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(8294400,1,46080,256) -> Float(16588800,1,92160,512) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(8294400,1,46080,256) -> Float(4147200,1:4,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(8294400,1,46080,256) -> Half(16588800,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(8294400,1,46080,256) -> Half(8294400,32400:2,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(8294400,1,46080,256) -> Half(8294400,1:2,46080,256) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(8294400,1,46080,256) -> Half(4147200,1:4,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(8294400,1,46080,256) -> Half(2073600,1:8,11520,64) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(8294400,1,46080,256) -> Half(1036800,1:16,5760,32) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1:4,11520,64) -> Float(16588800,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1:4,11520,64) -> Float(16588800,1,92160,512) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1:4,11520,64) -> Float(4147200,1:4,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1:4,11520,64) -> Half(16588800,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1:4,11520,64) -> Half(8294400,32400:2,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1:4,11520,64) -> Half(8294400,1:2,46080,256) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1:4,11520,64) -> Half(4147200,1:4,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1:4,11520,64) -> Half(2073600,1:8,11520,64) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1:4,11520,64) -> Half(1036800,1:16,5760,32) ***************
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Float(16588800,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_647) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0168223
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0183507
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0168061
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_647) (Reformat[0x80000006]) profiling completed in 0.00554947 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0168061
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Float(16588800,1,92160,512) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_647) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.097792
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.018284
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0976457
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_647) (Reformat[0x80000006]) profiling completed in 0.00548847 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.018284
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_647) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0985966
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0183406
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0986697
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_647) (Reformat[0x80000006]) profiling completed in 0.00570881 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0183406
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Half(16588800,32400,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_647) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00936286
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0143365
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00939943
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_647) (Reformat[0x80000006]) profiling completed in 0.00574516 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.00936286
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Half(8294400,32400:2,180,1) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_647) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0321243
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0192914
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0317147
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_647) (Reformat[0x80000006]) profiling completed in 0.00498604 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0192914
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Half(8294400,1:2,46080,256) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_647) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0955977
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.104741
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0956709
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_647) (Reformat[0x80000006]) profiling completed in 0.00580522 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.0955977
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Half(4147200,1:4,23040,128) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_647) (Reformat[0x80000006])
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.095744
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.104741
[04/25/2025-09:08:55] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0956709
[04/25/2025-09:08:55] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_647) (Reformat[0x80000006]) profiling completed in 0.00593292 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0956709
[04/25/2025-09:08:55] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[04/25/2025-09:08:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_647) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0955246
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0211566
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.017181
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_647) (Reformat[0x80000006]) profiling completed in 0.00563581 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.017181
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400,180,1) -> Half(1036800,1:16,5760,32) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> onnx::Concat_647) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0957371
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0127634
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0955977
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(<in> -> onnx::Concat_647) (Reformat[0x80000006]) profiling completed in 0.00555152 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0127634
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:8,5760,32) -> Float(16588800,32400,180,1) ***************
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:8,5760,32) -> Float(16588800,1,92160,512) ***************
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:8,5760,32) -> Float(4147200,1:4,23040,128) ***************
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:8,5760,32) -> Half(16588800,32400,180,1) ***************
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:8,5760,32) -> Half(8294400,32400:2,180,1) ***************
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:8,5760,32) -> Half(8294400,1:2,46080,256) ***************
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:8,5760,32) -> Half(4147200,1:4,23040,128) ***************
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:8,5760,32) -> Half(2073600,1:8,11520,64) ***************
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:8,5760,32) -> Half(1036800,1:16,5760,32) ***************
[04/25/2025-09:08:56] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:56] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.201582
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.146139
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.148919
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00549283 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.146139
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.203045
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.146139
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.149211
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00579454 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.146139
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Float(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.196315
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.104667
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.105033
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00653978 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.104667
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(16588800,32400,180,1) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.346697
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.144677
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.145262
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00657304 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.144677
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Float(4147200,1:4,23040,128) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.141093
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.142629
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.142043
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0085976 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.141093
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Float(16588800,1,92160,512) -> Half(2073600,1:8,11520,64) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.102985
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.10357
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.103497
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00626913 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.102985
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,32400,180,1) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.345819
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.144384
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.145408
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00664522 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.144384
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Float(16588800,1,92160,512) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.141093
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.142987
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.141166
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00886266 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.141093
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Float(4147200,1:4,23040,128) -> Half(2073600,1:8,11520,64) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.103207
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.104082
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.103424
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00638303 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.103207
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,32400,180,1) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.107739
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.108251
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.129168
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00687034 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.107739
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(16588800,1,92160,512) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.204215
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.1152
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.204069
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00661083 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.1152
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Float(4147200,1:4,23040,128) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.207287
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.116224
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.206117
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00671827 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.116224
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Half(16588800,32400,180,1) -> Half(2073600,1:8,11520,64) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.199973
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0206263
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0322121
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00525559 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0206263
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,32400,180,1) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.107374
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.111689
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.107227
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00650716 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.107227
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(16588800,1,92160,512) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.140946
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.12171
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.141019
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00780684 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.12171
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Float(4147200,1:4,23040,128) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.141605
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.12149
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.141385
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00792716 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.12149
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Half(8294400,32400:2,180,1) -> Half(2073600,1:8,11520,64) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.113445
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.026992
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0251368
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00559697 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0251368
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Half(8294400,1:2,46080,256) -> Float(16588800,32400,180,1) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.307639
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.132462
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.273408
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00831298 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.132462
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Half(8294400,1:2,46080,256) -> Float(16588800,1,92160,512) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.107227
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.109415
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.107593
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00677881 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.107227
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Half(8294400,1:2,46080,256) -> Float(4147200,1:4,23040,128) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.107081
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.109349
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.107447
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00651034 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.107081
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Half(8294400,1:2,46080,256) -> Half(2073600,1:8,11520,64) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0668968
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0256731
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0668038
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00567827 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0256731
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Half(4147200,1:4,23040,128) -> Float(16588800,32400,180,1) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.272969
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.131584
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.273115
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00801895 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.131584
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Half(4147200,1:4,23040,128) -> Float(16588800,1,92160,512) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.107447
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.109202
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.109275
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00671748 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.107447
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Half(4147200,1:4,23040,128) -> Float(4147200,1:4,23040,128) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.10752
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.108617
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.107666
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0065112 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.10752
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Half(4147200,1:4,23040,128) -> Half(2073600,1:8,11520,64) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0668526
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0213786
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0667063
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00563276 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0213786
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,32400,180,1) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.272677
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.131877
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.110519
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00730386 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.110519
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(16588800,1,92160,512) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.107227
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.108688
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.107586
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006]) profiling completed in 0.006528 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.107227
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Half(2073600,1:8,11520,64) -> Float(4147200,1:4,23040,128) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.107008
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.108617
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.10752
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00659406 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.107008
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,32400,180,1) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.272974
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.132462
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.273554
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00822451 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.132462
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(16588800,1,92160,512) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.107301
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.10869
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.107739
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0065958 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.107301
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Float(4147200,1:4,23040,128) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.107081
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.108617
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.107593
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00660385 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.107081
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Half(1036800,1:16,5760,32) -> Half(2073600,1:8,11520,64) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0668038
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0214204
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0668526
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.164 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0058938 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0214204
[04/25/2025-09:08:56] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:56] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Float(2073600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0115791
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0121051
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00599714
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00585896 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00599714
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Float(2073600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0119463
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0118154
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00596686
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00657307 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00596686
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Float(2073600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0108669
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00896
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00642385
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00679766 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00642385
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,11520,64) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.027648
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0108147
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00575762
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00639132 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00575762
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,11520,64) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00986941
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0108669
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00987916
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00630313 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.00986941
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Float(2073600,1,11520,64) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0098499
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0105221
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00985905
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00624587 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.0098499
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,2880,16) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0276724
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.010334
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00576329
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00637523 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00576329
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,2880,16) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00991817
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0110731
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00988891
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00625426 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00988891
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Float(518400,1:4,2880,16) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0109714
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0110164
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0109616
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00617047 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0109616
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,1440,8) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0276236
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0102501
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00613143
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00655294 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00613143
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,1440,8) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00990933
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0107729
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0098691
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00637107 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0098691
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Half(259200,1:8,1440,8) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0111311
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0106687
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0111174
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(onnx::Conv_651 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00593477 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0106687
[04/25/2025-09:08:56] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:56] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(74649600,1,414720,2304) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.06672
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.659607
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.704064
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat[0x80000006]) profiling completed in 0.0252181 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.659607
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.1027
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.659895
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.703781
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat[0x80000006]) profiling completed in 0.0250714 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.659895
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(74649600,32400,180,1) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.469577
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.470469
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.635465
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat[0x80000006]) profiling completed in 0.0169162 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.469577
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(37324800,1:2,207360,1152) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.960805
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.498688
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.960658
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat[0x80000006]) profiling completed in 0.0244155 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.498688
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(18662400,1:4,103680,576) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.960658
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.495616
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.961536
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat[0x80000006]) profiling completed in 0.024594 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.495616
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.961243
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.494446
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.498834
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat[0x80000006]) profiling completed in 0.0198908 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.494446
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(74649600,32400,180,1) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.72529
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.647314
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.673207
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat[0x80000006]) profiling completed in 0.0296247 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.647314
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(18662400,1:4,103680,576) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.631662
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.63605
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.631808
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat[0x80000006]) profiling completed in 0.0203463 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.631662
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(74649600,32400,180,1) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.6286
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.499127
[04/25/2025-09:08:56] [V] [TRT] Fast skip Tactic:0x0000000000000000 which exceed time limit during pre-run
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.59539
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat[0x80000006]) profiling completed in 0.0232952 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.499127
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(37324800,1:2,207360,1152) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.46709
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.469285
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.46709
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat[0x80000006]) profiling completed in 0.0152257 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.46709
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(18662400,1:4,103680,576) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.466651
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.516681
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.466944
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat[0x80000006]) profiling completed in 0.0159879 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.466651
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(9331200,1:8,51840,288) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.466798
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.469285
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.466665
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat[0x80000006]) profiling completed in 0.0152957 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.466665
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.68916
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.649216
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.672768
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat[0x80000006]) profiling completed in 0.02982 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.649216
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.631662
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.635611
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.631954
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat[0x80000006]) profiling completed in 0.0204103 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.631662
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(74649600,32400,180,1) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.63167
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.499127
[04/25/2025-09:08:56] [V] [TRT] Fast skip Tactic:0x0000000000000000 which exceed time limit during pre-run
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 1.59437
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat[0x80000006]) profiling completed in 0.0230107 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.499127
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(37324800,1:2,207360,1152) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.466944
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.468699
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.466651
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat[0x80000006]) profiling completed in 0.0149411 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.466651
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(18662400,1:4,103680,576) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.466944
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.518729
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.466798
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat[0x80000006]) profiling completed in 0.0152775 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.466798
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.466651
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.469006
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.466798
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat[0x80000006]) profiling completed in 0.0149119 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.466651
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,32400,180,1) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.29009
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.621129
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.540969
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat[0x80000006]) profiling completed in 0.0237803 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.540969
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,1,414720,2304) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.480695
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.482889
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.480832
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat[0x80000006]) profiling completed in 0.0153294 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.480695
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(18662400,1:4,103680,576) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.480695
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.48245
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.480841
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat[0x80000006]) profiling completed in 0.0155277 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.480695
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Half(74649600,32400,180,1) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 1.31641
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.323584
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.326656
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat[0x80000006]) profiling completed in 0.0188811 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.323584
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Half(37324800,1:2,207360,1152) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.348014
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.317147
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.348014
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat[0x80000006]) profiling completed in 0.0111318 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.317147
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Half(18662400,1:4,103680,576) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.34816
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.31627
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.348014
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(<in> -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168) (Reformat[0x80000006]) profiling completed in 0.011037 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.31627
[04/25/2025-09:08:56] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:56] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0119054
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0228206
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00660945
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00763302 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00660945
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0124099
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0126415
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0066294
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00763655 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0066294
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0114103
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0101132
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0110727
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00664745 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0101132
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0059275
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0108878
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00629665
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00720732 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.0059275
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0120076
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0098109
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00621396
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00760864 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00621396
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0121051
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0120446
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00625212
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00769064 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00625212
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0109714
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0109502
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.01093
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00735392 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.01093
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0289061
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0111849
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00587465
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00791534 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00587465
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00990842
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0126903
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00996693
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00839858 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.00990842
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00989867
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115562
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00991817
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00771239 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.00989867
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0288475
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0110277
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00581614
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00709455 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00581614
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0100254
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0116916
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00981059
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00676318 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00981059
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00989867
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112971
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00992792
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00617883 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.00989867
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00992792
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0111515
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00988891
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00608522 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00988891
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0289353
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0106364
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00583936
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00710908 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00583936
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00985966
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0113987
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00983954
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00711695 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00983954
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0108888
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0106887
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0109192
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00663283 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0106887
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0289646
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0105848
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00576951
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00653993 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00576951
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0102191
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00866528
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00996663
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0138471 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.00866528
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0109616
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00856202
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0110164
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00769676 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.00856202
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0109829
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00828978
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0110045
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00767287 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.00828978
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00563763
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00820013
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00579291
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00924894 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.00563763
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0114215
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0082334
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0114106
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00681995 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0082334
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0117025
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00855341
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0117138
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00663792 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.00855341
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0102919
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0261851
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.010658
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00676734 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.0102919
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00952838
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0161239
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00556993
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00596453 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00556993
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0112978
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0082814
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.011354
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0056894 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0082814
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0116241
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0106057
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0116251
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00556435 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0106057
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0104281
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0108774
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0102292
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00573518 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0102292
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0284282
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0106798
[04/25/2025-09:08:56] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0284282
[04/25/2025-09:08:56] [V] [TRT] Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00640723 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0106798
[04/25/2025-09:08:56] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0098304
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.010366
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00980114
[04/25/2025-09:08:57] [V] [TRT] Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0065401 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00980114
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0110727
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114103
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0110843
[04/25/2025-09:08:57] [V] [TRT] Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00648029 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.0110727
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0103752
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0114444
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0103863
[04/25/2025-09:08:57] [V] [TRT] Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00740473 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.0103752
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0284282
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0110716
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0284503
[04/25/2025-09:08:57] [V] [TRT] Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00634822 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0110716
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00992792
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0119101
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00991817
[04/25/2025-09:08:57] [V] [TRT] Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00706067 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00991817
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0111515
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0108144
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0111508
[04/25/2025-09:08:57] [V] [TRT] Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00679266 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0108144
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0104803
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0112647
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0104281
[04/25/2025-09:08:57] [V] [TRT] Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00671602 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0104281
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0284046
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0115228
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0284526
[04/25/2025-09:08:57] [V] [TRT] Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00719853 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0115228
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00993737
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0127878
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00994682
[04/25/2025-09:08:57] [V] [TRT] Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00792906 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.00993737
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0111515
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0117141
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0111624
[04/25/2025-09:08:57] [V] [TRT] Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00780552 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.0111515
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0103971
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.01208
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.010418
[04/25/2025-09:08:57] [V] [TRT] Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00716353 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.0103971
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0284526
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0117816
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0284526
[04/25/2025-09:08:57] [V] [TRT] Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00572976 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0117816
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00984015
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0105962
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00987916
[04/25/2025-09:08:57] [V] [TRT] Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00560223 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.00984015
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0111747
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.011174
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0110836
[04/25/2025-09:08:57] [V] [TRT] Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00551467 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0110836
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0103758
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0111627
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.010543
[04/25/2025-09:08:57] [V] [TRT] Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00586469 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.0103758
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0284038
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0171957
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0284526
[04/25/2025-09:08:57] [V] [TRT] Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00679098 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.0171957
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00988891
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.015243
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00988891
[04/25/2025-09:08:57] [V] [TRT] Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00701199 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.00988891
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.011309
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.013312
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0111188
[04/25/2025-09:08:57] [V] [TRT] Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00666861 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0111188
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0284769
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0102612
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00599162
[04/25/2025-09:08:57] [V] [TRT] Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00587061 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00599162
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0098883
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0108049
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0098499
[04/25/2025-09:08:57] [V] [TRT] Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00573552 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0098499
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.0110836
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00960701
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0110952
[04/25/2025-09:08:57] [V] [TRT] Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006]) profiling completed in 0.00533161 seconds. Fastest Tactic: 0x00000000000003ea Time: 0.00960701
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006])
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.010334
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0107105
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0103758
[04/25/2025-09:08:57] [V] [TRT] Optimizer Reformat(input.184 -> <out>) (Reformat[0x80000006]) profiling completed in 0.0055245 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.010334
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(64800,32400,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> reg_0) (Reformat[0x80000006])
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00425089
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0104911
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00890622
[04/25/2025-09:08:57] [V] [TRT] Optimizer Reformat(<in> -> reg_0) (Reformat[0x80000006]) profiling completed in 0.00557237 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.00425089
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(64800,1,360,2) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> reg_0) (Reformat[0x80000006])
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00701453
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00909743
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00401486
[04/25/2025-09:08:57] [V] [TRT] Optimizer Reformat(<in> -> reg_0) (Reformat[0x80000006]) profiling completed in 0.00580413 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00401486
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> reg_0) (Reformat[0x80000006])
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00526057
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0121897
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00635269
[04/25/2025-09:08:57] [V] [TRT] Optimizer Reformat(<in> -> reg_0) (Reformat[0x80000006]) profiling completed in 0.00644707 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.00526057
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> reg_0) (Reformat[0x80000006])
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00599181
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0132721
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00522873
[04/25/2025-09:08:57] [V] [TRT] Optimizer Reformat(<in> -> reg_0) (Reformat[0x80000006]) profiling completed in 0.00692919 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00522873
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(32400,32400,180,1) -> Half(32400,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> height_0) (Reformat[0x80000006])
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00392204
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0096253
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00623505
[04/25/2025-09:08:57] [V] [TRT] Optimizer Reformat(<in> -> height_0) (Reformat[0x80000006]) profiling completed in 0.00788129 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.00392204
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(32400,1,180,1) -> Half(32400,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> height_0) (Reformat[0x80000006])
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00490118
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00880296
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00356772
[04/25/2025-09:08:57] [V] [TRT] Optimizer Reformat(<in> -> height_0) (Reformat[0x80000006]) profiling completed in 0.0154394 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00356772
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(32400,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> height_0) (Reformat[0x80000006])
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00368738
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00988038
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00470474
[04/25/2025-09:08:57] [V] [TRT] Optimizer Reformat(<in> -> height_0) (Reformat[0x80000006]) profiling completed in 0.00742837 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.00368738
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(32400,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> height_0) (Reformat[0x80000006])
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00433164
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00941714
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.0037474
[04/25/2025-09:08:57] [V] [TRT] Optimizer Reformat(<in> -> height_0) (Reformat[0x80000006]) profiling completed in 0.00764557 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.0037474
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(97200,32400,180,1) -> Half(97200,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> dim_0) (Reformat[0x80000006])
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00365691
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.008934
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00367625
[04/25/2025-09:08:57] [V] [TRT] Optimizer Reformat(<in> -> dim_0) (Reformat[0x80000006]) profiling completed in 0.00562555 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.00365691
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(97200,1,540,3) -> Half(97200,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> dim_0) (Reformat[0x80000006])
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00381474
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.00833854
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00410501
[04/25/2025-09:08:57] [V] [TRT] Optimizer Reformat(<in> -> dim_0) (Reformat[0x80000006]) profiling completed in 0.00567249 seconds. Fastest Tactic: 0x00000000000003e8 Time: 0.00381474
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(97200,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> dim_0) (Reformat[0x80000006])
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00704305
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0188891
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00670317
[04/25/2025-09:08:57] [V] [TRT] Optimizer Reformat(<in> -> dim_0) (Reformat[0x80000006]) profiling completed in 0.00561261 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00670317
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(97200,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> dim_0) (Reformat[0x80000006])
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003e8 Time: 0.00657538
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x00000000000003ea Time: 0.0140459
[04/25/2025-09:08:57] [V] [TRT] Tactic: 0x0000000000000000 Time: 0.00634077
[04/25/2025-09:08:57] [V] [TRT] Optimizer Reformat(<in> -> dim_0) (Reformat[0x80000006]) profiling completed in 0.00569534 seconds. Fastest Tactic: 0x0000000000000000 Time: 0.00634077
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(64800,32400,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(64800,1,360,2) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(64800,32400,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(64800,1,360,2) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(32400,32400,180,1) -> Half(32400,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(32400,1,180,1) -> Half(32400,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(32400,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(32400,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(64800,32400,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(64800,1,360,2) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(32400,32400,180,1) -> Half(32400,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(32400,1,180,1) -> Half(32400,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(32400,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(32400,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(97200,32400,180,1) -> Half(97200,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(97200,1,540,3) -> Half(97200,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(97200,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(97200,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(64800,32400,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(64800,1,360,2) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(64800,32400,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(64800,1,360,2) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(64800,32400,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(64800,1,360,2) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(64800,32400,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(64800,1,360,2) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(32400,32400,180,1) -> Half(32400,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(32400,1,180,1) -> Half(32400,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(32400,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(32400,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(97200,32400,180,1) -> Half(97200,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(97200,1,540,3) -> Half(97200,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(97200,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(97200,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(64800,32400,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(64800,1,360,2) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(64800,32400,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(64800,1,360,2) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(64800,32400,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(64800,1,360,2) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(64800,32400,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(64800,1,360,2) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(32400,32400,180,1) -> Half(32400,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(32400,1,180,1) -> Half(32400,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(32400,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(32400,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(97200,32400,180,1) -> Half(97200,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(97200,1,540,3) -> Half(97200,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(97200,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(97200,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(64800,32400,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(64800,1,360,2) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(64800,32400,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(64800,1,360,2) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(32400,32400,180,1) -> Half(32400,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(32400,1,180,1) -> Half(32400,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(32400,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(32400,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(64800,32400,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(64800,1,360,2) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(32400,32400,180,1) -> Half(32400,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(32400,1,180,1) -> Half(32400,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(32400,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(32400,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(97200,32400,180,1) -> Half(97200,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(97200,1,540,3) -> Half(97200,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(97200,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(97200,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(64800,32400,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(64800,1,360,2) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(64800,32400,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(64800,1,360,2) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(64800,32400,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(64800,1,360,2) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(64800,32400,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(64800,1,360,2) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(32400,32400,180,1) -> Half(32400,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(32400,1,180,1) -> Half(32400,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(32400,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(32400,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(97200,32400,180,1) -> Half(97200,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(97200,1,540,3) -> Half(97200,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(97200,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(97200,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(64800,32400,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(64800,1,360,2) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(64800,32400,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(64800,1,360,2) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(74649600,1,414720,2304) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(74649600,32400,180,1) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(37324800,1:2,207360,1152) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(9331200,1:8,51840,288) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(18662400,1:4,103680,576) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,32400,180,1) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(74649600,1,414720,2304) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(18662400,1:4,103680,576) long-strided ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(2073600,1,11520,64) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Float(518400,1:4,2880,16) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(9331200,1:8,51840,288) -> Half(259200,1:8,1440,8) ***************
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs
[04/25/2025-09:08:57] [V] [TRT] =============== Computing reformatting costs: 
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(64800,32400,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(64800,1,360,2) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Float(32400,1:4,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [V] [TRT] *************** Autotuning Reformat: Half(32400,1:8,180,1) -> Half(64800,32400,180,1) ***************
[04/25/2025-09:08:57] [I] [TRT] [GraphReduction] The approximate region cut reduction algorithm is called.
[04/25/2025-09:08:57] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to Conv_15 + Relu_16 (input) from Half(8294400,32400,180,1) to Half(1036800,1:8,5760,32)
[04/25/2025-09:08:57] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_64 (reg_0) from Half(32400,1:8,180,1) to Half(64800,32400,180,1)
[04/25/2025-09:08:57] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_67 (height_0) from Half(32400,1:8,180,1) to Half(32400,32400,180,1)
[04/25/2025-09:08:57] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_70 (dim_0) from Half(32400,1:8,180,1) to Half(97200,32400,180,1)
[04/25/2025-09:08:57] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_73 (rot_0) from Half(32400,1:8,180,1) to Half(64800,32400,180,1)
[04/25/2025-09:08:57] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_76 (vel_0) from Half(32400,1:8,180,1) to Half(64800,32400,180,1)
[04/25/2025-09:08:57] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_79 (hm_0) from Half(32400,1:8,180,1) to Half(32400,32400,180,1)
[04/25/2025-09:08:57] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_82 (reg_1) from Half(32400,1:8,180,1) to Half(64800,32400,180,1)
[04/25/2025-09:08:57] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_85 (height_1) from Half(32400,1:8,180,1) to Half(32400,32400,180,1)
[04/25/2025-09:08:57] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_88 (dim_1) from Half(32400,1:8,180,1) to Half(97200,32400,180,1)
[04/25/2025-09:08:57] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_91 (rot_1) from Half(32400,1:8,180,1) to Half(64800,32400,180,1)
[04/25/2025-09:08:57] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_94 (vel_1) from Half(32400,1:8,180,1) to Half(64800,32400,180,1)
[04/25/2025-09:08:57] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_97 (hm_1) from Half(32400,1:8,180,1) to Half(64800,32400,180,1)
[04/25/2025-09:08:57] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_100 (reg_2) from Half(32400,1:8,180,1) to Half(64800,32400,180,1)
[04/25/2025-09:08:57] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_103 (height_2) from Half(32400,1:8,180,1) to Half(32400,32400,180,1)
[04/25/2025-09:08:57] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_106 (dim_2) from Half(32400,1:8,180,1) to Half(97200,32400,180,1)
[04/25/2025-09:08:57] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_109 (rot_2) from Half(32400,1:8,180,1) to Half(64800,32400,180,1)
[04/25/2025-09:08:57] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_112 (vel_2) from Half(32400,1:8,180,1) to Half(64800,32400,180,1)
[04/25/2025-09:08:57] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_115 (hm_2) from Half(32400,1:8,180,1) to Half(64800,32400,180,1)
[04/25/2025-09:08:57] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_118 (reg_3) from Half(32400,1:8,180,1) to Half(64800,32400,180,1)
[04/25/2025-09:08:57] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_121 (height_3) from Half(32400,1:8,180,1) to Half(32400,32400,180,1)
[04/25/2025-09:08:57] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_124 (dim_3) from Half(32400,1:8,180,1) to Half(97200,32400,180,1)
[04/25/2025-09:08:57] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_127 (rot_3) from Half(32400,1:8,180,1) to Half(64800,32400,180,1)
[04/25/2025-09:08:57] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_130 (vel_3) from Half(32400,1:8,180,1) to Half(64800,32400,180,1)
[04/25/2025-09:08:57] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_133 (hm_3) from Half(32400,1:8,180,1) to Half(32400,32400,180,1)
[04/25/2025-09:08:57] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_136 (reg_4) from Half(32400,1:8,180,1) to Half(64800,32400,180,1)
[04/25/2025-09:08:57] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_139 (height_4) from Half(32400,1:8,180,1) to Half(32400,32400,180,1)
[04/25/2025-09:08:57] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_142 (dim_4) from Half(32400,1:8,180,1) to Half(97200,32400,180,1)
[04/25/2025-09:08:57] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_145 (rot_4) from Half(32400,1:8,180,1) to Half(64800,32400,180,1)
[04/25/2025-09:08:57] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_148 (vel_4) from Half(32400,1:8,180,1) to Half(64800,32400,180,1)
[04/25/2025-09:08:57] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_151 (hm_4) from Half(32400,1:8,180,1) to Half(64800,32400,180,1)
[04/25/2025-09:08:57] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_154 (reg_5) from Half(32400,1:8,180,1) to Half(64800,32400,180,1)
[04/25/2025-09:08:57] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_157 (height_5) from Half(32400,1:8,180,1) to Half(32400,32400,180,1)
[04/25/2025-09:08:57] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_160 (dim_5) from Half(32400,1:8,180,1) to Half(97200,32400,180,1)
[04/25/2025-09:08:57] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_163 (rot_5) from Half(32400,1:8,180,1) to Half(64800,32400,180,1)
[04/25/2025-09:08:57] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_166 (vel_5) from Half(32400,1:8,180,1) to Half(64800,32400,180,1)
[04/25/2025-09:08:57] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to Conv_169 (hm_5) from Half(32400,1:8,180,1) to Half(64800,32400,180,1)
[04/25/2025-09:08:57] [V] [TRT] Formats and tactics selection completed in 16.2842 seconds.
[04/25/2025-09:08:57] [V] [TRT] After reformat layers: 89 layers
[04/25/2025-09:08:57] [V] [TRT] Total number of blocks in pre-optimized block assignment: 53
[04/25/2025-09:08:57] [I] [TRT] Detected 1 inputs and 36 output network tensors.
[04/25/2025-09:08:57] [V] [TRT] Layer: Conv_15 + Relu_16 Host Persistent: 5424 Device Persistent: 0 Scratch Memory: 0
[04/25/2025-09:08:57] [V] [TRT] Layer: Conv_17 + Relu_18 Host Persistent: 5424 Device Persistent: 0 Scratch Memory: 0
[04/25/2025-09:08:57] [V] [TRT] Layer: Conv_19 + Relu_20 Host Persistent: 5424 Device Persistent: 0 Scratch Memory: 0
[04/25/2025-09:08:57] [V] [TRT] Layer: Conv_21 + Relu_22 Host Persistent: 5424 Device Persistent: 0 Scratch Memory: 0
[04/25/2025-09:08:57] [V] [TRT] Layer: Conv_23 + Relu_24 Host Persistent: 5424 Device Persistent: 0 Scratch Memory: 0
[04/25/2025-09:08:57] [V] [TRT] Layer: Conv_25 + Relu_26 Host Persistent: 5424 Device Persistent: 0 Scratch Memory: 0
[04/25/2025-09:08:57] [V] [TRT] Layer: Conv_27 + Relu_28 Host Persistent: 7200 Device Persistent: 0 Scratch Memory: 0
[04/25/2025-09:08:57] [V] [TRT] Layer: Conv_44 + Relu_45 Host Persistent: 4784 Device Persistent: 0 Scratch Memory: 0
[04/25/2025-09:08:57] [V] [TRT] Layer: Conv_46 + Relu_47 Host Persistent: 5424 Device Persistent: 0 Scratch Memory: 0
[04/25/2025-09:08:57] [V] [TRT] Layer: Conv_48 + Relu_49 Host Persistent: 5424 Device Persistent: 0 Scratch Memory: 0
[04/25/2025-09:08:57] [V] [TRT] Layer: Conv_50 + Relu_51 Host Persistent: 5424 Device Persistent: 0 Scratch Memory: 0
[04/25/2025-09:08:57] [V] [TRT] Layer: Conv_52 + Relu_53 Host Persistent: 5424 Device Persistent: 0 Scratch Memory: 0
[04/25/2025-09:08:57] [V] [TRT] Layer: Conv_54 + Relu_55 Host Persistent: 5424 Device Persistent: 0 Scratch Memory: 0
[04/25/2025-09:08:57] [V] [TRT] Layer: ConvTranspose_56 + BatchNormalization_57 + Relu_58 Host Persistent: 4336 Device Persistent: 131584 Scratch Memory: 0
[04/25/2025-09:08:57] [V] [TRT] Layer: Conv_60 + Relu_61 Host Persistent: 5424 Device Persistent: 0 Scratch Memory: 0
[04/25/2025-09:08:57] [V] [TRT] Layer: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Host Persistent: 5424 Device Persistent: 0 Scratch Memory: 0
[04/25/2025-09:08:57] [V] [TRT] Layer: Conv_64 Host Persistent: 5424 Device Persistent: 0 Scratch Memory: 0
[04/25/2025-09:08:57] [V] [TRT] Layer: Conv_67 Host Persistent: 5424 Device Persistent: 0 Scratch Memory: 0
[04/25/2025-09:08:57] [V] [TRT] Layer: Conv_70 Host Persistent: 4784 Device Persistent: 0 Scratch Memory: 0
[04/25/2025-09:08:57] [V] [TRT] Layer: Conv_73 Host Persistent: 5424 Device Persistent: 0 Scratch Memory: 0
[04/25/2025-09:08:57] [V] [TRT] Layer: Conv_76 Host Persistent: 5424 Device Persistent: 0 Scratch Memory: 0
[04/25/2025-09:08:57] [V] [TRT] Layer: Conv_79 Host Persistent: 5424 Device Persistent: 0 Scratch Memory: 0
[04/25/2025-09:08:57] [V] [TRT] Layer: Conv_82 Host Persistent: 5424 Device Persistent: 0 Scratch Memory: 0
[04/25/2025-09:08:57] [V] [TRT] Layer: Conv_85 Host Persistent: 5424 Device Persistent: 0 Scratch Memory: 0
[04/25/2025-09:08:57] [V] [TRT] Layer: Conv_88 Host Persistent: 4784 Device Persistent: 0 Scratch Memory: 0
[04/25/2025-09:08:57] [V] [TRT] Layer: Conv_91 Host Persistent: 5424 Device Persistent: 0 Scratch Memory: 0
[04/25/2025-09:08:57] [V] [TRT] Layer: Conv_94 Host Persistent: 5424 Device Persistent: 0 Scratch Memory: 0
[04/25/2025-09:08:57] [V] [TRT] Layer: Conv_97 Host Persistent: 5424 Device Persistent: 0 Scratch Memory: 0
[04/25/2025-09:08:57] [V] [TRT] Layer: Conv_100 Host Persistent: 5424 Device Persistent: 0 Scratch Memory: 0
[04/25/2025-09:08:57] [V] [TRT] Layer: Conv_103 Host Persistent: 5424 Device Persistent: 0 Scratch Memory: 0
[04/25/2025-09:08:57] [V] [TRT] Layer: Conv_106 Host Persistent: 4784 Device Persistent: 0 Scratch Memory: 0
[04/25/2025-09:08:57] [V] [TRT] Layer: Conv_109 Host Persistent: 5424 Device Persistent: 0 Scratch Memory: 0
[04/25/2025-09:08:57] [V] [TRT] Layer: Conv_112 Host Persistent: 5424 Device Persistent: 0 Scratch Memory: 0
[04/25/2025-09:08:57] [V] [TRT] Layer: Conv_115 Host Persistent: 5424 Device Persistent: 0 Scratch Memory: 0
[04/25/2025-09:08:57] [V] [TRT] Layer: Conv_118 Host Persistent: 5424 Device Persistent: 0 Scratch Memory: 0
[04/25/2025-09:08:57] [V] [TRT] Layer: Conv_121 Host Persistent: 5424 Device Persistent: 0 Scratch Memory: 0
[04/25/2025-09:08:57] [V] [TRT] Layer: Conv_124 Host Persistent: 4784 Device Persistent: 0 Scratch Memory: 0
[04/25/2025-09:08:57] [V] [TRT] Layer: Conv_127 Host Persistent: 5424 Device Persistent: 0 Scratch Memory: 0
[04/25/2025-09:08:57] [V] [TRT] Layer: Conv_130 Host Persistent: 5424 Device Persistent: 0 Scratch Memory: 0
[04/25/2025-09:08:57] [V] [TRT] Layer: Conv_133 Host Persistent: 5424 Device Persistent: 0 Scratch Memory: 0
[04/25/2025-09:08:57] [V] [TRT] Layer: Conv_136 Host Persistent: 5424 Device Persistent: 0 Scratch Memory: 0
[04/25/2025-09:08:57] [V] [TRT] Layer: Conv_139 Host Persistent: 5424 Device Persistent: 0 Scratch Memory: 0
[04/25/2025-09:08:57] [V] [TRT] Layer: Conv_142 Host Persistent: 4784 Device Persistent: 0 Scratch Memory: 0
[04/25/2025-09:08:57] [V] [TRT] Layer: Conv_145 Host Persistent: 5424 Device Persistent: 0 Scratch Memory: 0
[04/25/2025-09:08:57] [V] [TRT] Layer: Conv_148 Host Persistent: 5424 Device Persistent: 0 Scratch Memory: 0
[04/25/2025-09:08:57] [V] [TRT] Layer: Conv_151 Host Persistent: 5424 Device Persistent: 0 Scratch Memory: 0
[04/25/2025-09:08:57] [V] [TRT] Layer: Conv_154 Host Persistent: 5424 Device Persistent: 0 Scratch Memory: 0
[04/25/2025-09:08:57] [V] [TRT] Layer: Conv_157 Host Persistent: 5424 Device Persistent: 0 Scratch Memory: 0
[04/25/2025-09:08:57] [V] [TRT] Layer: Conv_160 Host Persistent: 4784 Device Persistent: 0 Scratch Memory: 0
[04/25/2025-09:08:57] [V] [TRT] Layer: Conv_163 Host Persistent: 5424 Device Persistent: 0 Scratch Memory: 0
[04/25/2025-09:08:57] [V] [TRT] Layer: Conv_166 Host Persistent: 5424 Device Persistent: 0 Scratch Memory: 0
[04/25/2025-09:08:57] [V] [TRT] Layer: Conv_169 Host Persistent: 5424 Device Persistent: 0 Scratch Memory: 0
[04/25/2025-09:08:57] [V] [TRT] Skipped printing memory information for 37 layers with 0 memory size i.e. Host Persistent + Device Persistent + Scratch Memory == 0.
[04/25/2025-09:08:57] [I] [TRT] Total Host Persistent Memory: 278256
[04/25/2025-09:08:57] [I] [TRT] Total Device Persistent Memory: 131584
[04/25/2025-09:08:57] [I] [TRT] Total Scratch Memory: 0
[04/25/2025-09:08:57] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 19 MiB, GPU 570 MiB
[04/25/2025-09:08:57] [I] [TRT] [BlockAssignment] Started assigning block shifts. This will take 52 steps to complete.
[04/25/2025-09:08:57] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 0.275387ms to assign 3 blocks to 52 nodes requiring 165888000 bytes.
[04/25/2025-09:08:57] [V] [TRT] Total number of blocks in optimized block assignment: 3
[04/25/2025-09:08:57] [I] [TRT] Total Activation Memory: 165888000
[04/25/2025-09:08:57] [V] [TRT] Finalize: Conv_15 + Relu_16 Set kernel index: 0
[04/25/2025-09:08:57] [V] [TRT] Finalize: Conv_17 + Relu_18 Set kernel index: 1
[04/25/2025-09:08:57] [V] [TRT] Finalize: Conv_19 + Relu_20 Set kernel index: 1
[04/25/2025-09:08:57] [V] [TRT] Finalize: Conv_21 + Relu_22 Set kernel index: 1
[04/25/2025-09:08:57] [V] [TRT] Finalize: Conv_23 + Relu_24 Set kernel index: 1
[04/25/2025-09:08:57] [V] [TRT] Finalize: Conv_25 + Relu_26 Set kernel index: 1
[04/25/2025-09:08:57] [V] [TRT] Finalize: Conv_27 + Relu_28 Set kernel index: 2
[04/25/2025-09:08:57] [V] [TRT] Finalize: Conv_44 + Relu_45 Set kernel index: 3
[04/25/2025-09:08:57] [V] [TRT] Finalize: Conv_46 + Relu_47 Set kernel index: 4
[04/25/2025-09:08:57] [V] [TRT] Finalize: Conv_48 + Relu_49 Set kernel index: 4
[04/25/2025-09:08:57] [V] [TRT] Finalize: Conv_50 + Relu_51 Set kernel index: 4
[04/25/2025-09:08:57] [V] [TRT] Finalize: Conv_52 + Relu_53 Set kernel index: 4
[04/25/2025-09:08:57] [V] [TRT] Finalize: Conv_54 + Relu_55 Set kernel index: 4
[04/25/2025-09:08:57] [V] [TRT] Finalize: ConvTranspose_56 + BatchNormalization_57 + Relu_58 Set kernel index: 5
[04/25/2025-09:08:57] [V] [TRT] Finalize: Conv_60 + Relu_61 Set kernel index: 6
[04/25/2025-09:08:57] [V] [TRT] Finalize: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 Set kernel index: 1
[04/25/2025-09:08:57] [V] [TRT] Finalize: Conv_64 Set kernel index: 7
[04/25/2025-09:08:57] [V] [TRT] Finalize: Conv_67 Set kernel index: 8
[04/25/2025-09:08:57] [V] [TRT] Finalize: Conv_70 Set kernel index: 9
[04/25/2025-09:08:57] [V] [TRT] Finalize: Conv_73 Set kernel index: 7
[04/25/2025-09:08:57] [V] [TRT] Finalize: Conv_76 Set kernel index: 7
[04/25/2025-09:08:57] [V] [TRT] Finalize: Conv_79 Set kernel index: 8
[04/25/2025-09:08:57] [V] [TRT] Finalize: Conv_82 Set kernel index: 7
[04/25/2025-09:08:57] [V] [TRT] Finalize: Conv_85 Set kernel index: 8
[04/25/2025-09:08:57] [V] [TRT] Finalize: Conv_88 Set kernel index: 9
[04/25/2025-09:08:57] [V] [TRT] Finalize: Conv_91 Set kernel index: 7
[04/25/2025-09:08:57] [V] [TRT] Finalize: Conv_94 Set kernel index: 7
[04/25/2025-09:08:57] [V] [TRT] Finalize: Conv_97 Set kernel index: 7
[04/25/2025-09:08:57] [V] [TRT] Finalize: Conv_100 Set kernel index: 7
[04/25/2025-09:08:57] [V] [TRT] Finalize: Conv_103 Set kernel index: 8
[04/25/2025-09:08:57] [V] [TRT] Finalize: Conv_106 Set kernel index: 9
[04/25/2025-09:08:57] [V] [TRT] Finalize: Conv_109 Set kernel index: 7
[04/25/2025-09:08:57] [V] [TRT] Finalize: Conv_112 Set kernel index: 7
[04/25/2025-09:08:57] [V] [TRT] Finalize: Conv_115 Set kernel index: 7
[04/25/2025-09:08:57] [V] [TRT] Finalize: Conv_118 Set kernel index: 7
[04/25/2025-09:08:57] [V] [TRT] Finalize: Conv_121 Set kernel index: 8
[04/25/2025-09:08:57] [V] [TRT] Finalize: Conv_124 Set kernel index: 9
[04/25/2025-09:08:57] [V] [TRT] Finalize: Conv_127 Set kernel index: 7
[04/25/2025-09:08:57] [V] [TRT] Finalize: Conv_130 Set kernel index: 7
[04/25/2025-09:08:57] [V] [TRT] Finalize: Conv_133 Set kernel index: 8
[04/25/2025-09:08:57] [V] [TRT] Finalize: Conv_136 Set kernel index: 7
[04/25/2025-09:08:57] [V] [TRT] Finalize: Conv_139 Set kernel index: 8
[04/25/2025-09:08:57] [V] [TRT] Finalize: Conv_142 Set kernel index: 9
[04/25/2025-09:08:57] [V] [TRT] Finalize: Conv_145 Set kernel index: 7
[04/25/2025-09:08:57] [V] [TRT] Finalize: Conv_148 Set kernel index: 7
[04/25/2025-09:08:57] [V] [TRT] Finalize: Conv_151 Set kernel index: 7
[04/25/2025-09:08:57] [V] [TRT] Finalize: Conv_154 Set kernel index: 7
[04/25/2025-09:08:57] [V] [TRT] Finalize: Conv_157 Set kernel index: 8
[04/25/2025-09:08:57] [V] [TRT] Finalize: Conv_160 Set kernel index: 9
[04/25/2025-09:08:57] [V] [TRT] Finalize: Conv_163 Set kernel index: 7
[04/25/2025-09:08:57] [V] [TRT] Finalize: Conv_166 Set kernel index: 7
[04/25/2025-09:08:57] [V] [TRT] Finalize: Conv_169 Set kernel index: 7
[04/25/2025-09:08:57] [V] [TRT] Total number of generated kernels selected for the engine: 10
[04/25/2025-09:08:57] [V] [TRT] Kernel: 0 CASK_STATIC
[04/25/2025-09:08:57] [V] [TRT] Kernel: 1 CASK_STATIC
[04/25/2025-09:08:57] [V] [TRT] Kernel: 2 CASK_STATIC
[04/25/2025-09:08:57] [V] [TRT] Kernel: 3 CASK_STATIC
[04/25/2025-09:08:57] [V] [TRT] Kernel: 4 CASK_STATIC
[04/25/2025-09:08:57] [V] [TRT] Kernel: 5 CASK_STATIC
[04/25/2025-09:08:57] [V] [TRT] Kernel: 6 CASK_STATIC
[04/25/2025-09:08:57] [V] [TRT] Kernel: 7 CASK_STATIC
[04/25/2025-09:08:57] [V] [TRT] Kernel: 8 CASK_STATIC
[04/25/2025-09:08:57] [V] [TRT] Kernel: 9 CASK_STATIC
[04/25/2025-09:08:57] [V] [TRT] Disabling unused tactic source: JIT_CONVOLUTIONS
[04/25/2025-09:08:57] [V] [TRT] Engine generation completed in 16.5224 seconds.
[04/25/2025-09:08:57] [W] [TRT] TensorRT encountered issues when converting weights between types and that could affect accuracy.
[04/25/2025-09:08:57] [W] [TRT] If this is not the desired behavior, please modify the weights or retrain with regularization to adjust the magnitude of the weights.
[04/25/2025-09:08:57] [W] [TRT] Check verbose logs for the list of affected weights.
[04/25/2025-09:08:57] [W] [TRT] - 24 weights are affected by this issue: Detected subnormal FP16 values.
[04/25/2025-09:08:57] [V] [TRT]   List of affected weights: ConvTranspose_56 + BatchNormalization_57 + Relu_58.weight, Conv_100.weight, Conv_124.weight, Conv_127.weight, Conv_145.weight, Conv_15 + Relu_16.weight, Conv_163.weight, Conv_17 + Relu_18.weight, Conv_19 + Relu_20.weight, Conv_21 + Relu_22.weight, Conv_23 + Relu_24.weight, Conv_25 + Relu_26.weight, Conv_27 + Relu_28.weight, Conv_44 + Relu_45.weight, Conv_46 + Relu_47.weight, Conv_48 + Relu_49.weight, Conv_50 + Relu_51.weight, Conv_52 + Relu_53.weight, Conv_54 + Relu_55.weight, Conv_60 + Relu_61.weight, Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168.bias, Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168.weight, Conv_73.weight, Conv_88.weight
[04/25/2025-09:08:57] [W] [TRT] - 13 weights are affected by this issue: Detected values less than smallest positive FP16 subnormal value and converted them to the FP16 minimum subnormalized value.
[04/25/2025-09:08:57] [V] [TRT]   List of affected weights: Conv_112.bias, Conv_130.bias, Conv_148.bias, Conv_166.bias, Conv_21 + Relu_22.weight, Conv_23 + Relu_24.weight, Conv_46 + Relu_47.weight, Conv_50 + Relu_51.weight, Conv_52 + Relu_53.weight, Conv_60 + Relu_61.weight, Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168.weight, Conv_76.bias, Conv_94.bias
[04/25/2025-09:08:57] [V] [TRT] Deleting timing cache: 381 entries, served 2542 hits since creation.
[04/25/2025-09:08:57] [V] [TRT] Engine Layer Information:
Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to Conv_15 + Relu_16, Tactic: 0x00000000000003ea, input (Half[1,256,180,180]) -> Reformatted Input Tensor 0 to Conv_15 + Relu_16 (Half[1,256:8,180,180])
Layer(CaskConvolution): Conv_15 + Relu_16, Tactic: 0x60da8c7151d91e47, Reformatted Input Tensor 0 to Conv_15 + Relu_16 (Half[1,256:8,180,180]) -> input.12 (Half[1,128:8,180,180])
Layer(CaskConvolution): Conv_17 + Relu_18, Tactic: 0x048d6d0400f33439, input.12 (Half[1,128:8,180,180]) -> input.24 (Half[1,128:8,180,180])
Layer(CaskConvolution): Conv_19 + Relu_20, Tactic: 0x048d6d0400f33439, input.24 (Half[1,128:8,180,180]) -> input.36 (Half[1,128:8,180,180])
Layer(CaskConvolution): Conv_21 + Relu_22, Tactic: 0x048d6d0400f33439, input.36 (Half[1,128:8,180,180]) -> input.48 (Half[1,128:8,180,180])
Layer(CaskConvolution): Conv_23 + Relu_24, Tactic: 0x048d6d0400f33439, input.48 (Half[1,128:8,180,180]) -> input.60 (Half[1,128:8,180,180])
Layer(CaskConvolution): Conv_25 + Relu_26, Tactic: 0x048d6d0400f33439, input.60 (Half[1,128:8,180,180]) -> input.72 (Half[1,128:8,180,180])
Layer(CaskGemmConvolution): Conv_27 + Relu_28, Tactic: 0x000000000002008e, input.72 (Half[1,128:8,180,180]) -> input.164 (Half[1,256:8,180,180])
Layer(CaskConvolution): Conv_44 + Relu_45, Tactic: 0x0e07ff4f4f7c1ac9, input.72 (Half[1,128:8,180,180]) -> input.96 (Half[1,256:8,90,90])
Layer(CaskConvolution): Conv_46 + Relu_47, Tactic: 0x245530c34bd6090f, input.96 (Half[1,256:8,90,90]) -> input.108 (Half[1,256:8,90,90])
Layer(CaskConvolution): Conv_48 + Relu_49, Tactic: 0x245530c34bd6090f, input.108 (Half[1,256:8,90,90]) -> input.120 (Half[1,256:8,90,90])
Layer(CaskConvolution): Conv_50 + Relu_51, Tactic: 0x245530c34bd6090f, input.120 (Half[1,256:8,90,90]) -> input.132 (Half[1,256:8,90,90])
Layer(CaskConvolution): Conv_52 + Relu_53, Tactic: 0x245530c34bd6090f, input.132 (Half[1,256:8,90,90]) -> input.144 (Half[1,256:8,90,90])
Layer(CaskConvolution): Conv_54 + Relu_55, Tactic: 0x245530c34bd6090f, input.144 (Half[1,256:8,90,90]) -> onnx::ConvTranspose_644 (Half[1,256:8,90,90])
Layer(CaskDeconvolutionV2): ConvTranspose_56 + BatchNormalization_57 + Relu_58, Tactic: 0xdec24e75875e331b, onnx::ConvTranspose_644 (Half[1,256:8,90,90]) -> input.164 (Half[1,256:8,180,180])
Layer(CaskConvolution): Conv_60 + Relu_61, Tactic: 0x263a38afd75e3a43, input.164 (Half[1,512:8,180,180]) -> onnx::Conv_651 (Half[1,64:8,180,180])
Layer(CaskConvolution): Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168, Tactic: 0x048d6d0400f33439, onnx::Conv_651 (Half[1,64:8,180,180]) -> Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (Half[1,2304:8,180,180])
Layer(CaskConvolution): Conv_64, Tactic: 0xa83b68f30462f971, Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (Half[1,64:8,180,180]) -> Reformatted Output Tensor 0 to Conv_64 (Half[1,2:8,180,180])
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_64, Tactic: 0x0000000000000000, Reformatted Output Tensor 0 to Conv_64 (Half[1,2:8,180,180]) -> reg_0 (Half[1,2,180,180])
Layer(CaskConvolution): Conv_67, Tactic: 0xa40cb43c296a36a8, Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (Half[1,64:8,180,180]) -> Reformatted Output Tensor 0 to Conv_67 (Half[1,1:8,180,180])
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_67, Tactic: 0x0000000000000000, Reformatted Output Tensor 0 to Conv_67 (Half[1,1:8,180,180]) -> height_0 (Half[1,1,180,180])
Layer(CaskConvolution): Conv_70, Tactic: 0xdce100b9fe609424, Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (Half[1,64:8,180,180]) -> Reformatted Output Tensor 0 to Conv_70 (Half[1,3:8,180,180])
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_70, Tactic: 0x0000000000000000, Reformatted Output Tensor 0 to Conv_70 (Half[1,3:8,180,180]) -> dim_0 (Half[1,3,180,180])
Layer(CaskConvolution): Conv_73, Tactic: 0xa83b68f30462f971, Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (Half[1,64:8,180,180]) -> Reformatted Output Tensor 0 to Conv_73 (Half[1,2:8,180,180])
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_73, Tactic: 0x0000000000000000, Reformatted Output Tensor 0 to Conv_73 (Half[1,2:8,180,180]) -> rot_0 (Half[1,2,180,180])
Layer(CaskConvolution): Conv_76, Tactic: 0xa83b68f30462f971, Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (Half[1,64:8,180,180]) -> Reformatted Output Tensor 0 to Conv_76 (Half[1,2:8,180,180])
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_76, Tactic: 0x0000000000000000, Reformatted Output Tensor 0 to Conv_76 (Half[1,2:8,180,180]) -> vel_0 (Half[1,2,180,180])
Layer(CaskConvolution): Conv_79, Tactic: 0xa40cb43c296a36a8, Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (Half[1,64:8,180,180]) -> Reformatted Output Tensor 0 to Conv_79 (Half[1,1:8,180,180])
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_79, Tactic: 0x0000000000000000, Reformatted Output Tensor 0 to Conv_79 (Half[1,1:8,180,180]) -> hm_0 (Half[1,1,180,180])
Layer(CaskConvolution): Conv_82, Tactic: 0xa83b68f30462f971, Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (Half[1,64:8,180,180]) -> Reformatted Output Tensor 0 to Conv_82 (Half[1,2:8,180,180])
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_82, Tactic: 0x0000000000000000, Reformatted Output Tensor 0 to Conv_82 (Half[1,2:8,180,180]) -> reg_1 (Half[1,2,180,180])
Layer(CaskConvolution): Conv_85, Tactic: 0xa40cb43c296a36a8, Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (Half[1,64:8,180,180]) -> Reformatted Output Tensor 0 to Conv_85 (Half[1,1:8,180,180])
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_85, Tactic: 0x0000000000000000, Reformatted Output Tensor 0 to Conv_85 (Half[1,1:8,180,180]) -> height_1 (Half[1,1,180,180])
Layer(CaskConvolution): Conv_88, Tactic: 0xdce100b9fe609424, Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (Half[1,64:8,180,180]) -> Reformatted Output Tensor 0 to Conv_88 (Half[1,3:8,180,180])
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_88, Tactic: 0x0000000000000000, Reformatted Output Tensor 0 to Conv_88 (Half[1,3:8,180,180]) -> dim_1 (Half[1,3,180,180])
Layer(CaskConvolution): Conv_91, Tactic: 0xa83b68f30462f971, Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (Half[1,64:8,180,180]) -> Reformatted Output Tensor 0 to Conv_91 (Half[1,2:8,180,180])
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_91, Tactic: 0x0000000000000000, Reformatted Output Tensor 0 to Conv_91 (Half[1,2:8,180,180]) -> rot_1 (Half[1,2,180,180])
Layer(CaskConvolution): Conv_94, Tactic: 0xa83b68f30462f971, Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (Half[1,64:8,180,180]) -> Reformatted Output Tensor 0 to Conv_94 (Half[1,2:8,180,180])
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_94, Tactic: 0x0000000000000000, Reformatted Output Tensor 0 to Conv_94 (Half[1,2:8,180,180]) -> vel_1 (Half[1,2,180,180])
Layer(CaskConvolution): Conv_97, Tactic: 0xa83b68f30462f971, Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (Half[1,64:8,180,180]) -> Reformatted Output Tensor 0 to Conv_97 (Half[1,2:8,180,180])
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_97, Tactic: 0x0000000000000000, Reformatted Output Tensor 0 to Conv_97 (Half[1,2:8,180,180]) -> hm_1 (Half[1,2,180,180])
Layer(CaskConvolution): Conv_100, Tactic: 0xa83b68f30462f971, Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (Half[1,64:8,180,180]) -> Reformatted Output Tensor 0 to Conv_100 (Half[1,2:8,180,180])
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_100, Tactic: 0x0000000000000000, Reformatted Output Tensor 0 to Conv_100 (Half[1,2:8,180,180]) -> reg_2 (Half[1,2,180,180])
Layer(CaskConvolution): Conv_103, Tactic: 0xa40cb43c296a36a8, Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (Half[1,64:8,180,180]) -> Reformatted Output Tensor 0 to Conv_103 (Half[1,1:8,180,180])
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_103, Tactic: 0x0000000000000000, Reformatted Output Tensor 0 to Conv_103 (Half[1,1:8,180,180]) -> height_2 (Half[1,1,180,180])
Layer(CaskConvolution): Conv_106, Tactic: 0xdce100b9fe609424, Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (Half[1,64:8,180,180]) -> Reformatted Output Tensor 0 to Conv_106 (Half[1,3:8,180,180])
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_106, Tactic: 0x0000000000000000, Reformatted Output Tensor 0 to Conv_106 (Half[1,3:8,180,180]) -> dim_2 (Half[1,3,180,180])
Layer(CaskConvolution): Conv_109, Tactic: 0xa83b68f30462f971, Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (Half[1,64:8,180,180]) -> Reformatted Output Tensor 0 to Conv_109 (Half[1,2:8,180,180])
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_109, Tactic: 0x0000000000000000, Reformatted Output Tensor 0 to Conv_109 (Half[1,2:8,180,180]) -> rot_2 (Half[1,2,180,180])
Layer(CaskConvolution): Conv_112, Tactic: 0xa83b68f30462f971, Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (Half[1,64:8,180,180]) -> Reformatted Output Tensor 0 to Conv_112 (Half[1,2:8,180,180])
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_112, Tactic: 0x0000000000000000, Reformatted Output Tensor 0 to Conv_112 (Half[1,2:8,180,180]) -> vel_2 (Half[1,2,180,180])
Layer(CaskConvolution): Conv_115, Tactic: 0xa83b68f30462f971, Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (Half[1,64:8,180,180]) -> Reformatted Output Tensor 0 to Conv_115 (Half[1,2:8,180,180])
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_115, Tactic: 0x0000000000000000, Reformatted Output Tensor 0 to Conv_115 (Half[1,2:8,180,180]) -> hm_2 (Half[1,2,180,180])
Layer(CaskConvolution): Conv_118, Tactic: 0xa83b68f30462f971, Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (Half[1,64:8,180,180]) -> Reformatted Output Tensor 0 to Conv_118 (Half[1,2:8,180,180])
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_118, Tactic: 0x0000000000000000, Reformatted Output Tensor 0 to Conv_118 (Half[1,2:8,180,180]) -> reg_3 (Half[1,2,180,180])
Layer(CaskConvolution): Conv_121, Tactic: 0xa40cb43c296a36a8, Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (Half[1,64:8,180,180]) -> Reformatted Output Tensor 0 to Conv_121 (Half[1,1:8,180,180])
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_121, Tactic: 0x0000000000000000, Reformatted Output Tensor 0 to Conv_121 (Half[1,1:8,180,180]) -> height_3 (Half[1,1,180,180])
Layer(CaskConvolution): Conv_124, Tactic: 0xdce100b9fe609424, Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (Half[1,64:8,180,180]) -> Reformatted Output Tensor 0 to Conv_124 (Half[1,3:8,180,180])
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_124, Tactic: 0x0000000000000000, Reformatted Output Tensor 0 to Conv_124 (Half[1,3:8,180,180]) -> dim_3 (Half[1,3,180,180])
Layer(CaskConvolution): Conv_127, Tactic: 0xa83b68f30462f971, Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (Half[1,64:8,180,180]) -> Reformatted Output Tensor 0 to Conv_127 (Half[1,2:8,180,180])
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_127, Tactic: 0x0000000000000000, Reformatted Output Tensor 0 to Conv_127 (Half[1,2:8,180,180]) -> rot_3 (Half[1,2,180,180])
Layer(CaskConvolution): Conv_130, Tactic: 0xa83b68f30462f971, Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (Half[1,64:8,180,180]) -> Reformatted Output Tensor 0 to Conv_130 (Half[1,2:8,180,180])
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_130, Tactic: 0x0000000000000000, Reformatted Output Tensor 0 to Conv_130 (Half[1,2:8,180,180]) -> vel_3 (Half[1,2,180,180])
Layer(CaskConvolution): Conv_133, Tactic: 0xa40cb43c296a36a8, Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (Half[1,64:8,180,180]) -> Reformatted Output Tensor 0 to Conv_133 (Half[1,1:8,180,180])
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_133, Tactic: 0x0000000000000000, Reformatted Output Tensor 0 to Conv_133 (Half[1,1:8,180,180]) -> hm_3 (Half[1,1,180,180])
Layer(CaskConvolution): Conv_136, Tactic: 0xa83b68f30462f971, Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (Half[1,64:8,180,180]) -> Reformatted Output Tensor 0 to Conv_136 (Half[1,2:8,180,180])
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_136, Tactic: 0x0000000000000000, Reformatted Output Tensor 0 to Conv_136 (Half[1,2:8,180,180]) -> reg_4 (Half[1,2,180,180])
Layer(CaskConvolution): Conv_139, Tactic: 0xa40cb43c296a36a8, Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (Half[1,64:8,180,180]) -> Reformatted Output Tensor 0 to Conv_139 (Half[1,1:8,180,180])
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_139, Tactic: 0x0000000000000000, Reformatted Output Tensor 0 to Conv_139 (Half[1,1:8,180,180]) -> height_4 (Half[1,1,180,180])
Layer(CaskConvolution): Conv_142, Tactic: 0xdce100b9fe609424, Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (Half[1,64:8,180,180]) -> Reformatted Output Tensor 0 to Conv_142 (Half[1,3:8,180,180])
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_142, Tactic: 0x0000000000000000, Reformatted Output Tensor 0 to Conv_142 (Half[1,3:8,180,180]) -> dim_4 (Half[1,3,180,180])
Layer(CaskConvolution): Conv_145, Tactic: 0xa83b68f30462f971, Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (Half[1,64:8,180,180]) -> Reformatted Output Tensor 0 to Conv_145 (Half[1,2:8,180,180])
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_145, Tactic: 0x0000000000000000, Reformatted Output Tensor 0 to Conv_145 (Half[1,2:8,180,180]) -> rot_4 (Half[1,2,180,180])
Layer(CaskConvolution): Conv_148, Tactic: 0xa83b68f30462f971, Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (Half[1,64:8,180,180]) -> Reformatted Output Tensor 0 to Conv_148 (Half[1,2:8,180,180])
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_148, Tactic: 0x0000000000000000, Reformatted Output Tensor 0 to Conv_148 (Half[1,2:8,180,180]) -> vel_4 (Half[1,2,180,180])
Layer(CaskConvolution): Conv_151, Tactic: 0xa83b68f30462f971, Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (Half[1,64:8,180,180]) -> Reformatted Output Tensor 0 to Conv_151 (Half[1,2:8,180,180])
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_151, Tactic: 0x0000000000000000, Reformatted Output Tensor 0 to Conv_151 (Half[1,2:8,180,180]) -> hm_4 (Half[1,2,180,180])
Layer(CaskConvolution): Conv_154, Tactic: 0xa83b68f30462f971, Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (Half[1,64:8,180,180]) -> Reformatted Output Tensor 0 to Conv_154 (Half[1,2:8,180,180])
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_154, Tactic: 0x0000000000000000, Reformatted Output Tensor 0 to Conv_154 (Half[1,2:8,180,180]) -> reg_5 (Half[1,2,180,180])
Layer(CaskConvolution): Conv_157, Tactic: 0xa40cb43c296a36a8, Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (Half[1,64:8,180,180]) -> Reformatted Output Tensor 0 to Conv_157 (Half[1,1:8,180,180])
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_157, Tactic: 0x0000000000000000, Reformatted Output Tensor 0 to Conv_157 (Half[1,1:8,180,180]) -> height_5 (Half[1,1,180,180])
Layer(CaskConvolution): Conv_160, Tactic: 0xdce100b9fe609424, Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (Half[1,64:8,180,180]) -> Reformatted Output Tensor 0 to Conv_160 (Half[1,3:8,180,180])
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_160, Tactic: 0x0000000000000000, Reformatted Output Tensor 0 to Conv_160 (Half[1,3:8,180,180]) -> dim_5 (Half[1,3,180,180])
Layer(CaskConvolution): Conv_163, Tactic: 0xa83b68f30462f971, Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (Half[1,64:8,180,180]) -> Reformatted Output Tensor 0 to Conv_163 (Half[1,2:8,180,180])
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_163, Tactic: 0x0000000000000000, Reformatted Output Tensor 0 to Conv_163 (Half[1,2:8,180,180]) -> rot_5 (Half[1,2,180,180])
Layer(CaskConvolution): Conv_166, Tactic: 0xa83b68f30462f971, Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (Half[1,64:8,180,180]) -> Reformatted Output Tensor 0 to Conv_166 (Half[1,2:8,180,180])
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_166, Tactic: 0x0000000000000000, Reformatted Output Tensor 0 to Conv_166 (Half[1,2:8,180,180]) -> vel_5 (Half[1,2,180,180])
Layer(CaskConvolution): Conv_169, Tactic: 0xa83b68f30462f971, Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168 (Half[1,64:8,180,180]) -> Reformatted Output Tensor 0 to Conv_169 (Half[1,2:8,180,180])
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to Conv_169, Tactic: 0x0000000000000000, Reformatted Output Tensor 0 to Conv_169 (Half[1,2:8,180,180]) -> hm_5 (Half[1,2,180,180])
[04/25/2025-09:08:57] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +11, GPU +13, now: CPU 11, GPU 13 (MiB)
[04/25/2025-09:08:57] [V] [TRT] Adding 1 engine(s) to plan file.
[04/25/2025-09:08:57] [I] Engine built in 25.1991 sec.
[04/25/2025-09:08:57] [I] [TRT] Loaded engine size: 13 MiB
[04/25/2025-09:08:57] [V] [TRT] Deserialization required 8967 microseconds.
[04/25/2025-09:08:57] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +12, now: CPU 0, GPU 12 (MiB)
[04/25/2025-09:08:57] [I] Engine deserialized in 0.0125248 sec.
[04/25/2025-09:08:57] [V] [TRT] Total per-runner device persistent memory is 131584
[04/25/2025-09:08:57] [V] [TRT] Total per-runner host persistent memory is 278256
[04/25/2025-09:08:57] [V] [TRT] Allocated activation device memory of size 165888000
[04/25/2025-09:08:57] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +158, now: CPU 0, GPU 170 (MiB)
[04/25/2025-09:08:57] [V] [TRT] CUDA lazy loading is enabled.
[04/25/2025-09:08:57] [I] Setting persistentCacheLimit to 0 bytes.
[04/25/2025-09:08:57] [V] Using enqueueV3.
[04/25/2025-09:08:57] [I] Using random values for input input
[04/25/2025-09:08:58] [I] Input binding for input with dimensions 1x256x180x180 is created.
[04/25/2025-09:08:58] [I] Output binding for reg_0 with dimensions 1x2x180x180 is created.
[04/25/2025-09:08:58] [I] Output binding for height_0 with dimensions 1x1x180x180 is created.
[04/25/2025-09:08:58] [I] Output binding for dim_0 with dimensions 1x3x180x180 is created.
[04/25/2025-09:08:58] [I] Output binding for rot_0 with dimensions 1x2x180x180 is created.
[04/25/2025-09:08:58] [I] Output binding for vel_0 with dimensions 1x2x180x180 is created.
[04/25/2025-09:08:58] [I] Output binding for hm_0 with dimensions 1x1x180x180 is created.
[04/25/2025-09:08:58] [I] Output binding for reg_1 with dimensions 1x2x180x180 is created.
[04/25/2025-09:08:58] [I] Output binding for height_1 with dimensions 1x1x180x180 is created.
[04/25/2025-09:08:58] [I] Output binding for dim_1 with dimensions 1x3x180x180 is created.
[04/25/2025-09:08:58] [I] Output binding for rot_1 with dimensions 1x2x180x180 is created.
[04/25/2025-09:08:58] [I] Output binding for vel_1 with dimensions 1x2x180x180 is created.
[04/25/2025-09:08:58] [I] Output binding for hm_1 with dimensions 1x2x180x180 is created.
[04/25/2025-09:08:58] [I] Output binding for reg_2 with dimensions 1x2x180x180 is created.
[04/25/2025-09:08:58] [I] Output binding for height_2 with dimensions 1x1x180x180 is created.
[04/25/2025-09:08:58] [I] Output binding for dim_2 with dimensions 1x3x180x180 is created.
[04/25/2025-09:08:58] [I] Output binding for rot_2 with dimensions 1x2x180x180 is created.
[04/25/2025-09:08:58] [I] Output binding for vel_2 with dimensions 1x2x180x180 is created.
[04/25/2025-09:08:58] [I] Output binding for hm_2 with dimensions 1x2x180x180 is created.
[04/25/2025-09:08:58] [I] Output binding for reg_3 with dimensions 1x2x180x180 is created.
[04/25/2025-09:08:58] [I] Output binding for height_3 with dimensions 1x1x180x180 is created.
[04/25/2025-09:08:58] [I] Output binding for dim_3 with dimensions 1x3x180x180 is created.
[04/25/2025-09:08:58] [I] Output binding for rot_3 with dimensions 1x2x180x180 is created.
[04/25/2025-09:08:58] [I] Output binding for vel_3 with dimensions 1x2x180x180 is created.
[04/25/2025-09:08:58] [I] Output binding for hm_3 with dimensions 1x1x180x180 is created.
[04/25/2025-09:08:58] [I] Output binding for reg_4 with dimensions 1x2x180x180 is created.
[04/25/2025-09:08:58] [I] Output binding for height_4 with dimensions 1x1x180x180 is created.
[04/25/2025-09:08:58] [I] Output binding for dim_4 with dimensions 1x3x180x180 is created.
[04/25/2025-09:08:58] [I] Output binding for rot_4 with dimensions 1x2x180x180 is created.
[04/25/2025-09:08:58] [I] Output binding for vel_4 with dimensions 1x2x180x180 is created.
[04/25/2025-09:08:58] [I] Output binding for hm_4 with dimensions 1x2x180x180 is created.
[04/25/2025-09:08:58] [I] Output binding for reg_5 with dimensions 1x2x180x180 is created.
[04/25/2025-09:08:58] [I] Output binding for height_5 with dimensions 1x1x180x180 is created.
[04/25/2025-09:08:58] [I] Output binding for dim_5 with dimensions 1x3x180x180 is created.
[04/25/2025-09:08:58] [I] Output binding for rot_5 with dimensions 1x2x180x180 is created.
[04/25/2025-09:08:58] [I] Output binding for vel_5 with dimensions 1x2x180x180 is created.
[04/25/2025-09:08:58] [I] Output binding for hm_5 with dimensions 1x2x180x180 is created.
[04/25/2025-09:08:58] [I] Layer Information:
[04/25/2025-09:08:58] [I] Layers:
Name: Reformatting CopyNode for Input Tensor 0 to Conv_15 + Relu_16, LayerType: Reformat, Inputs: [ { Name: input, Location: Device, Dimensions: [1,256,180,180], Format/Datatype: Row major linear FP16 format }], Outputs: [ { Name: Reformatted Input Tensor 0 to Conv_15 + Relu_16, Location: Device, Dimensions: [1,256,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x00000000000003ea, StreamId: 0, Metadata: 
Name: Conv_15 + Relu_16, LayerType: CaskConvolution, Inputs: [ { Name: Reformatted Input Tensor 0 to Conv_15 + Relu_16, Location: Device, Dimensions: [1,256,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: input.12, Location: Device, Dimensions: [1,128,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 128, Groups: 1, Weights: {"Type": "Half", "Count": 294912}, Bias: {"Type": "Half", "Count": 128}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16, TacticValue: 0x60da8c7151d91e47, StreamId: 0, Metadata: [ONNX Layer: Conv_15][ONNX Layer: Relu_16]
Name: Conv_17 + Relu_18, LayerType: CaskConvolution, Inputs: [ { Name: input.12, Location: Device, Dimensions: [1,128,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: input.24, Location: Device, Dimensions: [1,128,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 128, Groups: 1, Weights: {"Type": "Half", "Count": 147456}, Bias: {"Type": "Half", "Count": 128}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0x048d6d0400f33439, StreamId: 0, Metadata: [ONNX Layer: Conv_17][ONNX Layer: Relu_18]
Name: Conv_19 + Relu_20, LayerType: CaskConvolution, Inputs: [ { Name: input.24, Location: Device, Dimensions: [1,128,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: input.36, Location: Device, Dimensions: [1,128,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 128, Groups: 1, Weights: {"Type": "Half", "Count": 147456}, Bias: {"Type": "Half", "Count": 128}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0x048d6d0400f33439, StreamId: 0, Metadata: [ONNX Layer: Conv_19][ONNX Layer: Relu_20]
Name: Conv_21 + Relu_22, LayerType: CaskConvolution, Inputs: [ { Name: input.36, Location: Device, Dimensions: [1,128,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: input.48, Location: Device, Dimensions: [1,128,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 128, Groups: 1, Weights: {"Type": "Half", "Count": 147456}, Bias: {"Type": "Half", "Count": 128}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0x048d6d0400f33439, StreamId: 0, Metadata: [ONNX Layer: Conv_21][ONNX Layer: Relu_22]
Name: Conv_23 + Relu_24, LayerType: CaskConvolution, Inputs: [ { Name: input.48, Location: Device, Dimensions: [1,128,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: input.60, Location: Device, Dimensions: [1,128,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 128, Groups: 1, Weights: {"Type": "Half", "Count": 147456}, Bias: {"Type": "Half", "Count": 128}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0x048d6d0400f33439, StreamId: 0, Metadata: [ONNX Layer: Conv_23][ONNX Layer: Relu_24]
Name: Conv_25 + Relu_26, LayerType: CaskConvolution, Inputs: [ { Name: input.60, Location: Device, Dimensions: [1,128,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: input.72, Location: Device, Dimensions: [1,128,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 128, Groups: 1, Weights: {"Type": "Half", "Count": 147456}, Bias: {"Type": "Half", "Count": 128}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0x048d6d0400f33439, StreamId: 0, Metadata: [ONNX Layer: Conv_25][ONNX Layer: Relu_26]
Name: Conv_27 + Relu_28, LayerType: CaskGemmConvolution, Inputs: [ { Name: input.72, Location: Device, Dimensions: [1,128,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: input.164, Location: Device, Dimensions: [1,256,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [1,1], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [0,0], PostPadding: [0,0], Stride: [1,1], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Half", "Count": 32768}, Bias: {"Type": "Half", "Count": 256}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, TacticName: sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize256x128x32_stage3_warpsize4x2x1_tensor16x8x16, TacticValue: 0x000000000002008e, StreamId: 0, Metadata: [ONNX Layer: Conv_27][ONNX Layer: Relu_28]
Name: Conv_44 + Relu_45, LayerType: CaskConvolution, Inputs: [ { Name: input.72, Location: Device, Dimensions: [1,128,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: input.96, Location: Device, Dimensions: [1,256,90,90], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [2,2], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Half", "Count": 294912}, Bias: {"Type": "Half", "Count": 256}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16, TacticValue: 0x0e07ff4f4f7c1ac9, StreamId: 0, Metadata: [ONNX Layer: Conv_44][ONNX Layer: Relu_45]
Name: Conv_46 + Relu_47, LayerType: CaskConvolution, Inputs: [ { Name: input.96, Location: Device, Dimensions: [1,256,90,90], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: input.108, Location: Device, Dimensions: [1,256,90,90], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Half", "Count": 589824}, Bias: {"Type": "Half", "Count": 256}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3_aACCESS, TacticValue: 0x245530c34bd6090f, StreamId: 0, Metadata: [ONNX Layer: Conv_46][ONNX Layer: Relu_47]
Name: Conv_48 + Relu_49, LayerType: CaskConvolution, Inputs: [ { Name: input.108, Location: Device, Dimensions: [1,256,90,90], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: input.120, Location: Device, Dimensions: [1,256,90,90], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Half", "Count": 589824}, Bias: {"Type": "Half", "Count": 256}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3_aACCESS, TacticValue: 0x245530c34bd6090f, StreamId: 0, Metadata: [ONNX Layer: Conv_48][ONNX Layer: Relu_49]
Name: Conv_50 + Relu_51, LayerType: CaskConvolution, Inputs: [ { Name: input.120, Location: Device, Dimensions: [1,256,90,90], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: input.132, Location: Device, Dimensions: [1,256,90,90], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Half", "Count": 589824}, Bias: {"Type": "Half", "Count": 256}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3_aACCESS, TacticValue: 0x245530c34bd6090f, StreamId: 0, Metadata: [ONNX Layer: Conv_50][ONNX Layer: Relu_51]
Name: Conv_52 + Relu_53, LayerType: CaskConvolution, Inputs: [ { Name: input.132, Location: Device, Dimensions: [1,256,90,90], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: input.144, Location: Device, Dimensions: [1,256,90,90], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Half", "Count": 589824}, Bias: {"Type": "Half", "Count": 256}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3_aACCESS, TacticValue: 0x245530c34bd6090f, StreamId: 0, Metadata: [ONNX Layer: Conv_52][ONNX Layer: Relu_53]
Name: Conv_54 + Relu_55, LayerType: CaskConvolution, Inputs: [ { Name: input.144, Location: Device, Dimensions: [1,256,90,90], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: onnx::ConvTranspose_644, Location: Device, Dimensions: [1,256,90,90], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Half", "Count": 589824}, Bias: {"Type": "Half", "Count": 256}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3_aACCESS, TacticValue: 0x245530c34bd6090f, StreamId: 0, Metadata: [ONNX Layer: Conv_54][ONNX Layer: Relu_55]
Name: ConvTranspose_56 + BatchNormalization_57 + Relu_58, LayerType: CaskDeconvolutionV2, Inputs: [ { Name: onnx::ConvTranspose_644, Location: Device, Dimensions: [1,256,90,90], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: input.164, Location: Device, Dimensions: [1,256,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [2,2], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [0,0], PostPadding: [0,0], Stride: [2,2], Dilation: [1,1], OutMaps: 256, Groups: 1, Weights: {"Type": "Half", "Count": 262144}, Bias: {"Type": "Half", "Count": 256}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_deconv_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16_strided, TacticValue: 0xdec24e75875e331b, StreamId: 0, Metadata: [ONNX Layer: ConvTranspose_56][ONNX Layer: BatchNormalization_57][ONNX Layer: Relu_58]
Name: Conv_60 + Relu_61, LayerType: CaskConvolution, Inputs: [ { Name: input.164, Location: Device, Dimensions: [1,512,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: onnx::Conv_651, Location: Device, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 64, Groups: 1, Weights: {"Type": "Half", "Count": 294912}, Bias: {"Type": "Half", "Count": 64}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3_aACCESS, TacticValue: 0x263a38afd75e3a43, StreamId: 0, Metadata: [ONNX Layer: Conv_60][ONNX Layer: Relu_61]
Name: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168, LayerType: CaskConvolution, Inputs: [ { Name: onnx::Conv_651, Location: Device, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168, Location: Device, Dimensions: [1,2304,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2304, Groups: 1, Weights: {"Type": "Half", "Count": 1327104}, Bias: {"Type": "Half", "Count": 2304}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: RELU, HasBias: 1, HasReLU: 1, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x128x32_stage3_warpsize4x2x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0x048d6d0400f33439, StreamId: 0, Metadata: [ONNX Layer: Conv_62][ONNX Layer: Relu_63][ONNX Layer: Conv_65][ONNX Layer: Relu_66][ONNX Layer: Conv_68][ONNX Layer: Relu_69][ONNX Layer: Conv_71][ONNX Layer: Relu_72][ONNX Layer: Conv_74][ONNX Layer: Relu_75][ONNX Layer: Conv_77][ONNX Layer: Relu_78][ONNX Layer: Conv_80][ONNX Layer: Relu_81][ONNX Layer: Conv_83][ONNX Layer: Relu_84][ONNX Layer: Conv_86][ONNX Layer: Relu_87][ONNX Layer: Conv_89][ONNX Layer: Relu_90][ONNX Layer: Conv_92][ONNX Layer: Relu_93][ONNX Layer: Conv_95][ONNX Layer: Relu_96][ONNX Layer: Conv_98][ONNX Layer: Relu_99][ONNX Layer: Conv_101][ONNX Layer: Relu_102][ONNX Layer: Conv_104][ONNX Layer: Relu_105][ONNX Layer: Conv_107][ONNX Layer: Relu_108][ONNX Layer: Conv_110][ONNX Layer: Relu_111][ONNX Layer: Conv_113][ONNX Layer: Relu_114][ONNX Layer: Conv_116][ONNX Layer: Relu_117][ONNX Layer: Conv_119][ONNX Layer: Relu_120][ONNX Layer: Conv_122][ONNX Layer: Relu_123][ONNX Layer: Conv_125][ONNX Layer: Relu_126][ONNX Layer: Conv_128][ONNX Layer: Relu_129][ONNX Layer: Conv_131][ONNX Layer: Relu_132][ONNX Layer: Conv_134][ONNX Layer: Relu_135][ONNX Layer: Conv_137][ONNX Layer: Relu_138][ONNX Layer: Conv_140][ONNX Layer: Relu_141][ONNX Layer: Conv_143][ONNX Layer: Relu_144][ONNX Layer: Conv_146][ONNX Layer: Relu_147][ONNX Layer: Conv_149][ONNX Layer: Relu_150][ONNX Layer: Conv_152][ONNX Layer: Relu_153][ONNX Layer: Conv_155][ONNX Layer: Relu_156][ONNX Layer: Conv_158][ONNX Layer: Relu_159][ONNX Layer: Conv_161][ONNX Layer: Relu_162][ONNX Layer: Conv_164][ONNX Layer: Relu_165][ONNX Layer: Conv_167][ONNX Layer: Relu_168]
Name: Conv_64, LayerType: CaskConvolution, Inputs: [ { Name: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168, Location: Device, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_64, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16, TacticValue: 0xa83b68f30462f971, StreamId: 0, Metadata: [ONNX Layer: Conv_64]
Name: Reformatting CopyNode for Output Tensor 0 to Conv_64, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_64, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: reg_0, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0000000000000000, StreamId: 0, Metadata: 
Name: Conv_67, LayerType: CaskConvolution, Inputs: [ { Name: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168, Location: Device, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_67, Location: Device, Dimensions: [1,1,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 1, Groups: 1, Weights: {"Type": "Half", "Count": 576}, Bias: {"Type": "Half", "Count": 1}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0xa40cb43c296a36a8, StreamId: 0, Metadata: [ONNX Layer: Conv_67]
Name: Reformatting CopyNode for Output Tensor 0 to Conv_67, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_67, Location: Device, Dimensions: [1,1,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: height_0, Location: Device, Dimensions: [1,1,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0000000000000000, StreamId: 0, Metadata: 
Name: Conv_70, LayerType: CaskConvolution, Inputs: [ { Name: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168, Location: Device, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_70, Location: Device, Dimensions: [1,3,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 3, Groups: 1, Weights: {"Type": "Half", "Count": 1728}, Bias: {"Type": "Half", "Count": 3}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16, TacticValue: 0xdce100b9fe609424, StreamId: 0, Metadata: [ONNX Layer: Conv_70]
Name: Reformatting CopyNode for Output Tensor 0 to Conv_70, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_70, Location: Device, Dimensions: [1,3,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: dim_0, Location: Device, Dimensions: [1,3,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0000000000000000, StreamId: 0, Metadata: 
Name: Conv_73, LayerType: CaskConvolution, Inputs: [ { Name: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168, Location: Device, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_73, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16, TacticValue: 0xa83b68f30462f971, StreamId: 0, Metadata: [ONNX Layer: Conv_73]
Name: Reformatting CopyNode for Output Tensor 0 to Conv_73, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_73, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: rot_0, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0000000000000000, StreamId: 0, Metadata: 
Name: Conv_76, LayerType: CaskConvolution, Inputs: [ { Name: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168, Location: Device, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_76, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16, TacticValue: 0xa83b68f30462f971, StreamId: 0, Metadata: [ONNX Layer: Conv_76]
Name: Reformatting CopyNode for Output Tensor 0 to Conv_76, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_76, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: vel_0, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0000000000000000, StreamId: 0, Metadata: 
Name: Conv_79, LayerType: CaskConvolution, Inputs: [ { Name: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168, Location: Device, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_79, Location: Device, Dimensions: [1,1,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 1, Groups: 1, Weights: {"Type": "Half", "Count": 576}, Bias: {"Type": "Half", "Count": 1}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0xa40cb43c296a36a8, StreamId: 0, Metadata: [ONNX Layer: Conv_79]
Name: Reformatting CopyNode for Output Tensor 0 to Conv_79, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_79, Location: Device, Dimensions: [1,1,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: hm_0, Location: Device, Dimensions: [1,1,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0000000000000000, StreamId: 0, Metadata: 
Name: Conv_82, LayerType: CaskConvolution, Inputs: [ { Name: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168, Location: Device, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_82, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16, TacticValue: 0xa83b68f30462f971, StreamId: 0, Metadata: [ONNX Layer: Conv_82]
Name: Reformatting CopyNode for Output Tensor 0 to Conv_82, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_82, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: reg_1, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0000000000000000, StreamId: 0, Metadata: 
Name: Conv_85, LayerType: CaskConvolution, Inputs: [ { Name: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168, Location: Device, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_85, Location: Device, Dimensions: [1,1,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 1, Groups: 1, Weights: {"Type": "Half", "Count": 576}, Bias: {"Type": "Half", "Count": 1}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0xa40cb43c296a36a8, StreamId: 0, Metadata: [ONNX Layer: Conv_85]
Name: Reformatting CopyNode for Output Tensor 0 to Conv_85, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_85, Location: Device, Dimensions: [1,1,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: height_1, Location: Device, Dimensions: [1,1,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0000000000000000, StreamId: 0, Metadata: 
Name: Conv_88, LayerType: CaskConvolution, Inputs: [ { Name: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168, Location: Device, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_88, Location: Device, Dimensions: [1,3,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 3, Groups: 1, Weights: {"Type": "Half", "Count": 1728}, Bias: {"Type": "Half", "Count": 3}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16, TacticValue: 0xdce100b9fe609424, StreamId: 0, Metadata: [ONNX Layer: Conv_88]
Name: Reformatting CopyNode for Output Tensor 0 to Conv_88, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_88, Location: Device, Dimensions: [1,3,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: dim_1, Location: Device, Dimensions: [1,3,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0000000000000000, StreamId: 0, Metadata: 
Name: Conv_91, LayerType: CaskConvolution, Inputs: [ { Name: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168, Location: Device, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_91, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16, TacticValue: 0xa83b68f30462f971, StreamId: 0, Metadata: [ONNX Layer: Conv_91]
Name: Reformatting CopyNode for Output Tensor 0 to Conv_91, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_91, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: rot_1, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0000000000000000, StreamId: 0, Metadata: 
Name: Conv_94, LayerType: CaskConvolution, Inputs: [ { Name: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168, Location: Device, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_94, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16, TacticValue: 0xa83b68f30462f971, StreamId: 0, Metadata: [ONNX Layer: Conv_94]
Name: Reformatting CopyNode for Output Tensor 0 to Conv_94, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_94, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: vel_1, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0000000000000000, StreamId: 0, Metadata: 
Name: Conv_97, LayerType: CaskConvolution, Inputs: [ { Name: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168, Location: Device, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_97, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16, TacticValue: 0xa83b68f30462f971, StreamId: 0, Metadata: [ONNX Layer: Conv_97]
Name: Reformatting CopyNode for Output Tensor 0 to Conv_97, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_97, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: hm_1, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0000000000000000, StreamId: 0, Metadata: 
Name: Conv_100, LayerType: CaskConvolution, Inputs: [ { Name: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168, Location: Device, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_100, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16, TacticValue: 0xa83b68f30462f971, StreamId: 0, Metadata: [ONNX Layer: Conv_100]
Name: Reformatting CopyNode for Output Tensor 0 to Conv_100, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_100, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: reg_2, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0000000000000000, StreamId: 0, Metadata: 
Name: Conv_103, LayerType: CaskConvolution, Inputs: [ { Name: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168, Location: Device, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_103, Location: Device, Dimensions: [1,1,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 1, Groups: 1, Weights: {"Type": "Half", "Count": 576}, Bias: {"Type": "Half", "Count": 1}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0xa40cb43c296a36a8, StreamId: 0, Metadata: [ONNX Layer: Conv_103]
Name: Reformatting CopyNode for Output Tensor 0 to Conv_103, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_103, Location: Device, Dimensions: [1,1,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: height_2, Location: Device, Dimensions: [1,1,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0000000000000000, StreamId: 0, Metadata: 
Name: Conv_106, LayerType: CaskConvolution, Inputs: [ { Name: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168, Location: Device, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_106, Location: Device, Dimensions: [1,3,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 3, Groups: 1, Weights: {"Type": "Half", "Count": 1728}, Bias: {"Type": "Half", "Count": 3}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16, TacticValue: 0xdce100b9fe609424, StreamId: 0, Metadata: [ONNX Layer: Conv_106]
Name: Reformatting CopyNode for Output Tensor 0 to Conv_106, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_106, Location: Device, Dimensions: [1,3,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: dim_2, Location: Device, Dimensions: [1,3,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0000000000000000, StreamId: 0, Metadata: 
Name: Conv_109, LayerType: CaskConvolution, Inputs: [ { Name: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168, Location: Device, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_109, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16, TacticValue: 0xa83b68f30462f971, StreamId: 0, Metadata: [ONNX Layer: Conv_109]
Name: Reformatting CopyNode for Output Tensor 0 to Conv_109, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_109, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: rot_2, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0000000000000000, StreamId: 0, Metadata: 
Name: Conv_112, LayerType: CaskConvolution, Inputs: [ { Name: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168, Location: Device, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_112, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16, TacticValue: 0xa83b68f30462f971, StreamId: 0, Metadata: [ONNX Layer: Conv_112]
Name: Reformatting CopyNode for Output Tensor 0 to Conv_112, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_112, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: vel_2, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0000000000000000, StreamId: 0, Metadata: 
Name: Conv_115, LayerType: CaskConvolution, Inputs: [ { Name: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168, Location: Device, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_115, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16, TacticValue: 0xa83b68f30462f971, StreamId: 0, Metadata: [ONNX Layer: Conv_115]
Name: Reformatting CopyNode for Output Tensor 0 to Conv_115, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_115, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: hm_2, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0000000000000000, StreamId: 0, Metadata: 
Name: Conv_118, LayerType: CaskConvolution, Inputs: [ { Name: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168, Location: Device, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_118, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16, TacticValue: 0xa83b68f30462f971, StreamId: 0, Metadata: [ONNX Layer: Conv_118]
Name: Reformatting CopyNode for Output Tensor 0 to Conv_118, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_118, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: reg_3, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0000000000000000, StreamId: 0, Metadata: 
Name: Conv_121, LayerType: CaskConvolution, Inputs: [ { Name: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168, Location: Device, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_121, Location: Device, Dimensions: [1,1,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 1, Groups: 1, Weights: {"Type": "Half", "Count": 576}, Bias: {"Type": "Half", "Count": 1}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0xa40cb43c296a36a8, StreamId: 0, Metadata: [ONNX Layer: Conv_121]
Name: Reformatting CopyNode for Output Tensor 0 to Conv_121, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_121, Location: Device, Dimensions: [1,1,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: height_3, Location: Device, Dimensions: [1,1,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0000000000000000, StreamId: 0, Metadata: 
Name: Conv_124, LayerType: CaskConvolution, Inputs: [ { Name: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168, Location: Device, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_124, Location: Device, Dimensions: [1,3,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 3, Groups: 1, Weights: {"Type": "Half", "Count": 1728}, Bias: {"Type": "Half", "Count": 3}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16, TacticValue: 0xdce100b9fe609424, StreamId: 0, Metadata: [ONNX Layer: Conv_124]
Name: Reformatting CopyNode for Output Tensor 0 to Conv_124, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_124, Location: Device, Dimensions: [1,3,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: dim_3, Location: Device, Dimensions: [1,3,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0000000000000000, StreamId: 0, Metadata: 
Name: Conv_127, LayerType: CaskConvolution, Inputs: [ { Name: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168, Location: Device, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_127, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16, TacticValue: 0xa83b68f30462f971, StreamId: 0, Metadata: [ONNX Layer: Conv_127]
Name: Reformatting CopyNode for Output Tensor 0 to Conv_127, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_127, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: rot_3, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0000000000000000, StreamId: 0, Metadata: 
Name: Conv_130, LayerType: CaskConvolution, Inputs: [ { Name: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168, Location: Device, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_130, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16, TacticValue: 0xa83b68f30462f971, StreamId: 0, Metadata: [ONNX Layer: Conv_130]
Name: Reformatting CopyNode for Output Tensor 0 to Conv_130, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_130, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: vel_3, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0000000000000000, StreamId: 0, Metadata: 
Name: Conv_133, LayerType: CaskConvolution, Inputs: [ { Name: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168, Location: Device, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_133, Location: Device, Dimensions: [1,1,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 1, Groups: 1, Weights: {"Type": "Half", "Count": 576}, Bias: {"Type": "Half", "Count": 1}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0xa40cb43c296a36a8, StreamId: 0, Metadata: [ONNX Layer: Conv_133]
Name: Reformatting CopyNode for Output Tensor 0 to Conv_133, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_133, Location: Device, Dimensions: [1,1,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: hm_3, Location: Device, Dimensions: [1,1,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0000000000000000, StreamId: 0, Metadata: 
Name: Conv_136, LayerType: CaskConvolution, Inputs: [ { Name: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168, Location: Device, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_136, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16, TacticValue: 0xa83b68f30462f971, StreamId: 0, Metadata: [ONNX Layer: Conv_136]
Name: Reformatting CopyNode for Output Tensor 0 to Conv_136, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_136, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: reg_4, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0000000000000000, StreamId: 0, Metadata: 
Name: Conv_139, LayerType: CaskConvolution, Inputs: [ { Name: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168, Location: Device, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_139, Location: Device, Dimensions: [1,1,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 1, Groups: 1, Weights: {"Type": "Half", "Count": 576}, Bias: {"Type": "Half", "Count": 1}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0xa40cb43c296a36a8, StreamId: 0, Metadata: [ONNX Layer: Conv_139]
Name: Reformatting CopyNode for Output Tensor 0 to Conv_139, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_139, Location: Device, Dimensions: [1,1,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: height_4, Location: Device, Dimensions: [1,1,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0000000000000000, StreamId: 0, Metadata: 
Name: Conv_142, LayerType: CaskConvolution, Inputs: [ { Name: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168, Location: Device, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_142, Location: Device, Dimensions: [1,3,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 3, Groups: 1, Weights: {"Type": "Half", "Count": 1728}, Bias: {"Type": "Half", "Count": 3}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16, TacticValue: 0xdce100b9fe609424, StreamId: 0, Metadata: [ONNX Layer: Conv_142]
Name: Reformatting CopyNode for Output Tensor 0 to Conv_142, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_142, Location: Device, Dimensions: [1,3,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: dim_4, Location: Device, Dimensions: [1,3,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0000000000000000, StreamId: 0, Metadata: 
Name: Conv_145, LayerType: CaskConvolution, Inputs: [ { Name: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168, Location: Device, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_145, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16, TacticValue: 0xa83b68f30462f971, StreamId: 0, Metadata: [ONNX Layer: Conv_145]
Name: Reformatting CopyNode for Output Tensor 0 to Conv_145, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_145, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: rot_4, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0000000000000000, StreamId: 0, Metadata: 
Name: Conv_148, LayerType: CaskConvolution, Inputs: [ { Name: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168, Location: Device, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_148, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16, TacticValue: 0xa83b68f30462f971, StreamId: 0, Metadata: [ONNX Layer: Conv_148]
Name: Reformatting CopyNode for Output Tensor 0 to Conv_148, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_148, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: vel_4, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0000000000000000, StreamId: 0, Metadata: 
Name: Conv_151, LayerType: CaskConvolution, Inputs: [ { Name: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168, Location: Device, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_151, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16, TacticValue: 0xa83b68f30462f971, StreamId: 0, Metadata: [ONNX Layer: Conv_151]
Name: Reformatting CopyNode for Output Tensor 0 to Conv_151, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_151, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: hm_4, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0000000000000000, StreamId: 0, Metadata: 
Name: Conv_154, LayerType: CaskConvolution, Inputs: [ { Name: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168, Location: Device, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_154, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16, TacticValue: 0xa83b68f30462f971, StreamId: 0, Metadata: [ONNX Layer: Conv_154]
Name: Reformatting CopyNode for Output Tensor 0 to Conv_154, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_154, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: reg_5, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0000000000000000, StreamId: 0, Metadata: 
Name: Conv_157, LayerType: CaskConvolution, Inputs: [ { Name: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168, Location: Device, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_157, Location: Device, Dimensions: [1,1,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 1, Groups: 1, Weights: {"Type": "Half", "Count": 576}, Bias: {"Type": "Half", "Count": 1}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_t1r3s3, TacticValue: 0xa40cb43c296a36a8, StreamId: 0, Metadata: [ONNX Layer: Conv_157]
Name: Reformatting CopyNode for Output Tensor 0 to Conv_157, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_157, Location: Device, Dimensions: [1,1,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: height_5, Location: Device, Dimensions: [1,1,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0000000000000000, StreamId: 0, Metadata: 
Name: Conv_160, LayerType: CaskConvolution, Inputs: [ { Name: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168, Location: Device, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_160, Location: Device, Dimensions: [1,3,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 3, Groups: 1, Weights: {"Type": "Half", "Count": 1728}, Bias: {"Type": "Half", "Count": 3}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16, TacticValue: 0xdce100b9fe609424, StreamId: 0, Metadata: [ONNX Layer: Conv_160]
Name: Reformatting CopyNode for Output Tensor 0 to Conv_160, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_160, Location: Device, Dimensions: [1,3,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: dim_5, Location: Device, Dimensions: [1,3,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0000000000000000, StreamId: 0, Metadata: 
Name: Conv_163, LayerType: CaskConvolution, Inputs: [ { Name: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168, Location: Device, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_163, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16, TacticValue: 0xa83b68f30462f971, StreamId: 0, Metadata: [ONNX Layer: Conv_163]
Name: Reformatting CopyNode for Output Tensor 0 to Conv_163, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_163, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: rot_5, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0000000000000000, StreamId: 0, Metadata: 
Name: Conv_166, LayerType: CaskConvolution, Inputs: [ { Name: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168, Location: Device, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_166, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16, TacticValue: 0xa83b68f30462f971, StreamId: 0, Metadata: [ONNX Layer: Conv_166]
Name: Reformatting CopyNode for Output Tensor 0 to Conv_166, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_166, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: vel_5, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0000000000000000, StreamId: 0, Metadata: 
Name: Conv_169, LayerType: CaskConvolution, Inputs: [ { Name: Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168, Location: Device, Dimensions: [1,64,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: Reformatted Output Tensor 0 to Conv_169, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], ParameterType: Convolution, Kernel: [3,3], PaddingMode: kEXPLICIT_ROUND_DOWN, PrePadding: [1,1], PostPadding: [1,1], Stride: [1,1], Dilation: [1,1], OutMaps: 2, Groups: 1, Weights: {"Type": "Half", "Count": 1152}, Bias: {"Type": "Half", "Count": 2}, HasSparseWeights: 0, HasDynamicFilter: 0, HasDynamicBias: 0, HasResidual: 0, ConvXAsActInputIdx: -1, BiasAsActInputIdx: -1, ResAsActInputIdx: -1, Activation: NONE, HasBias: 1, HasReLU: 0, TacticName: sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16, TacticValue: 0xa83b68f30462f971, StreamId: 0, Metadata: [ONNX Layer: Conv_169]
Name: Reformatting CopyNode for Output Tensor 0 to Conv_169, LayerType: Reformat, Inputs: [ { Name: Reformatted Output Tensor 0 to Conv_169, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Channel major FP16 format where channel % 8 == 0 }], Outputs: [ { Name: hm_5, Location: Device, Dimensions: [1,2,180,180], Format/Datatype: Row major linear FP16 format }], ParameterType: Reformat, Origin: REFORMAT, TacticValue: 0x0000000000000000, StreamId: 0, Metadata: 

Bindings:
input
reg_0
height_0
dim_0
rot_0
vel_0
hm_0
reg_1
height_1
dim_1
rot_1
vel_1
hm_1
reg_2
height_2
dim_2
rot_2
vel_2
hm_2
reg_3
height_3
dim_3
rot_3
vel_3
hm_3
reg_4
height_4
dim_4
rot_4
vel_4
hm_4
reg_5
height_5
dim_5
rot_5
vel_5
hm_5
[04/25/2025-09:08:58] [I] Starting inference
[04/25/2025-09:09:01] [I] Warmup completed 121 queries over 200 ms
[04/25/2025-09:09:01] [I] Timing trace has 1859 queries over 3.00403 s
[04/25/2025-09:09:01] [I] 
[04/25/2025-09:09:01] [I] === Trace details ===
[04/25/2025-09:09:01] [I] Trace averages of 10 runs:
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58833 ms - Host latency: 2.88374 ms (enqueue 0.383093 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.6128 ms - Host latency: 2.89824 ms (enqueue 0.382414 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58085 ms - Host latency: 2.77772 ms (enqueue 0.380043 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.61556 ms - Host latency: 2.84653 ms (enqueue 0.435158 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.57993 ms - Host latency: 2.74415 ms (enqueue 0.482599 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58085 ms - Host latency: 2.77135 ms (enqueue 0.471674 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.62816 ms - Host latency: 2.80679 ms (enqueue 0.481714 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58014 ms - Host latency: 2.70368 ms (enqueue 0.484039 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.59754 ms - Host latency: 2.75075 ms (enqueue 0.547702 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.61505 ms - Host latency: 2.90373 ms (enqueue 0.731158 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.583 ms - Host latency: 2.79415 ms (enqueue 0.697421 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.62253 ms - Host latency: 2.73291 ms (enqueue 0.679202 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.57788 ms - Host latency: 2.66695 ms (enqueue 0.688165 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.57829 ms - Host latency: 2.66013 ms (enqueue 0.463821 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.61403 ms - Host latency: 2.8608 ms (enqueue 0.491943 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.57973 ms - Host latency: 2.70617 ms (enqueue 0.488083 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.60573 ms - Host latency: 2.65782 ms (enqueue 0.481625 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.57798 ms - Host latency: 2.55323 ms (enqueue 0.490109 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.57871 ms - Host latency: 2.59072 ms (enqueue 0.476736 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.59775 ms - Host latency: 2.62078 ms (enqueue 0.496066 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.57931 ms - Host latency: 2.62691 ms (enqueue 0.479004 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.6168 ms - Host latency: 2.92481 ms (enqueue 0.494037 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58709 ms - Host latency: 2.91878 ms (enqueue 0.510669 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.5957 ms - Host latency: 3.0488 ms (enqueue 0.483148 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.60225 ms - Host latency: 2.66395 ms (enqueue 0.485748 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58514 ms - Host latency: 2.78064 ms (enqueue 0.502173 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.61342 ms - Host latency: 2.74872 ms (enqueue 0.480688 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58587 ms - Host latency: 2.76803 ms (enqueue 0.478796 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.57942 ms - Host latency: 2.61895 ms (enqueue 0.47746 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.59467 ms - Host latency: 2.5868 ms (enqueue 0.473431 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.57626 ms - Host latency: 2.59071 ms (enqueue 0.489294 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.60706 ms - Host latency: 2.68129 ms (enqueue 0.486877 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58219 ms - Host latency: 2.70701 ms (enqueue 0.48949 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.57786 ms - Host latency: 2.64028 ms (enqueue 0.482135 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.61659 ms - Host latency: 2.73792 ms (enqueue 0.477655 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.57974 ms - Host latency: 2.66183 ms (enqueue 0.487592 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.59692 ms - Host latency: 2.66673 ms (enqueue 0.487787 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58024 ms - Host latency: 2.67314 ms (enqueue 0.475665 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.57809 ms - Host latency: 2.58948 ms (enqueue 0.46778 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.62549 ms - Host latency: 2.62552 ms (enqueue 0.489331 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.60256 ms - Host latency: 2.93469 ms (enqueue 0.475787 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.64681 ms - Host latency: 4.20877 ms (enqueue 0.535651 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.57943 ms - Host latency: 2.71061 ms (enqueue 0.505365 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.57972 ms - Host latency: 2.65912 ms (enqueue 0.471881 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.5997 ms - Host latency: 2.63166 ms (enqueue 0.464124 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58249 ms - Host latency: 2.6186 ms (enqueue 0.501697 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.61752 ms - Host latency: 2.56809 ms (enqueue 0.481396 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.57357 ms - Host latency: 2.54173 ms (enqueue 0.48808 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.57961 ms - Host latency: 2.62806 ms (enqueue 0.476587 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.61834 ms - Host latency: 2.67089 ms (enqueue 0.487646 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.57809 ms - Host latency: 2.62914 ms (enqueue 0.467438 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.59828 ms - Host latency: 2.73777 ms (enqueue 0.48667 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.57776 ms - Host latency: 2.64897 ms (enqueue 0.790015 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.57972 ms - Host latency: 2.66797 ms (enqueue 0.475415 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.59813 ms - Host latency: 2.63821 ms (enqueue 0.496765 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58113 ms - Host latency: 2.62515 ms (enqueue 0.489624 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.60973 ms - Host latency: 2.63458 ms (enqueue 0.479614 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58812 ms - Host latency: 2.83558 ms (enqueue 0.498706 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58873 ms - Host latency: 2.84645 ms (enqueue 0.482459 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.60479 ms - Host latency: 2.63442 ms (enqueue 0.492261 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58136 ms - Host latency: 2.73315 ms (enqueue 0.485632 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.61329 ms - Host latency: 2.92015 ms (enqueue 0.492896 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.57881 ms - Host latency: 2.70027 ms (enqueue 0.487146 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.57827 ms - Host latency: 2.6038 ms (enqueue 0.478125 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.61588 ms - Host latency: 2.90576 ms (enqueue 0.484424 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58157 ms - Host latency: 2.69744 ms (enqueue 0.490723 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.57953 ms - Host latency: 2.59747 ms (enqueue 0.498425 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.62091 ms - Host latency: 2.94044 ms (enqueue 0.491699 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.61729 ms - Host latency: 3.36973 ms (enqueue 0.506799 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.61648 ms - Host latency: 2.93281 ms (enqueue 0.492676 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58936 ms - Host latency: 2.87229 ms (enqueue 0.490747 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58024 ms - Host latency: 2.63726 ms (enqueue 0.479285 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.61475 ms - Host latency: 2.69412 ms (enqueue 0.492981 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58411 ms - Host latency: 2.70608 ms (enqueue 0.472009 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.62108 ms - Host latency: 2.76355 ms (enqueue 0.482288 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58066 ms - Host latency: 2.78492 ms (enqueue 0.509924 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.57788 ms - Host latency: 2.6623 ms (enqueue 0.482068 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.62019 ms - Host latency: 2.7324 ms (enqueue 0.488367 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58333 ms - Host latency: 2.84281 ms (enqueue 0.475208 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.61812 ms - Host latency: 3.01842 ms (enqueue 0.502612 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58721 ms - Host latency: 2.86189 ms (enqueue 0.487451 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58667 ms - Host latency: 2.82495 ms (enqueue 0.485693 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.60688 ms - Host latency: 3.0233 ms (enqueue 0.484229 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58228 ms - Host latency: 2.69731 ms (enqueue 0.499072 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.63492 ms - Host latency: 2.89138 ms (enqueue 0.485364 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58179 ms - Host latency: 2.72211 ms (enqueue 0.497681 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58076 ms - Host latency: 2.71637 ms (enqueue 0.480811 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.62703 ms - Host latency: 2.70515 ms (enqueue 0.491821 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.57738 ms - Host latency: 2.59023 ms (enqueue 0.469714 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58073 ms - Host latency: 2.67317 ms (enqueue 0.498022 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.62153 ms - Host latency: 2.72966 ms (enqueue 0.484961 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58047 ms - Host latency: 2.75513 ms (enqueue 0.485486 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.61393 ms - Host latency: 2.79397 ms (enqueue 0.497998 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58118 ms - Host latency: 2.73887 ms (enqueue 0.48053 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58333 ms - Host latency: 2.66873 ms (enqueue 0.497314 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.63796 ms - Host latency: 2.94307 ms (enqueue 0.497192 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.60165 ms - Host latency: 3.13193 ms (enqueue 0.502527 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.60972 ms - Host latency: 2.8853 ms (enqueue 0.518213 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.57981 ms - Host latency: 2.6088 ms (enqueue 0.469421 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.57626 ms - Host latency: 2.56779 ms (enqueue 0.486743 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.60647 ms - Host latency: 2.66591 ms (enqueue 0.48396 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.59752 ms - Host latency: 2.94117 ms (enqueue 0.494263 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.62581 ms - Host latency: 3.35977 ms (enqueue 0.504077 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.61248 ms - Host latency: 2.90822 ms (enqueue 0.524121 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58076 ms - Host latency: 2.74178 ms (enqueue 0.498865 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.61954 ms - Host latency: 2.88784 ms (enqueue 0.510339 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58416 ms - Host latency: 2.70714 ms (enqueue 0.479919 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58261 ms - Host latency: 2.72017 ms (enqueue 0.504346 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.61095 ms - Host latency: 2.7179 ms (enqueue 0.482666 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.57786 ms - Host latency: 2.67828 ms (enqueue 0.502954 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.62551 ms - Host latency: 2.7647 ms (enqueue 0.483521 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58578 ms - Host latency: 2.86825 ms (enqueue 0.511072 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58342 ms - Host latency: 2.75682 ms (enqueue 0.498145 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.60818 ms - Host latency: 2.85803 ms (enqueue 0.486353 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58431 ms - Host latency: 2.77705 ms (enqueue 0.487671 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.60745 ms - Host latency: 2.91641 ms (enqueue 0.511401 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58179 ms - Host latency: 2.78096 ms (enqueue 0.497949 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58831 ms - Host latency: 2.83965 ms (enqueue 0.497339 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58545 ms - Host latency: 2.80569 ms (enqueue 0.691772 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58962 ms - Host latency: 2.93879 ms (enqueue 0.751538 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58738 ms - Host latency: 2.68035 ms (enqueue 0.702002 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.60664 ms - Host latency: 2.71409 ms (enqueue 0.687671 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.57903 ms - Host latency: 2.6343 ms (enqueue 0.680151 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.59231 ms - Host latency: 3.16792 ms (enqueue 0.750806 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58765 ms - Host latency: 2.8375 ms (enqueue 0.668604 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.59714 ms - Host latency: 3.02454 ms (enqueue 0.628076 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.63022 ms - Host latency: 3.19653 ms (enqueue 0.680371 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58813 ms - Host latency: 2.99971 ms (enqueue 0.642407 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.62341 ms - Host latency: 2.83743 ms (enqueue 0.703906 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58503 ms - Host latency: 2.8781 ms (enqueue 0.523047 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.57983 ms - Host latency: 2.76189 ms (enqueue 0.510962 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.61914 ms - Host latency: 2.88875 ms (enqueue 0.515088 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58042 ms - Host latency: 2.76477 ms (enqueue 0.494409 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.60459 ms - Host latency: 2.73159 ms (enqueue 0.711035 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.57732 ms - Host latency: 2.63657 ms (enqueue 0.484692 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58091 ms - Host latency: 2.70664 ms (enqueue 0.490356 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.60686 ms - Host latency: 2.75132 ms (enqueue 0.499609 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.63083 ms - Host latency: 3.37747 ms (enqueue 0.479077 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.62456 ms - Host latency: 3.58777 ms (enqueue 0.36228 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.6157 ms - Host latency: 3.20994 ms (enqueue 0.357715 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.6209 ms - Host latency: 2.99658 ms (enqueue 0.369458 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58372 ms - Host latency: 2.81685 ms (enqueue 0.357324 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58015 ms - Host latency: 2.671 ms (enqueue 0.351758 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.62627 ms - Host latency: 3.03135 ms (enqueue 0.355933 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58367 ms - Host latency: 2.78457 ms (enqueue 0.352271 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58633 ms - Host latency: 2.88159 ms (enqueue 0.348291 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.61545 ms - Host latency: 2.84275 ms (enqueue 0.349316 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.5835 ms - Host latency: 2.64912 ms (enqueue 0.347607 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.60669 ms - Host latency: 2.68159 ms (enqueue 0.348413 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.59917 ms - Host latency: 3.3727 ms (enqueue 0.390796 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58892 ms - Host latency: 2.86699 ms (enqueue 0.750879 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.63262 ms - Host latency: 3.151 ms (enqueue 0.481396 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58284 ms - Host latency: 2.76174 ms (enqueue 0.527515 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.60542 ms - Host latency: 2.76392 ms (enqueue 0.539648 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58279 ms - Host latency: 2.7116 ms (enqueue 0.48125 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58027 ms - Host latency: 2.7064 ms (enqueue 0.515161 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.60535 ms - Host latency: 2.8677 ms (enqueue 0.485376 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58611 ms - Host latency: 2.82124 ms (enqueue 0.500195 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.60447 ms - Host latency: 2.87983 ms (enqueue 0.500366 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58137 ms - Host latency: 2.70918 ms (enqueue 0.479419 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58154 ms - Host latency: 2.73315 ms (enqueue 0.502832 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.60613 ms - Host latency: 2.83474 ms (enqueue 0.483545 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58782 ms - Host latency: 2.89648 ms (enqueue 0.495947 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.60728 ms - Host latency: 2.84075 ms (enqueue 0.747021 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58044 ms - Host latency: 2.66565 ms (enqueue 0.462769 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.5802 ms - Host latency: 2.63914 ms (enqueue 0.496899 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58113 ms - Host latency: 2.80845 ms (enqueue 0.564307 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.57983 ms - Host latency: 2.64687 ms (enqueue 0.473657 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58716 ms - Host latency: 2.86965 ms (enqueue 0.492358 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.61621 ms - Host latency: 2.98743 ms (enqueue 0.710474 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58328 ms - Host latency: 2.78125 ms (enqueue 0.498413 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.6467 ms - Host latency: 3.01187 ms (enqueue 0.520898 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58088 ms - Host latency: 2.66245 ms (enqueue 0.507471 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58018 ms - Host latency: 2.62891 ms (enqueue 0.502026 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.60078 ms - Host latency: 2.66599 ms (enqueue 0.484595 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58328 ms - Host latency: 2.7405 ms (enqueue 0.511597 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.59514 ms - Host latency: 2.63811 ms (enqueue 0.708398 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58994 ms - Host latency: 2.93677 ms (enqueue 0.496558 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.5783 ms - Host latency: 2.65164 ms (enqueue 0.478491 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.63071 ms - Host latency: 2.77766 ms (enqueue 0.507788 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58079 ms - Host latency: 2.69241 ms (enqueue 0.480273 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.60481 ms - Host latency: 2.71953 ms (enqueue 0.48396 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58157 ms - Host latency: 2.651 ms (enqueue 0.500562 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58391 ms - Host latency: 2.80144 ms (enqueue 0.484058 ms)
[04/25/2025-09:09:01] [I] Average on 10 runs - GPU latency: 1.58994 ms - Host latency: 2.95994 ms (enqueue 0.498853 ms)
[04/25/2025-09:09:01] [I] 
[04/25/2025-09:09:01] [I] === Performance summary ===
[04/25/2025-09:09:01] [I] Throughput: 618.836 qps
[04/25/2025-09:09:01] [I] Latency: min = 2.48877 ms, max = 8.46875 ms, mean = 2.79498 ms, median = 2.73883 ms, percentile(90%) = 3.05298 ms, percentile(95%) = 3.24841 ms, percentile(99%) = 3.70044 ms
[04/25/2025-09:09:01] [I] Enqueue Time: min = 0.340546 ms, max = 1.34961 ms, mean = 0.506015 ms, median = 0.488281 ms, percentile(90%) = 0.620361 ms, percentile(95%) = 0.708618 ms, percentile(99%) = 1.02979 ms
[04/25/2025-09:09:01] [I] H2D Latency: min = 0.670898 ms, max = 6.44043 ms, mean = 0.925315 ms, median = 0.882492 ms, percentile(90%) = 1.13635 ms, percentile(95%) = 1.28809 ms, percentile(99%) = 1.6355 ms
[04/25/2025-09:09:01] [I] GPU Compute Time: min = 1.56464 ms, max = 2.04492 ms, mean = 1.59568 ms, median = 1.58215 ms, percentile(90%) = 1.60571 ms, percentile(95%) = 1.69165 ms, percentile(99%) = 1.85037 ms
[04/25/2025-09:09:01] [I] D2H Latency: min = 0.235596 ms, max = 0.760193 ms, mean = 0.273995 ms, median = 0.253357 ms, percentile(90%) = 0.323975 ms, percentile(95%) = 0.402588 ms, percentile(99%) = 0.542969 ms
[04/25/2025-09:09:01] [I] Total Host Walltime: 3.00403 s
[04/25/2025-09:09:01] [I] Total GPU Compute Time: 2.96636 s
[04/25/2025-09:09:01] [W] * GPU compute time is unstable, with coefficient of variance = 3.15307%.
[04/25/2025-09:09:01] [W]   If not already in use, locking GPU clock frequency or adding --useSpinWait may improve the stability.
[04/25/2025-09:09:01] [I] Explanations of the performance metrics are printed in the verbose logs.
[04/25/2025-09:09:01] [V] 
[04/25/2025-09:09:01] [V] === Explanations of the performance metrics ===
[04/25/2025-09:09:01] [V] Total Host Walltime: the host walltime from when the first query (after warmups) is enqueued to when the last query is completed.
[04/25/2025-09:09:01] [V] GPU Compute Time: the GPU latency to execute the kernels for a query.
[04/25/2025-09:09:01] [V] Total GPU Compute Time: the summation of the GPU Compute Time of all the queries. If this is significantly shorter than Total Host Walltime, the GPU may be under-utilized because of host-side overheads or data transfers.
[04/25/2025-09:09:01] [V] Throughput: the observed throughput computed by dividing the number of queries by the Total Host Walltime. If this is significantly lower than the reciprocal of GPU Compute Time, the GPU may be under-utilized because of host-side overheads or data transfers.
[04/25/2025-09:09:01] [V] Enqueue Time: the host latency to enqueue a query. If this is longer than GPU Compute Time, the GPU may be under-utilized.
[04/25/2025-09:09:01] [V] H2D Latency: the latency for host-to-device data transfers for input tensors of a single query.
[04/25/2025-09:09:01] [V] D2H Latency: the latency for device-to-host data transfers for output tensors of a single query.
[04/25/2025-09:09:01] [V] Latency: the summation of H2D Latency, GPU Compute Time, and D2H Latency. This is the latency to infer a single query.
[04/25/2025-09:09:01] [I] 
[04/25/2025-09:09:04] [I] 
[04/25/2025-09:09:04] [I] === Profile (1169 iterations ) ===
[04/25/2025-09:09:04] [I]    Time(ms)     Avg.(ms)   Median(ms)   Time(%)   Layer
[04/25/2025-09:09:04] [I]       26.52       0.0227       0.0225       1.3   Reformatting CopyNode for Input Tensor 0 to Conv_15 + Relu_16
[04/25/2025-09:09:04] [I]       88.02       0.0753       0.0748       4.2   Conv_15 + Relu_16
[04/25/2025-09:09:04] [I]       46.28       0.0396       0.0399       2.2   Conv_17 + Relu_18
[04/25/2025-09:09:04] [I]       44.70       0.0382       0.0379       2.2   Conv_19 + Relu_20
[04/25/2025-09:09:04] [I]       44.98       0.0385       0.0379       2.2   Conv_21 + Relu_22
[04/25/2025-09:09:04] [I]       44.83       0.0384       0.0379       2.2   Conv_23 + Relu_24
[04/25/2025-09:09:04] [I]       44.44       0.0380       0.0379       2.1   Conv_25 + Relu_26
[04/25/2025-09:09:04] [I]       24.43       0.0209       0.0205       1.2   Conv_27 + Relu_28
[04/25/2025-09:09:04] [I]       30.86       0.0264       0.0266       1.5   Conv_44 + Relu_45
[04/25/2025-09:09:04] [I]       44.38       0.0380       0.0379       2.1   Conv_46 + Relu_47
[04/25/2025-09:09:04] [I]       42.74       0.0366       0.0369       2.1   Conv_48 + Relu_49
[04/25/2025-09:09:04] [I]       42.31       0.0362       0.0358       2.0   Conv_50 + Relu_51
[04/25/2025-09:09:04] [I]       42.95       0.0367       0.0369       2.1   Conv_52 + Relu_53
[04/25/2025-09:09:04] [I]       42.62       0.0365       0.0358       2.1   Conv_54 + Relu_55
[04/25/2025-09:09:04] [I]       34.21       0.0293       0.0287       1.7   ConvTranspose_56 + BatchNormalization_57 + Relu_58
[04/25/2025-09:09:04] [I]       86.19       0.0737       0.0737       4.2   Conv_60 + Relu_61
[04/25/2025-09:09:04] [I]      407.90       0.3489       0.3492      19.7   Conv_62 + Relu_63 || Conv_65 + Relu_66 || Conv_68 + Relu_69 || Conv_71 + Relu_72 || Conv_74 + Relu_75 || Conv_77 + Relu_78 || Conv_80 + Relu_81 || Conv_83 + Relu_84 || Conv_86 + Relu_87 || Conv_89 + Relu_90 || Conv_92 + Relu_93 || Conv_95 + Relu_96 || Conv_98 + Relu_99 || Conv_101 + Relu_102 || Conv_104 + Relu_105 || Conv_107 + Relu_108 || Conv_110 + Relu_111 || Conv_113 + Relu_114 || Conv_116 + Relu_117 || Conv_119 + Relu_120 || Conv_122 + Relu_123 || Conv_125 + Relu_126 || Conv_128 + Relu_129 || Conv_131 + Relu_132 || Conv_134 + Relu_135 || Conv_137 + Relu_138 || Conv_140 + Relu_141 || Conv_143 + Relu_144 || Conv_146 + Relu_147 || Conv_149 + Relu_150 || Conv_152 + Relu_153 || Conv_155 + Relu_156 || Conv_158 + Relu_159 || Conv_161 + Relu_162 || Conv_164 + Relu_165 || Conv_167 + Relu_168
[04/25/2025-09:09:04] [I]       21.69       0.0186       0.0184       1.0   Conv_64
[04/25/2025-09:09:04] [I]        4.79       0.0041       0.0041       0.2   Reformatting CopyNode for Output Tensor 0 to Conv_64
[04/25/2025-09:09:04] [I]       19.79       0.0169       0.0164       1.0   Conv_67
[04/25/2025-09:09:04] [I]        4.62       0.0039       0.0041       0.2   Reformatting CopyNode for Output Tensor 0 to Conv_67
[04/25/2025-09:09:04] [I]       19.42       0.0166       0.0164       0.9   Conv_70
[04/25/2025-09:09:04] [I]        4.57       0.0039       0.0041       0.2   Reformatting CopyNode for Output Tensor 0 to Conv_70
[04/25/2025-09:09:04] [I]       18.83       0.0161       0.0164       0.9   Conv_73
[04/25/2025-09:09:04] [I]        4.56       0.0039       0.0041       0.2   Reformatting CopyNode for Output Tensor 0 to Conv_73
[04/25/2025-09:09:04] [I]       18.77       0.0161       0.0164       0.9   Conv_76
[04/25/2025-09:09:04] [I]        4.61       0.0039       0.0041       0.2   Reformatting CopyNode for Output Tensor 0 to Conv_76
[04/25/2025-09:09:04] [I]       19.31       0.0165       0.0164       0.9   Conv_79
[04/25/2025-09:09:04] [I]        4.56       0.0039       0.0041       0.2   Reformatting CopyNode for Output Tensor 0 to Conv_79
[04/25/2025-09:09:04] [I]       19.54       0.0167       0.0164       0.9   Conv_82
[04/25/2025-09:09:04] [I]        4.58       0.0039       0.0041       0.2   Reformatting CopyNode for Output Tensor 0 to Conv_82
[04/25/2025-09:09:04] [I]       19.60       0.0168       0.0164       0.9   Conv_85
[04/25/2025-09:09:04] [I]        4.54       0.0039       0.0041       0.2   Reformatting CopyNode for Output Tensor 0 to Conv_85
[04/25/2025-09:09:04] [I]       19.69       0.0168       0.0164       1.0   Conv_88
[04/25/2025-09:09:04] [I]        4.88       0.0042       0.0041       0.2   Reformatting CopyNode for Output Tensor 0 to Conv_88
[04/25/2025-09:09:04] [I]       20.85       0.0178       0.0174       1.0   Conv_91
[04/25/2025-09:09:04] [I]        4.54       0.0039       0.0041       0.2   Reformatting CopyNode for Output Tensor 0 to Conv_91
[04/25/2025-09:09:04] [I]       20.78       0.0178       0.0174       1.0   Conv_94
[04/25/2025-09:09:04] [I]        4.54       0.0039       0.0041       0.2   Reformatting CopyNode for Output Tensor 0 to Conv_94
[04/25/2025-09:09:04] [I]       21.15       0.0181       0.0184       1.0   Conv_97
[04/25/2025-09:09:04] [I]        4.58       0.0039       0.0041       0.2   Reformatting CopyNode for Output Tensor 0 to Conv_97
[04/25/2025-09:09:04] [I]       22.14       0.0189       0.0184       1.1   Conv_100
[04/25/2025-09:09:04] [I]        4.60       0.0039       0.0041       0.2   Reformatting CopyNode for Output Tensor 0 to Conv_100
[04/25/2025-09:09:04] [I]       22.17       0.0190       0.0184       1.1   Conv_103
[04/25/2025-09:09:04] [I]        4.58       0.0039       0.0041       0.2   Reformatting CopyNode for Output Tensor 0 to Conv_103
[04/25/2025-09:09:04] [I]       22.25       0.0190       0.0184       1.1   Conv_106
[04/25/2025-09:09:04] [I]        4.56       0.0039       0.0041       0.2   Reformatting CopyNode for Output Tensor 0 to Conv_106
[04/25/2025-09:09:04] [I]       22.91       0.0196       0.0195       1.1   Conv_109
[04/25/2025-09:09:04] [I]        4.52       0.0039       0.0041       0.2   Reformatting CopyNode for Output Tensor 0 to Conv_109
[04/25/2025-09:09:04] [I]       22.30       0.0191       0.0195       1.1   Conv_112
[04/25/2025-09:09:04] [I]        4.58       0.0039       0.0041       0.2   Reformatting CopyNode for Output Tensor 0 to Conv_112
[04/25/2025-09:09:04] [I]       22.09       0.0189       0.0184       1.1   Conv_115
[04/25/2025-09:09:04] [I]        4.56       0.0039       0.0041       0.2   Reformatting CopyNode for Output Tensor 0 to Conv_115
[04/25/2025-09:09:04] [I]       22.18       0.0190       0.0184       1.1   Conv_118
[04/25/2025-09:09:04] [I]        4.59       0.0039       0.0041       0.2   Reformatting CopyNode for Output Tensor 0 to Conv_118
[04/25/2025-09:09:04] [I]       22.72       0.0194       0.0195       1.1   Conv_121
[04/25/2025-09:09:04] [I]        4.60       0.0039       0.0041       0.2   Reformatting CopyNode for Output Tensor 0 to Conv_121
[04/25/2025-09:09:04] [I]       22.24       0.0190       0.0184       1.1   Conv_124
[04/25/2025-09:09:04] [I]        4.56       0.0039       0.0041       0.2   Reformatting CopyNode for Output Tensor 0 to Conv_124
[04/25/2025-09:09:04] [I]       22.33       0.0191       0.0194       1.1   Conv_127
[04/25/2025-09:09:04] [I]        4.54       0.0039       0.0041       0.2   Reformatting CopyNode for Output Tensor 0 to Conv_127
[04/25/2025-09:09:04] [I]       21.89       0.0187       0.0184       1.1   Conv_130
[04/25/2025-09:09:04] [I]        4.63       0.0040       0.0041       0.2   Reformatting CopyNode for Output Tensor 0 to Conv_130
[04/25/2025-09:09:04] [I]       21.77       0.0186       0.0184       1.1   Conv_133
[04/25/2025-09:09:04] [I]        4.56       0.0039       0.0041       0.2   Reformatting CopyNode for Output Tensor 0 to Conv_133
[04/25/2025-09:09:04] [I]       21.69       0.0186       0.0184       1.0   Conv_136
[04/25/2025-09:09:04] [I]        4.63       0.0040       0.0041       0.2   Reformatting CopyNode for Output Tensor 0 to Conv_136
[04/25/2025-09:09:04] [I]       22.38       0.0191       0.0195       1.1   Conv_139
[04/25/2025-09:09:04] [I]        4.64       0.0040       0.0041       0.2   Reformatting CopyNode for Output Tensor 0 to Conv_139
[04/25/2025-09:09:04] [I]       22.14       0.0189       0.0184       1.1   Conv_142
[04/25/2025-09:09:04] [I]        4.61       0.0039       0.0041       0.2   Reformatting CopyNode for Output Tensor 0 to Conv_142
[04/25/2025-09:09:04] [I]       22.36       0.0191       0.0185       1.1   Conv_145
[04/25/2025-09:09:04] [I]        4.59       0.0039       0.0041       0.2   Reformatting CopyNode for Output Tensor 0 to Conv_145
[04/25/2025-09:09:04] [I]       21.99       0.0188       0.0184       1.1   Conv_148
[04/25/2025-09:09:04] [I]        4.64       0.0040       0.0041       0.2   Reformatting CopyNode for Output Tensor 0 to Conv_148
[04/25/2025-09:09:04] [I]       21.94       0.0188       0.0184       1.1   Conv_151
[04/25/2025-09:09:04] [I]        4.63       0.0040       0.0041       0.2   Reformatting CopyNode for Output Tensor 0 to Conv_151
[04/25/2025-09:09:04] [I]       21.66       0.0185       0.0184       1.0   Conv_154
[04/25/2025-09:09:04] [I]        5.08       0.0043       0.0041       0.2   Reformatting CopyNode for Output Tensor 0 to Conv_154
[04/25/2025-09:09:04] [I]       22.03       0.0188       0.0184       1.1   Conv_157
[04/25/2025-09:09:04] [I]        4.59       0.0039       0.0041       0.2   Reformatting CopyNode for Output Tensor 0 to Conv_157
[04/25/2025-09:09:04] [I]       21.18       0.0181       0.0184       1.0   Conv_160
[04/25/2025-09:09:04] [I]        4.63       0.0040       0.0041       0.2   Reformatting CopyNode for Output Tensor 0 to Conv_160
[04/25/2025-09:09:04] [I]       21.65       0.0185       0.0184       1.0   Conv_163
[04/25/2025-09:09:04] [I]        4.60       0.0039       0.0041       0.2   Reformatting CopyNode for Output Tensor 0 to Conv_163
[04/25/2025-09:09:04] [I]       21.05       0.0180       0.0174       1.0   Conv_166
[04/25/2025-09:09:04] [I]        4.63       0.0040       0.0041       0.2   Reformatting CopyNode for Output Tensor 0 to Conv_166
[04/25/2025-09:09:04] [I]       21.31       0.0182       0.0184       1.0   Conv_169
[04/25/2025-09:09:04] [I]        4.60       0.0039       0.0041       0.2   Reformatting CopyNode for Output Tensor 0 to Conv_169
[04/25/2025-09:09:04] [I]     2072.25       1.7727       1.7572     100.0   Total
[04/25/2025-09:09:04] [I] 
&&&& PASSED TensorRT.trtexec [TensorRT v8601] # trtexec --onnx=model/rpn_centerhead_sim.onnx --saveEngine=model/rpn_centerhead_sim.plan.8503 --workspace=4096 --fp16 --outputIOFormats=fp16:chw --inputIOFormats=fp16:chw --verbose --dumpLayerInfo --dumpProfile --separateProfileRun --profilingVerbosity=detailed
